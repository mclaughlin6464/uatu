-------------------------------------------------------------------------------
There are messages associated with the following module(s):
-------------------------------------------------------------------------------

py-tensorflow/1.6.0_py27:
    Warning: this module requires a GPU, it won't work on CPU nodes.

-------------------------------------------------------------------------------


The following have been reloaded with a version change:
  1) openmpi/2.1.1 => openmpi/2.0.2

/home/users/swmclau2/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
2019-05-02 14:45:26.840057: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-05-02 14:45:27.006084: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1212] Found device 0 with properties: 
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.076
pciBusID: 0000:04:00.0
totalMemory: 11.93GiB freeMemory: 11.82GiB
2019-05-02 14:45:27.091462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1212] Found device 1 with properties: 
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.076
pciBusID: 0000:05:00.0
totalMemory: 11.93GiB freeMemory: 11.82GiB
2019-05-02 14:45:27.091880: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1227] Device peer to peer matrix
2019-05-02 14:45:27.091911: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1233] DMA: 0 1 
2019-05-02 14:45:27.091920: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1243] 0:   Y Y 
2019-05-02 14:45:27.091925: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1243] 1:   Y Y 
2019-05-02 14:45:27.091936: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1312] Adding visible gpu devices: 0, 1
2019-05-02 14:45:27.841898: I tensorflow/core/common_runtime/gpu/gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11444 MB memory) -> physical GPU (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:04:00.0, compute capability: 5.2)
2019-05-02 14:45:28.044846: I tensorflow/core/common_runtime/gpu/gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 11444 MB memory) -> physical GPU (device: 1, name: GeForce GTX TITAN X, pci bus id: 0000:05:00.0, compute capability: 5.2)
False
Starting epoch 0
Iteration 0, loss = 0.3179
Om: 114.69%, s8: 41.92% accuracy
chi2: 0.564

Iteration 10, loss = -2.3240
Iteration 20, loss = -3.6361
Iteration 30, loss = -4.5076
Iteration 40, loss = -4.8421
Iteration 50, loss = -5.1230
Iteration 60, loss = -4.6636
Iteration 70, loss = -5.6667
Iteration 80, loss = -5.4667
Iteration 90, loss = -5.1136
Iteration 100, loss = -5.8608
Iteration 110, loss = -4.4515
Iteration 120, loss = -6.3737
Iteration 130, loss = -5.5247
Iteration 140, loss = -5.4888
Iteration 150, loss = -6.1158
Iteration 160, loss = -6.7184
Iteration 170, loss = -5.6682
Iteration 180, loss = -6.5849
Iteration 190, loss = -6.5749
Iteration 200, loss = -6.4438
Iteration 210, loss = -6.3598
Iteration 220, loss = -6.3222
Iteration 230, loss = -7.1261
Iteration 240, loss = -6.7402
Iteration 250, loss = -7.1316
Iteration 260, loss = -7.2112
Iteration 270, loss = -6.7809
Iteration 280, loss = -7.2847
Iteration 290, loss = -6.6232
Iteration 300, loss = -7.3327
Iteration 310, loss = -7.2215
Iteration 320, loss = -7.2412
Iteration 330, loss = -7.8435
Iteration 340, loss = -7.6656
Iteration 350, loss = -7.3427
Iteration 360, loss = -7.8726
Iteration 370, loss = -8.0318
Iteration 380, loss = -7.6481
Iteration 390, loss = -7.3990
Iteration 400, loss = -7.6934
Iteration 410, loss = -7.9855
Iteration 420, loss = -7.5840
Iteration 430, loss = -8.0434
Iteration 440, loss = -7.6127
Iteration 450, loss = -7.6119
Iteration 460, loss = -8.0500
Iteration 470, loss = -8.4204
Iteration 480, loss = -8.4398
Iteration 490, loss = -8.3654
Iteration 500, loss = -8.0129
Iteration 510, loss = -8.2613
Iteration 520, loss = -8.4132
Iteration 530, loss = -8.4617
Iteration 540, loss = -8.6103
Iteration 550, loss = -8.8802
Iteration 560, loss = -8.9257
Iteration 570, loss = -8.4641
Iteration 580, loss = -8.7325
Iteration 590, loss = -8.9923
Iteration 600, loss = -8.7843
Iteration 610, loss = -8.8896
Iteration 620, loss = -9.3354
Iteration 630, loss = -8.4195
Iteration 640, loss = -8.1600
Iteration 650, loss = -8.3223
Iteration 660, loss = -8.9715
Iteration 670, loss = -9.2764
Iteration 680, loss = -9.5660
Iteration 690, loss = -9.2505
Iteration 700, loss = -9.7355
Iteration 710, loss = -9.0098
Iteration 720, loss = -9.2641
Iteration 730, loss = -9.5394
Iteration 740, loss = -9.2905
Iteration 750, loss = -8.8362
Iteration 760, loss = -9.0487
Iteration 770, loss = -8.6562
Iteration 780, loss = -9.5553
Iteration 790, loss = -9.1321
Iteration 800, loss = -9.4739
Iteration 810, loss = -8.9224
Iteration 820, loss = -9.1918
Iteration 830, loss = -9.6719
Iteration 840, loss = -9.3879
Iteration 850, loss = -8.8683
Iteration 860, loss = -9.8015
Iteration 870, loss = -10.0719
Iteration 880, loss = -9.2142
Iteration 890, loss = -9.7455
Iteration 900, loss = -9.3129
Iteration 910, loss = -9.9331
Iteration 920, loss = -9.9816
Iteration 930, loss = -10.5305
Iteration 940, loss = -10.2835
Iteration 950, loss = -9.9345
Iteration 960, loss = -9.9459
Iteration 970, loss = -9.0949
Iteration 980, loss = -9.7496
Iteration 990, loss = -9.4787
Iteration 1000, loss = -10.0533
Om: 14.15%, s8: 9.51% accuracy
chi2: 1.709

Iteration 1010, loss = -10.1860
Iteration 1020, loss = -10.2398
Iteration 1030, loss = -10.2807
Iteration 1040, loss = -10.0682
Iteration 1050, loss = -10.0413
Iteration 1060, loss = -10.2121
Iteration 1070, loss = -9.9640
Iteration 1080, loss = -10.0111
Iteration 1090, loss = -10.6503
Iteration 1100, loss = -10.5111
Iteration 1110, loss = -9.8403
Iteration 1120, loss = -10.9561
Iteration 1130, loss = -10.2393
Iteration 1140, loss = -10.3666
Iteration 1150, loss = -10.7442
Iteration 1160, loss = -10.9723
Iteration 1170, loss = -11.6153
Iteration 1180, loss = -11.0630
Iteration 1190, loss = -8.9937
Iteration 1200, loss = -9.9512
Iteration 1210, loss = -10.4307
Iteration 1220, loss = -10.1154
Iteration 1230, loss = -11.0746
Iteration 1240, loss = -10.5955
Iteration 1250, loss = -10.9615
Iteration 1260, loss = -10.0942
Iteration 1270, loss = -10.7677
Iteration 1280, loss = -10.7705
Iteration 1290, loss = -10.7381
Iteration 1300, loss = -11.7448
Iteration 1310, loss = -9.3895
Iteration 1320, loss = -10.9621
Iteration 1330, loss = -10.7086
Iteration 1340, loss = -11.4549
Iteration 1350, loss = -11.2767
Iteration 1360, loss = -11.1469
Iteration 1370, loss = -11.1129
Iteration 1380, loss = -10.3890
Iteration 1390, loss = -10.9147
Iteration 1400, loss = -11.0727
Iteration 1410, loss = -11.0317
Iteration 1420, loss = -11.0606
Iteration 1430, loss = -10.9621
Iteration 1440, loss = -11.7667
Starting epoch 1
Iteration 1450, loss = -11.0337
Iteration 1460, loss = -10.7143
Iteration 1470, loss = -10.9910
Iteration 1480, loss = -11.5192
Iteration 1490, loss = -11.4050
Iteration 1500, loss = -10.8824
Iteration 1510, loss = -11.6056
Iteration 1520, loss = -11.1475
Iteration 1530, loss = -11.5731
Iteration 1540, loss = -10.0879
Iteration 1550, loss = -11.5294
Iteration 1560, loss = -11.6067
Iteration 1570, loss = -12.0558
Iteration 1580, loss = -11.4528
Iteration 1590, loss = -11.5744
Iteration 1600, loss = -11.2303
Iteration 1610, loss = -11.6523
Iteration 1620, loss = -11.3248
Iteration 1630, loss = -11.5494
Iteration 1640, loss = -11.3300
Iteration 1650, loss = -12.0355
Iteration 1660, loss = -12.4652
Iteration 1670, loss = -11.8016
Iteration 1680, loss = -11.5214
Iteration 1690, loss = -11.8658
Iteration 1700, loss = -11.9102
Iteration 1710, loss = -11.9594
Iteration 1720, loss = -12.4833
Iteration 1730, loss = -11.0904
Iteration 1740, loss = -11.9271
Iteration 1750, loss = -11.7653
Iteration 1760, loss = -11.6759
Iteration 1770, loss = -11.9624
Iteration 1780, loss = -11.6849
Iteration 1790, loss = -12.0812
Iteration 1800, loss = -12.1713
Iteration 1810, loss = -10.4965
Iteration 1820, loss = -11.9961
Iteration 1830, loss = -12.4519
Iteration 1840, loss = -12.0012
Iteration 1850, loss = -12.4495
Iteration 1860, loss = -12.1864
Iteration 1870, loss = -12.2572
Iteration 1880, loss = -12.5758
Iteration 1890, loss = -12.5123
Iteration 1900, loss = -11.8998
Iteration 1910, loss = -12.1220
Iteration 1920, loss = -11.7719
Iteration 1930, loss = -12.0731
Iteration 1940, loss = -12.1847
Iteration 1950, loss = -11.9701
Iteration 1960, loss = -12.2875
Iteration 1970, loss = -11.8780
Iteration 1980, loss = -12.2293
Iteration 1990, loss = -10.8888
Iteration 2000, loss = -11.6364
Om: 9.67%, s8: 7.72% accuracy
chi2: 0.761

Iteration 2010, loss = -12.1177
Iteration 2020, loss = -12.3482
Iteration 2030, loss = -12.2118
Iteration 2040, loss = -12.1284
Iteration 2050, loss = -12.6406
Iteration 2060, loss = -12.3538
Iteration 2070, loss = -12.2098
Iteration 2080, loss = -12.6086
Iteration 2090, loss = -12.7627
Iteration 2100, loss = -12.5454
Iteration 2110, loss = -11.4048
Iteration 2120, loss = -11.9773
Iteration 2130, loss = -12.3973
Iteration 2140, loss = -12.5292
Iteration 2150, loss = -12.1213
Iteration 2160, loss = -12.4091
Iteration 2170, loss = -12.2533
Iteration 2180, loss = -12.1421
Iteration 2190, loss = -12.6942
Iteration 2200, loss = -12.1833
Iteration 2210, loss = -11.9506
Iteration 2220, loss = -12.1981
Iteration 2230, loss = -12.3106
Iteration 2240, loss = -12.6182
Iteration 2250, loss = -11.3855
Iteration 2260, loss = -12.8807
Iteration 2270, loss = -12.6698
Iteration 2280, loss = -12.2842
Iteration 2290, loss = -12.3865
Iteration 2300, loss = -12.1451
Iteration 2310, loss = -11.9950
Iteration 2320, loss = -12.3589
Iteration 2330, loss = -12.3585
Iteration 2340, loss = -12.7354
Iteration 2350, loss = -11.0158
Iteration 2360, loss = -12.9365
Iteration 2370, loss = -12.6700
Iteration 2380, loss = -12.2874
Iteration 2390, loss = -13.1034
Iteration 2400, loss = -12.3775
Iteration 2410, loss = -12.6817
Iteration 2420, loss = -12.5107
Iteration 2430, loss = -12.7545
Iteration 2440, loss = -12.5174
Iteration 2450, loss = -12.0867
Iteration 2460, loss = -12.3804
Iteration 2470, loss = -13.0145
Iteration 2480, loss = -12.6796
Iteration 2490, loss = -12.6468
Iteration 2500, loss = -11.7836
Iteration 2510, loss = -12.8785
Iteration 2520, loss = -12.0016
Iteration 2530, loss = -12.6226
Iteration 2540, loss = -12.5955
Iteration 2550, loss = -12.3961
Iteration 2560, loss = -12.7414
Iteration 2570, loss = -12.5221
Iteration 2580, loss = -12.7590
Iteration 2590, loss = -11.8937
Iteration 2600, loss = -12.7179
Iteration 2610, loss = -13.0327
Iteration 2620, loss = -12.7544
Iteration 2630, loss = -12.8025
Iteration 2640, loss = -13.0789
Iteration 2650, loss = -12.9078
Iteration 2660, loss = -11.4429
Iteration 2670, loss = -12.7045
Iteration 2680, loss = -12.8686
Iteration 2690, loss = -12.9302
Iteration 2700, loss = -12.1917
Iteration 2710, loss = -12.4233
Iteration 2720, loss = -13.0191
Iteration 2730, loss = -12.5770
Iteration 2740, loss = -12.8067
Iteration 2750, loss = -13.0311
Iteration 2760, loss = -12.8055
Iteration 2770, loss = -12.6979
Iteration 2780, loss = -12.2089
Iteration 2790, loss = -12.6714
Iteration 2800, loss = -11.9975
Iteration 2810, loss = -12.4668
Iteration 2820, loss = -12.6819
Iteration 2830, loss = -12.1481
Iteration 2840, loss = -13.0158
Iteration 2850, loss = -12.6044
Iteration 2860, loss = -12.0828
Iteration 2870, loss = -11.8130
Iteration 2880, loss = -13.0523
Starting epoch 2
Iteration 2890, loss = -13.5390
Iteration 2900, loss = -12.2629
Iteration 2910, loss = -12.7284
Iteration 2920, loss = -13.1279
Iteration 2930, loss = -12.3865
Iteration 2940, loss = -12.8399
Iteration 2950, loss = -12.3779
Iteration 2960, loss = -12.6849
Iteration 2970, loss = -12.0886
Iteration 2980, loss = -12.7280
Iteration 2990, loss = -13.1351
Iteration 3000, loss = -12.6034
Om: 9.65%, s8: 7.52% accuracy
chi2: 0.745

Iteration 3010, loss = -11.7315
Iteration 3020, loss = -12.6087
Iteration 3030, loss = -13.0068
Iteration 3040, loss = -11.7284
Iteration 3050, loss = -13.1249
Iteration 3060, loss = -12.4566
Iteration 3070, loss = -13.2925
Iteration 3080, loss = -12.8519
Iteration 3090, loss = -12.8802
Iteration 3100, loss = -12.4534
Iteration 3110, loss = -12.7405
Iteration 3120, loss = -12.6793
Iteration 3130, loss = -11.4243
Iteration 3140, loss = -12.3173
Iteration 3150, loss = -11.6524
Iteration 3160, loss = -12.1083
Iteration 3170, loss = -12.7052
Iteration 3180, loss = -12.6568
Iteration 3190, loss = -12.6058
Iteration 3200, loss = -12.6541
Iteration 3210, loss = -13.0774
Iteration 3220, loss = -12.9727
Iteration 3230, loss = -12.9510
Iteration 3240, loss = -13.1074
Iteration 3250, loss = -12.5427
Iteration 3260, loss = -12.2890
Iteration 3270, loss = -12.8985
Iteration 3280, loss = -12.1169
Iteration 3290, loss = -12.8567
Iteration 3300, loss = -12.7416
Iteration 3310, loss = -12.8320
Iteration 3320, loss = -13.1491
Iteration 3330, loss = -13.1616
Iteration 3340, loss = -12.7762
Iteration 3350, loss = -12.5360
Iteration 3360, loss = -12.2718
Iteration 3370, loss = -12.1789
Iteration 3380, loss = -11.4898
Iteration 3390, loss = -12.9005
Iteration 3400, loss = -12.8625
Iteration 3410, loss = -12.8530
Iteration 3420, loss = -12.5542
Iteration 3430, loss = -12.6241
Iteration 3440, loss = -12.9284
Iteration 3450, loss = -13.0108
Iteration 3460, loss = -13.2606
Iteration 3470, loss = -13.3726
Iteration 3480, loss = -11.9752
Iteration 3490, loss = -13.2559
Iteration 3500, loss = -12.4902
Iteration 3510, loss = -12.3586
Iteration 3520, loss = -12.7690
Iteration 3530, loss = -12.4241
Iteration 3540, loss = -12.7766
Iteration 3550, loss = -12.6674
Iteration 3560, loss = -13.0110
Iteration 3570, loss = -12.4491
Iteration 3580, loss = -13.1932
Iteration 3590, loss = -13.1961
Iteration 3600, loss = -13.6143
Iteration 3610, loss = -13.4059
Iteration 3620, loss = -13.6995
Iteration 3630, loss = -12.8630
Iteration 3640, loss = -12.5052
Iteration 3650, loss = -12.9815
Iteration 3660, loss = -12.9866
Iteration 3670, loss = -13.7053
Iteration 3680, loss = -12.7098
Iteration 3690, loss = -12.9144
Iteration 3700, loss = -12.6932
Iteration 3710, loss = -12.9792
Iteration 3720, loss = -13.0231
Iteration 3730, loss = -12.9899
Iteration 3740, loss = -12.9657
Iteration 3750, loss = -13.1214
Iteration 3760, loss = -12.5316
Iteration 3770, loss = -13.2051
Iteration 3780, loss = -13.6342
Iteration 3790, loss = -12.9555
Iteration 3800, loss = -12.0570
Iteration 3810, loss = -12.1136
Iteration 3820, loss = -12.8595
Iteration 3830, loss = -12.7155
Iteration 3840, loss = -12.6346
Iteration 3850, loss = -13.3215
Iteration 3860, loss = -12.5352
Iteration 3870, loss = -12.6506
Iteration 3880, loss = -12.6661
Iteration 3890, loss = -13.2139
Iteration 3900, loss = -12.8530
Iteration 3910, loss = -13.2672
Iteration 3920, loss = -11.9844
Iteration 3930, loss = -12.8737
Iteration 3940, loss = -13.1414
Iteration 3950, loss = -12.6910
Iteration 3960, loss = -12.9150
Iteration 3970, loss = -12.2819
Iteration 3980, loss = -13.1700
Iteration 3990, loss = -12.7983
Iteration 4000, loss = -12.9190
Om: 9.14%, s8: 6.87% accuracy
chi2: 1.487

Iteration 4010, loss = -13.0277
Iteration 4020, loss = -13.4182
Iteration 4030, loss = -13.4826
Iteration 4040, loss = -12.6613
Iteration 4050, loss = -12.9992
Iteration 4060, loss = -13.1764
Iteration 4070, loss = -12.8805
Iteration 4080, loss = -13.5075
Iteration 4090, loss = -13.0078
Iteration 4100, loss = -11.8981
Iteration 4110, loss = -13.2003
Iteration 4120, loss = -13.3942
Iteration 4130, loss = -12.4618
Iteration 4140, loss = -12.4757
Iteration 4150, loss = -12.5892
Iteration 4160, loss = -11.2720
Iteration 4170, loss = -12.8715
Iteration 4180, loss = -11.1147
Iteration 4190, loss = -12.9703
Iteration 4200, loss = -12.7994
Iteration 4210, loss = -12.0749
Iteration 4220, loss = -12.6245
Iteration 4230, loss = -13.5405
Iteration 4240, loss = -12.8943
Iteration 4250, loss = -12.3774
Iteration 4260, loss = -12.6040
Iteration 4270, loss = -12.8455
Iteration 4280, loss = -12.6635
Iteration 4290, loss = -13.7082
Iteration 4300, loss = -12.9124
Iteration 4310, loss = -13.0847
Iteration 4320, loss = -13.0274
Iteration 4330, loss = -13.4533
Starting epoch 3
Iteration 4340, loss = -13.1349
Iteration 4350, loss = -12.9991
Iteration 4360, loss = -13.0643
Iteration 4370, loss = -12.7462
Iteration 4380, loss = -13.2990
Iteration 4390, loss = -12.9025
Iteration 4400, loss = -12.4160
Iteration 4410, loss = -12.6194
Iteration 4420, loss = -13.0253
Iteration 4430, loss = -13.3803
Iteration 4440, loss = -13.0630
Iteration 4450, loss = -13.1250
Iteration 4460, loss = -13.4979
Iteration 4470, loss = -13.2030
Iteration 4480, loss = -12.8434
Iteration 4490, loss = -12.5669
Iteration 4500, loss = -12.6150
Iteration 4510, loss = -13.1449
Iteration 4520, loss = -13.1604
Iteration 4530, loss = -13.3029
Iteration 4540, loss = -13.1382
Iteration 4550, loss = -13.3055
Iteration 4560, loss = -13.5467
Iteration 4570, loss = -12.6494
Iteration 4580, loss = -12.7112
Iteration 4590, loss = -12.8114
Iteration 4600, loss = -12.8714
Iteration 4610, loss = -12.9031
Iteration 4620, loss = -13.3664
Iteration 4630, loss = -13.4506
Iteration 4640, loss = -12.9177
Iteration 4650, loss = -12.3471
Iteration 4660, loss = -12.6957
Iteration 4670, loss = -13.1840
Iteration 4680, loss = -12.8848
Iteration 4690, loss = -13.6529
Iteration 4700, loss = -12.8652
Iteration 4710, loss = -12.9625
Iteration 4720, loss = -13.2361
Iteration 4730, loss = -12.6359
Iteration 4740, loss = -13.2507
Iteration 4750, loss = -13.1899
Iteration 4760, loss = -13.4203
Iteration 4770, loss = -12.5916
Iteration 4780, loss = -13.5662
Iteration 4790, loss = -12.6032
Iteration 4800, loss = -12.9027
Iteration 4810, loss = -13.0996
Iteration 4820, loss = -12.4161
Iteration 4830, loss = -12.8897
Iteration 4840, loss = -12.5336
Iteration 4850, loss = -13.0140
Iteration 4860, loss = -13.3314
Iteration 4870, loss = -13.3446
Iteration 4880, loss = -13.2564
Iteration 4890, loss = -12.5993
Iteration 4900, loss = -13.1577
Iteration 4910, loss = -12.7335
Iteration 4920, loss = -13.2339
Iteration 4930, loss = -13.4906
Iteration 4940, loss = -13.6853
Iteration 4950, loss = -13.5131
Iteration 4960, loss = -13.3457
Iteration 4970, loss = -12.6603
Iteration 4980, loss = -13.1340
Iteration 4990, loss = -13.0786
Iteration 5000, loss = -13.2862
Om: 9.18%, s8: 6.79% accuracy
chi2: 1.185

Iteration 5010, loss = -12.8780
Iteration 5020, loss = -13.0446
Iteration 5030, loss = -12.8776
Iteration 5040, loss = -12.9270
Iteration 5050, loss = -13.0349
Iteration 5060, loss = -13.1522
Iteration 5070, loss = -13.0746
Iteration 5080, loss = -12.9231
Iteration 5090, loss = -12.2031
Iteration 5100, loss = -12.5869
Iteration 5110, loss = -13.4299
Iteration 5120, loss = -13.3307
Iteration 5130, loss = -13.2506
Iteration 5140, loss = -11.6184
Iteration 5150, loss = -13.5585
Iteration 5160, loss = -13.2536
Iteration 5170, loss = -12.8114
Iteration 5180, loss = -12.6914
Iteration 5190, loss = -13.1917
Iteration 5200, loss = -13.1384
Iteration 5210, loss = -12.8675
Iteration 5220, loss = -12.9923
Iteration 5230, loss = -12.7162
Iteration 5240, loss = -13.2218
Iteration 5250, loss = -13.2331
Iteration 5260, loss = -12.9739
Iteration 5270, loss = -13.6868
Iteration 5280, loss = -13.7946
Iteration 5290, loss = -13.8516
Iteration 5300, loss = -12.6388
Iteration 5310, loss = -12.3844
Iteration 5320, loss = -13.5668
Iteration 5330, loss = -12.5466
Iteration 5340, loss = -12.7897
Iteration 5350, loss = -12.2677
Iteration 5360, loss = -13.3102
Iteration 5370, loss = -13.0530
Iteration 5380, loss = -13.3723
Iteration 5390, loss = -12.6090
Iteration 5400, loss = -13.3105
Iteration 5410, loss = -12.6312
Iteration 5420, loss = -13.3653
Iteration 5430, loss = -12.9183
Iteration 5440, loss = -13.0180
Iteration 5450, loss = -13.0623
Iteration 5460, loss = -12.7962
Iteration 5470, loss = -12.9859
Iteration 5480, loss = -13.0368
Iteration 5490, loss = -12.9597
Iteration 5500, loss = -12.7987
Iteration 5510, loss = -13.5954
Iteration 5520, loss = -13.3517
Iteration 5530, loss = -13.1821
Iteration 5540, loss = -13.4920
Iteration 5550, loss = -12.7558
Iteration 5560, loss = -13.1995
Iteration 5570, loss = -13.3831
Iteration 5580, loss = -13.7111
Iteration 5590, loss = -11.5907
Iteration 5600, loss = -13.2834
Iteration 5610, loss = -13.4327
Iteration 5620, loss = -13.2504
Iteration 5630, loss = -12.4970
Iteration 5640, loss = -13.5122
Iteration 5650, loss = -13.0899
Iteration 5660, loss = -12.8817
Iteration 5670, loss = -12.8703
Iteration 5680, loss = -12.7854
Iteration 5690, loss = -12.7150
Iteration 5700, loss = -13.2003
Iteration 5710, loss = -12.9890
Iteration 5720, loss = -13.2960
Iteration 5730, loss = -12.5767
Iteration 5740, loss = -12.8884
Iteration 5750, loss = -13.1738
Iteration 5760, loss = -12.4803
Iteration 5770, loss = -13.1313
Starting epoch 4
Iteration 5780, loss = -13.5097
Iteration 5790, loss = -12.3243
Iteration 5800, loss = -12.9814
Iteration 5810, loss = -12.8283
Iteration 5820, loss = -12.8995
Iteration 5830, loss = -13.4418
Iteration 5840, loss = -12.9974
Iteration 5850, loss = -13.1783
Iteration 5860, loss = -12.9471
Iteration 5870, loss = -13.4891
Iteration 5880, loss = -13.1624
Iteration 5890, loss = -13.3791
Iteration 5900, loss = -13.0901
Iteration 5910, loss = -11.9652
Iteration 5920, loss = -13.4179
Iteration 5930, loss = -13.5081
Iteration 5940, loss = -13.1357
Iteration 5950, loss = -13.2435
Iteration 5960, loss = -13.3081
Iteration 5970, loss = -12.7113
Iteration 5980, loss = -13.0929
Iteration 5990, loss = -13.2166
Iteration 6000, loss = -12.9145
Om: 9.10%, s8: 6.75% accuracy
chi2: 1.146

Iteration 6010, loss = -12.8739
Iteration 6020, loss = -12.7071
Iteration 6030, loss = -13.3970
Iteration 6040, loss = -12.0352
Iteration 6050, loss = -13.3732
Iteration 6060, loss = -12.4160
Iteration 6070, loss = -13.2629
Iteration 6080, loss = -12.7978
Iteration 6090, loss = -12.7310
Iteration 6100, loss = -13.2013
Iteration 6110, loss = -13.2289
Iteration 6120, loss = -13.5372
Iteration 6130, loss = -13.6553
Iteration 6140, loss = -13.2199
Iteration 6150, loss = -12.6646
Iteration 6160, loss = -13.0165
Iteration 6170, loss = -12.8031
Iteration 6180, loss = -13.4372
Iteration 6190, loss = -13.0788
Iteration 6200, loss = -12.0883
Iteration 6210, loss = -12.7583
Iteration 6220, loss = -13.4753
Iteration 6230, loss = -12.6897
Iteration 6240, loss = -12.8498
Iteration 6250, loss = -13.2382
Iteration 6260, loss = -12.9531
Iteration 6270, loss = -13.0539
Iteration 6280, loss = -13.6948
Iteration 6290, loss = -13.0230
Iteration 6300, loss = -12.9975
Iteration 6310, loss = -13.0991
Iteration 6320, loss = -12.3350
Iteration 6330, loss = -12.9422
Iteration 6340, loss = -12.7672
Iteration 6350, loss = -13.1476
Iteration 6360, loss = -13.8633
Iteration 6370, loss = -12.8827
Iteration 6380, loss = -12.8850
Iteration 6390, loss = -13.4015
Iteration 6400, loss = -13.1173
Iteration 6410, loss = -13.7606
Iteration 6420, loss = -13.0910
Iteration 6430, loss = -12.9784
Iteration 6440, loss = -12.6570
Iteration 6450, loss = -13.3110
Iteration 6460, loss = -12.9753
Iteration 6470, loss = -13.1272
Iteration 6480, loss = -13.6573
Iteration 6490, loss = -13.6826
Iteration 6500, loss = -12.9742
Iteration 6510, loss = -13.8258
Iteration 6520, loss = -13.5053
Iteration 6530, loss = -12.4962
Iteration 6540, loss = -13.4049
Iteration 6550, loss = -13.2377
Iteration 6560, loss = -13.4145
Iteration 6570, loss = -13.0668
Iteration 6580, loss = -12.9905
Iteration 6590, loss = -13.4901
Iteration 6600, loss = -13.2097
Iteration 6610, loss = -13.4156
Iteration 6620, loss = -13.3960
Iteration 6630, loss = -12.9728
Iteration 6640, loss = -13.3222
Iteration 6650, loss = -12.7462
Iteration 6660, loss = -13.3269
Iteration 6670, loss = -13.0075
Iteration 6680, loss = -13.2051
Iteration 6690, loss = -12.9874
Iteration 6700, loss = -12.7672
Iteration 6710, loss = -13.5266
Iteration 6720, loss = -13.0059
Iteration 6730, loss = -12.9764
Iteration 6740, loss = -13.3108
Iteration 6750, loss = -13.2252
Iteration 6760, loss = -12.9724
Iteration 6770, loss = -12.7204
Iteration 6780, loss = -12.8491
Iteration 6790, loss = -13.0951
Iteration 6800, loss = -12.8338
Iteration 6810, loss = -12.9101
Iteration 6820, loss = -13.5180
Iteration 6830, loss = -13.2151
Iteration 6840, loss = -12.8429
Iteration 6850, loss = -12.9818
Iteration 6860, loss = -12.1289
Iteration 6870, loss = -12.8493
Iteration 6880, loss = -12.7301
Iteration 6890, loss = -13.5963
Iteration 6900, loss = -13.5582
Iteration 6910, loss = -13.5249
Iteration 6920, loss = -13.6932
Iteration 6930, loss = -12.9969
Iteration 6940, loss = -13.4423
Iteration 6950, loss = -13.6269
Iteration 6960, loss = -12.4768
Iteration 6970, loss = -13.0277
Iteration 6980, loss = -12.9388
Iteration 6990, loss = -12.6468
Iteration 7000, loss = -13.3905
Om: 9.07%, s8: 6.76% accuracy
chi2: 1.893

Iteration 7010, loss = -13.4569
Iteration 7020, loss = -13.4367
Iteration 7030, loss = -12.7188
Iteration 7040, loss = -13.3921
Iteration 7050, loss = -12.2911
Iteration 7060, loss = -13.2930
Iteration 7070, loss = -13.7648
Iteration 7080, loss = -13.3976
Iteration 7090, loss = -13.0047
Iteration 7100, loss = -12.8406
Iteration 7110, loss = -12.7590
Iteration 7120, loss = -13.9215
Iteration 7130, loss = -13.4651
Iteration 7140, loss = -13.6510
Iteration 7150, loss = -13.2771
Iteration 7160, loss = -13.6582
Iteration 7170, loss = -12.6803
Iteration 7180, loss = -13.5489
Iteration 7190, loss = -13.3637
Iteration 7200, loss = -13.3510
Iteration 7210, loss = -12.8032
Iteration 7220, loss = -13.0260
Starting epoch 5
Iteration 7230, loss = -12.5281
Iteration 7240, loss = -13.4896
Iteration 7250, loss = -13.0731
Iteration 7260, loss = -13.4259
Iteration 7270, loss = -13.2269
Iteration 7280, loss = -13.2188
Iteration 7290, loss = -13.1129
Iteration 7300, loss = -13.0891
Iteration 7310, loss = -12.9618
Iteration 7320, loss = -13.6262
Iteration 7330, loss = -13.1097
Iteration 7340, loss = -13.0857
Iteration 7350, loss = -13.8710
Iteration 7360, loss = -13.1490
Iteration 7370, loss = -13.4052
Iteration 7380, loss = -12.7157
Iteration 7390, loss = -12.3809
Iteration 7400, loss = -12.5752
Iteration 7410, loss = -12.8792
Iteration 7420, loss = -13.1620
Iteration 7430, loss = -13.8271
Iteration 7440, loss = -13.1704
Iteration 7450, loss = -13.0428
Iteration 7460, loss = -12.7571
Iteration 7470, loss = -13.0290
Iteration 7480, loss = -13.6180
Iteration 7490, loss = -13.5577
Iteration 7500, loss = -12.8650
Iteration 7510, loss = -13.8343
Iteration 7520, loss = -13.4511
Iteration 7530, loss = -11.7832
Iteration 7540, loss = -13.1754
Iteration 7550, loss = -12.9218
Iteration 7560, loss = -12.6261
Iteration 7570, loss = -12.9640
Iteration 7580, loss = -13.0477
Iteration 7590, loss = -12.8703
Iteration 7600, loss = -13.4699
Iteration 7610, loss = -13.6985
Iteration 7620, loss = -13.5117
Iteration 7630, loss = -13.3556
Iteration 7640, loss = -12.6605
Iteration 7650, loss = -13.4684
Iteration 7660, loss = -13.5326
Iteration 7670, loss = -12.8286
Iteration 7680, loss = -12.7977
Iteration 7690, loss = -13.6578
Iteration 7700, loss = -13.3479
Iteration 7710, loss = -12.9572
Iteration 7720, loss = -13.4655
Iteration 7730, loss = -12.2652
Iteration 7740, loss = -12.7027
Iteration 7750, loss = -13.4567
Iteration 7760, loss = -13.1155
Iteration 7770, loss = -13.2605
Iteration 7780, loss = -12.9285
Iteration 7790, loss = -13.4376
Iteration 7800, loss = -13.5417
Iteration 7810, loss = -13.2304
Iteration 7820, loss = -13.2077
Iteration 7830, loss = -13.4617
Iteration 7840, loss = -13.2124
Iteration 7850, loss = -13.7664
Iteration 7860, loss = -13.5849
Iteration 7870, loss = -13.4629
Iteration 7880, loss = -13.1755
Iteration 7890, loss = -13.4801
Iteration 7900, loss = -13.1747
Iteration 7910, loss = -13.1674
Iteration 7920, loss = -12.3516
Iteration 7930, loss = -13.2346
Iteration 7940, loss = -13.1851
Iteration 7950, loss = -13.1638
Iteration 7960, loss = -13.1323
Iteration 7970, loss = -13.5624
Iteration 7980, loss = -12.7490
Iteration 7990, loss = -12.8553
Iteration 8000, loss = -13.8239
Om: 9.03%, s8: 6.70% accuracy
chi2: 1.720

Iteration 8010, loss = -13.6264
Iteration 8020, loss = -13.5233
Iteration 8030, loss = -13.0797
Iteration 8040, loss = -13.2540
Iteration 8050, loss = -13.1690
Iteration 8060, loss = -13.0910
Iteration 8070, loss = -13.2218
Iteration 8080, loss = -13.4292
Iteration 8090, loss = -13.2800
Iteration 8100, loss = -13.2174
Iteration 8110, loss = -13.3025
Iteration 8120, loss = -13.0500
Iteration 8130, loss = -13.5426
Iteration 8140, loss = -13.2037
Iteration 8150, loss = -13.0746
Iteration 8160, loss = -13.2331
Iteration 8170, loss = -12.8956
Iteration 8180, loss = -13.5466
Iteration 8190, loss = -13.2005
Iteration 8200, loss = -13.0964
Iteration 8210, loss = -13.3124
Iteration 8220, loss = -13.3816
Iteration 8230, loss = -12.6440
Iteration 8240, loss = -13.3666
Iteration 8250, loss = -13.4945
Iteration 8260, loss = -13.5188
Iteration 8270, loss = -12.8068
Iteration 8280, loss = -12.8359
Iteration 8290, loss = -13.5628
Iteration 8300, loss = -13.1941
Iteration 8310, loss = -13.3415
Iteration 8320, loss = -13.0335
Iteration 8330, loss = -13.1971
Iteration 8340, loss = -13.5148
Iteration 8350, loss = -13.7142
Iteration 8360, loss = -13.2727
Iteration 8370, loss = -12.7755
Iteration 8380, loss = -13.0926
Iteration 8390, loss = -11.9848
Iteration 8400, loss = -12.5702
Iteration 8410, loss = -13.8976
Iteration 8420, loss = -13.5012
Iteration 8430, loss = -13.1558
Iteration 8440, loss = -12.5443
Iteration 8450, loss = -13.1014
Iteration 8460, loss = -12.4813
Iteration 8470, loss = -13.1898
Iteration 8480, loss = -12.6148
Iteration 8490, loss = -13.7694
Iteration 8500, loss = -13.8926
Iteration 8510, loss = -13.1680
Iteration 8520, loss = -13.0971
Iteration 8530, loss = -13.4510
Iteration 8540, loss = -13.9644
Iteration 8550, loss = -13.2836
Iteration 8560, loss = -13.0852
Iteration 8570, loss = -13.0352
Iteration 8580, loss = -13.1182
Iteration 8590, loss = -13.0298
Iteration 8600, loss = -12.8099
Iteration 8610, loss = -13.1825
Iteration 8620, loss = -12.9774
Iteration 8630, loss = -13.4191
Iteration 8640, loss = -12.9134
Iteration 8650, loss = -12.3506
Iteration 8660, loss = -12.6652
Starting epoch 6
Iteration 8670, loss = -13.6425
Iteration 8680, loss = -13.0216
Iteration 8690, loss = -12.7448
Iteration 8700, loss = -13.4881
Iteration 8710, loss = -13.3289
Iteration 8720, loss = -13.4682
Iteration 8730, loss = -13.3010
Iteration 8740, loss = -13.7129
Iteration 8750, loss = -12.7277
Iteration 8760, loss = -13.4719
Iteration 8770, loss = -13.5433
Iteration 8780, loss = -13.6658
Iteration 8790, loss = -13.2426
Iteration 8800, loss = -13.0457
Iteration 8810, loss = -13.3039
Iteration 8820, loss = -12.9803
Iteration 8830, loss = -13.3512
Iteration 8840, loss = -13.3667
Iteration 8850, loss = -13.0780
Iteration 8860, loss = -13.3486
Iteration 8870, loss = -13.2355
Iteration 8880, loss = -13.0504
Iteration 8890, loss = -12.2907
Iteration 8900, loss = -12.9542
Iteration 8910, loss = -12.8318
Iteration 8920, loss = -13.8495
Iteration 8930, loss = -12.6514
Iteration 8940, loss = -12.9817
Iteration 8950, loss = -12.7862
Iteration 8960, loss = -12.8357
Iteration 8970, loss = -13.1765
Iteration 8980, loss = -12.9390
Iteration 8990, loss = -13.7466
Iteration 9000, loss = -13.3035
Om: 8.98%, s8: 6.59% accuracy
chi2: 1.721

Iteration 9010, loss = -13.5249
Iteration 9020, loss = -13.4113
Iteration 9030, loss = -13.4177
Iteration 9040, loss = -12.8160
Iteration 9050, loss = -12.7141
Iteration 9060, loss = -13.3271
Iteration 9070, loss = -13.1356
Iteration 9080, loss = -13.2621
Iteration 9090, loss = -13.5262
Iteration 9100, loss = -13.4873
Iteration 9110, loss = -13.3768
Iteration 9120, loss = -12.9838
Iteration 9130, loss = -13.7522
Iteration 9140, loss = -13.0031
Iteration 9150, loss = -13.0336
Iteration 9160, loss = -13.2196
Iteration 9170, loss = -13.8933
Iteration 9180, loss = -12.9851
Iteration 9190, loss = -13.4035
Iteration 9200, loss = -13.0717
Iteration 9210, loss = -12.9773
Iteration 9220, loss = -13.2234
Iteration 9230, loss = -12.7951
Iteration 9240, loss = -13.7638
Iteration 9250, loss = -13.4880
Iteration 9260, loss = -13.1411
Iteration 9270, loss = -13.7916
Iteration 9280, loss = -12.8227
Iteration 9290, loss = -13.3474
Iteration 9300, loss = -13.4918
Iteration 9310, loss = -13.1166
Iteration 9320, loss = -13.6280
Iteration 9330, loss = -12.4337
Iteration 9340, loss = -13.7515
Iteration 9350, loss = -13.3251
Iteration 9360, loss = -13.8307
Iteration 9370, loss = -13.9636
Iteration 9380, loss = -13.6038
Iteration 9390, loss = -13.1609
Iteration 9400, loss = -13.7881
Iteration 9410, loss = -13.3447
Iteration 9420, loss = -13.0708
Iteration 9430, loss = -13.1296
Iteration 9440, loss = -13.5912
Iteration 9450, loss = -13.8052
Iteration 9460, loss = -13.2274
Iteration 9470, loss = -13.3761
Iteration 9480, loss = -13.3543
Iteration 9490, loss = -13.3660
Iteration 9500, loss = -13.4304
Iteration 9510, loss = -13.4020
Iteration 9520, loss = -12.6320
Iteration 9530, loss = -13.3625
Iteration 9540, loss = -12.9852
Iteration 9550, loss = -13.5549
Iteration 9560, loss = -13.1583
Iteration 9570, loss = -13.4905
Iteration 9580, loss = -12.8804
Iteration 9590, loss = -13.5007
Iteration 9600, loss = -13.4338
Iteration 9610, loss = -13.0266
Iteration 9620, loss = -12.4619
Iteration 9630, loss = -13.1173
Iteration 9640, loss = -13.2438
Iteration 9650, loss = -12.9932
Iteration 9660, loss = -12.9847
Iteration 9670, loss = -13.1839
Iteration 9680, loss = -13.3799
Iteration 9690, loss = -12.9295
Iteration 9700, loss = -12.4105
Iteration 9710, loss = -13.8774
Iteration 9720, loss = -13.0533
Iteration 9730, loss = -12.3850
Iteration 9740, loss = -13.8752
Iteration 9750, loss = -13.2242
Iteration 9760, loss = -13.2995
Iteration 9770, loss = -12.5008
Iteration 9780, loss = -13.0999
Iteration 9790, loss = -13.6594
Iteration 9800, loss = -13.5213
Iteration 9810, loss = -14.0287
Iteration 9820, loss = -13.3587
Iteration 9830, loss = -13.2847
Iteration 9840, loss = -13.4604
Iteration 9850, loss = -12.6626
Iteration 9860, loss = -13.3749
Iteration 9870, loss = -13.3244
Iteration 9880, loss = -12.8428
Iteration 9890, loss = -13.6030
Iteration 9900, loss = -13.4021
Iteration 9910, loss = -13.6789
Iteration 9920, loss = -13.2273
Iteration 9930, loss = -13.1037
Iteration 9940, loss = -12.4058
Iteration 9950, loss = -13.3014
Iteration 9960, loss = -13.7077
Iteration 9970, loss = -13.5873
Iteration 9980, loss = -13.0287
Iteration 9990, loss = -12.8659
Iteration 10000, loss = -13.1522
Om: 9.00%, s8: 6.61% accuracy
chi2: 1.247

Iteration 10010, loss = -13.4238
Iteration 10020, loss = -13.6568
Iteration 10030, loss = -13.5378
Iteration 10040, loss = -13.4150
Iteration 10050, loss = -13.2505
Iteration 10060, loss = -13.1529
Iteration 10070, loss = -13.7982
Iteration 10080, loss = -13.4861
Iteration 10090, loss = -14.0252
Iteration 10100, loss = -13.0422
Iteration 10110, loss = -13.6060
Starting epoch 7
Iteration 10120, loss = -13.1177
Iteration 10130, loss = -13.3343
Iteration 10140, loss = -13.5411
Iteration 10150, loss = -13.9719
Iteration 10160, loss = -13.6483
Iteration 10170, loss = -13.4548
Iteration 10180, loss = -13.0987
Iteration 10190, loss = -13.4853
Iteration 10200, loss = -13.3397
Iteration 10210, loss = -13.6861
Iteration 10220, loss = -13.0001
Iteration 10230, loss = -13.6418
Iteration 10240, loss = -13.7607
Iteration 10250, loss = -13.3805
Iteration 10260, loss = -12.9272
Iteration 10270, loss = -13.3493
Iteration 10280, loss = -12.9586
Iteration 10290, loss = -13.2503
Iteration 10300, loss = -13.0967
Iteration 10310, loss = -13.7373
Iteration 10320, loss = -13.4878
Iteration 10330, loss = -13.5857
Iteration 10340, loss = -13.4420
Iteration 10350, loss = -12.7439
Iteration 10360, loss = -13.4717
Iteration 10370, loss = -13.3917
Iteration 10380, loss = -13.4524
Iteration 10390, loss = -13.0382
Iteration 10400, loss = -13.9053
Iteration 10410, loss = -13.4108
Iteration 10420, loss = -13.0425
Iteration 10430, loss = -12.3848
Iteration 10440, loss = -13.4804
Iteration 10450, loss = -13.4655
Iteration 10460, loss = -13.5573
Iteration 10470, loss = -13.7137
Iteration 10480, loss = -13.1589
Iteration 10490, loss = -13.5198
Iteration 10500, loss = -13.4386
Iteration 10510, loss = -13.5338
Iteration 10520, loss = -13.6625
Iteration 10530, loss = -13.1314
Iteration 10540, loss = -13.6824
Iteration 10550, loss = -13.3701
Iteration 10560, loss = -13.5989
Iteration 10570, loss = -13.2690
Iteration 10580, loss = -13.7193
Iteration 10590, loss = -13.4549
Iteration 10600, loss = -12.8853
Iteration 10610, loss = -13.6690
Iteration 10620, loss = -12.7112
Iteration 10630, loss = -12.9405
Iteration 10640, loss = -13.2899
Iteration 10650, loss = -13.8927
Iteration 10660, loss = -13.3449
Iteration 10670, loss = -13.2497
Iteration 10680, loss = -13.5779
Iteration 10690, loss = -13.2024
Iteration 10700, loss = -13.3350
Iteration 10710, loss = -13.1081
Iteration 10720, loss = -13.5183
Iteration 10730, loss = -12.6474
Iteration 10740, loss = -13.9800
Iteration 10750, loss = -13.5705
Iteration 10760, loss = -13.3934
Iteration 10770, loss = -13.4631
Iteration 10780, loss = -13.7028
Iteration 10790, loss = -13.4907
Iteration 10800, loss = -13.1857
Iteration 10810, loss = -12.7618
Iteration 10820, loss = -13.2568
Iteration 10830, loss = -13.8886
Iteration 10840, loss = -13.1065
Iteration 10850, loss = -12.3974
Iteration 10860, loss = -13.0243
Iteration 10870, loss = -13.0981
Iteration 10880, loss = -12.9823
Iteration 10890, loss = -13.8060
Iteration 10900, loss = -13.5229
Iteration 10910, loss = -13.1076
Iteration 10920, loss = -12.0510
Iteration 10930, loss = -13.5568
Iteration 10940, loss = -13.7152
Iteration 10950, loss = -13.2517
Iteration 10960, loss = -12.8340
Iteration 10970, loss = -13.3800
Iteration 10980, loss = -13.5609
Iteration 10990, loss = -12.7699
Iteration 11000, loss = -13.3994
Om: 8.91%, s8: 6.52% accuracy
chi2: 1.260

Iteration 11010, loss = -13.5046
Iteration 11020, loss = -13.0814
Iteration 11030, loss = -13.0169
Iteration 11040, loss = -13.2379
Iteration 11050, loss = -12.9126
Iteration 11060, loss = -13.3667
Iteration 11070, loss = -14.0357
Iteration 11080, loss = -13.6377
Iteration 11090, loss = -13.1445
Iteration 11100, loss = -13.5545
Iteration 11110, loss = -13.2596
Iteration 11120, loss = -13.4775
Iteration 11130, loss = -13.2292
Iteration 11140, loss = -13.5382
Iteration 11150, loss = -13.6050
Iteration 11160, loss = -13.2574
Iteration 11170, loss = -13.0569
Iteration 11180, loss = -13.5747
Iteration 11190, loss = -13.2746
Iteration 11200, loss = -12.4944
Iteration 11210, loss = -13.3775
Iteration 11220, loss = -13.7448
Iteration 11230, loss = -13.1264
Iteration 11240, loss = -13.7295
Iteration 11250, loss = -13.7104
Iteration 11260, loss = -13.1856
Iteration 11270, loss = -13.2165
Iteration 11280, loss = -13.0301
Iteration 11290, loss = -12.9444
Iteration 11300, loss = -13.7017
Iteration 11310, loss = -13.6019
Iteration 11320, loss = -13.5414
Iteration 11330, loss = -12.7400
Iteration 11340, loss = -13.3592
Iteration 11350, loss = -13.4766
Iteration 11360, loss = -13.9010
Iteration 11370, loss = -12.9003
Iteration 11380, loss = -13.6746
Iteration 11390, loss = -13.3235
Iteration 11400, loss = -13.1670
Iteration 11410, loss = -13.5982
Iteration 11420, loss = -13.6198
Iteration 11430, loss = -13.3828
Iteration 11440, loss = -13.4530
Iteration 11450, loss = -13.1462
Iteration 11460, loss = -13.5923
Iteration 11470, loss = -13.1551
Iteration 11480, loss = -13.0770
Iteration 11490, loss = -13.3919
Iteration 11500, loss = -13.6456
Iteration 11510, loss = -13.7129
Iteration 11520, loss = -13.7604
Iteration 11530, loss = -13.6256
Iteration 11540, loss = -12.2115
Iteration 11550, loss = -13.0310
Starting epoch 8
Iteration 11560, loss = -14.0394
Iteration 11570, loss = -13.2538
Iteration 11580, loss = -13.1450
Iteration 11590, loss = -13.3625
Iteration 11600, loss = -13.1997
Iteration 11610, loss = -13.5350
Iteration 11620, loss = -12.9183
Iteration 11630, loss = -12.8203
Iteration 11640, loss = -13.4064
Iteration 11650, loss = -12.8164
Iteration 11660, loss = -13.7556
Iteration 11670, loss = -13.6381
Iteration 11680, loss = -13.8800
Iteration 11690, loss = -12.7162
Iteration 11700, loss = -13.1259
Iteration 11710, loss = -13.3406
Iteration 11720, loss = -13.4528
Iteration 11730, loss = -12.9911
Iteration 11740, loss = -13.6553
Iteration 11750, loss = -13.6023
Iteration 11760, loss = -13.3578
Iteration 11770, loss = -13.3376
Iteration 11780, loss = -12.3742
Iteration 11790, loss = -12.9176
Iteration 11800, loss = -12.7149
Iteration 11810, loss = -13.7583
Iteration 11820, loss = -12.2499
Iteration 11830, loss = -13.2758
Iteration 11840, loss = -13.3002
Iteration 11850, loss = -12.8230
Iteration 11860, loss = -13.4109
Iteration 11870, loss = -12.9102
Iteration 11880, loss = -13.7866
Iteration 11890, loss = -13.1154
Iteration 11900, loss = -13.6662
Iteration 11910, loss = -13.4646
Iteration 11920, loss = -13.5025
Iteration 11930, loss = -13.1307
Iteration 11940, loss = -13.4968
Iteration 11950, loss = -12.9437
Iteration 11960, loss = -13.4562
Iteration 11970, loss = -13.5112
Iteration 11980, loss = -12.9839
Iteration 11990, loss = -13.2325
Iteration 12000, loss = -13.1861
Om: 8.92%, s8: 6.50% accuracy
chi2: 1.549

Iteration 12010, loss = -13.0169
Iteration 12020, loss = -12.8707
Iteration 12030, loss = -13.0341
Iteration 12040, loss = -12.8504
Iteration 12050, loss = -12.9134
Iteration 12060, loss = -13.9408
Iteration 12070, loss = -13.0136
Iteration 12080, loss = -13.2996
Iteration 12090, loss = -13.2172
Iteration 12100, loss = -13.5257
Iteration 12110, loss = -12.6330
Iteration 12120, loss = -13.7764
Iteration 12130, loss = -13.4731
Iteration 12140, loss = -13.6555
Iteration 12150, loss = -13.2161
Iteration 12160, loss = -13.6849
Iteration 12170, loss = -13.1668
Iteration 12180, loss = -13.2701
Iteration 12190, loss = -13.3963
Iteration 12200, loss = -12.9594
Iteration 12210, loss = -13.3127
Iteration 12220, loss = -12.6702
Iteration 12230, loss = -13.8533
Iteration 12240, loss = -13.5443
Iteration 12250, loss = -13.6055
Iteration 12260, loss = -13.7824
Iteration 12270, loss = -13.7371
Iteration 12280, loss = -13.6697
Iteration 12290, loss = -14.1018
Iteration 12300, loss = -13.4192
Iteration 12310, loss = -13.4419
Iteration 12320, loss = -13.5751
Iteration 12330, loss = -13.5317
Iteration 12340, loss = -13.5504
Iteration 12350, loss = -13.5963
Iteration 12360, loss = -13.1462
Iteration 12370, loss = -13.4312
Iteration 12380, loss = -13.4082
Iteration 12390, loss = -13.3254
Iteration 12400, loss = -13.2830
Iteration 12410, loss = -13.5980
Iteration 12420, loss = -13.4500
Iteration 12430, loss = -13.3754
Iteration 12440, loss = -13.6366
Iteration 12450, loss = -12.7766
Iteration 12460, loss = -13.5313
Iteration 12470, loss = -13.2248
Iteration 12480, loss = -13.2338
Iteration 12490, loss = -13.6793
Iteration 12500, loss = -12.8804
Iteration 12510, loss = -12.7190
Iteration 12520, loss = -13.4115
Iteration 12530, loss = -13.4482
Iteration 12540, loss = -13.3717
Iteration 12550, loss = -12.7314
Iteration 12560, loss = -13.4359
Iteration 12570, loss = -13.6171
Iteration 12580, loss = -13.2925
Iteration 12590, loss = -12.6243
Iteration 12600, loss = -13.7417
Iteration 12610, loss = -12.7661
Iteration 12620, loss = -13.0878
Iteration 12630, loss = -13.7676
Iteration 12640, loss = -12.7138
Iteration 12650, loss = -13.3940
Iteration 12660, loss = -12.7004
Iteration 12670, loss = -13.6120
Iteration 12680, loss = -13.9813
Iteration 12690, loss = -13.9101
Iteration 12700, loss = -13.8568
Iteration 12710, loss = -13.5480
Iteration 12720, loss = -12.9619
Iteration 12730, loss = -13.6602
Iteration 12740, loss = -13.3926
Iteration 12750, loss = -13.8658
Iteration 12760, loss = -13.6350
Iteration 12770, loss = -13.1842
Iteration 12780, loss = -13.6313
Iteration 12790, loss = -13.4254
Iteration 12800, loss = -13.4698
Iteration 12810, loss = -13.2609
Iteration 12820, loss = -13.3144
Iteration 12830, loss = -12.3766
Iteration 12840, loss = -13.8477
Iteration 12850, loss = -13.5559
Iteration 12860, loss = -13.7502
Iteration 12870, loss = -12.8597
Iteration 12880, loss = -12.9894
Iteration 12890, loss = -13.3055
Iteration 12900, loss = -13.7423
Iteration 12910, loss = -13.5105
Iteration 12920, loss = -13.5904
Iteration 12930, loss = -13.8771
Iteration 12940, loss = -13.6404
Iteration 12950, loss = -13.2181
Iteration 12960, loss = -14.0813
Iteration 12970, loss = -13.4959
Iteration 12980, loss = -14.0370
Iteration 12990, loss = -13.5838
Iteration 13000, loss = -13.5044
Om: 8.90%, s8: 6.50% accuracy
chi2: 1.902

Starting epoch 9
Iteration 13010, loss = -13.7792
Iteration 13020, loss = -12.6682
Iteration 13030, loss = -13.4474
Iteration 13040, loss = -13.7065
Iteration 13050, loss = -13.2653
Iteration 13060, loss = -13.5204
Iteration 13070, loss = -13.1895
Iteration 13080, loss = -13.4073
Iteration 13090, loss = -13.4166
Iteration 13100, loss = -13.3360
Iteration 13110, loss = -13.3241
Iteration 13120, loss = -13.3988
Iteration 13130, loss = -13.8836
Iteration 13140, loss = -13.4170
Iteration 13150, loss = -13.5372
Iteration 13160, loss = -12.9563
Iteration 13170, loss = -13.1599
Iteration 13180, loss = -13.4595
Iteration 13190, loss = -12.8665
Iteration 13200, loss = -13.2507
Iteration 13210, loss = -13.4950
Iteration 13220, loss = -13.4597
Iteration 13230, loss = -12.8651
Iteration 13240, loss = -12.3093
Iteration 13250, loss = -13.2752
Iteration 13260, loss = -13.3752
Iteration 13270, loss = -13.5009
Iteration 13280, loss = -12.9001
Iteration 13290, loss = -14.0675
Iteration 13300, loss = -13.8858
Iteration 13310, loss = -12.3321
Iteration 13320, loss = -13.1996
Iteration 13330, loss = -13.2610
Iteration 13340, loss = -13.2170
Iteration 13350, loss = -13.7762
Iteration 13360, loss = -13.7283
Iteration 13370, loss = -13.2487
Iteration 13380, loss = -13.7365
Iteration 13390, loss = -13.7816
Iteration 13400, loss = -13.2577
Iteration 13410, loss = -13.2335
Iteration 13420, loss = -13.0257
Iteration 13430, loss = -13.3478
Iteration 13440, loss = -13.3525
Iteration 13450, loss = -13.8785
Iteration 13460, loss = -13.1494
Iteration 13470, loss = -13.8729
Iteration 13480, loss = -13.5554
Iteration 13490, loss = -12.6200
Iteration 13500, loss = -13.6830
Iteration 13510, loss = -13.5440
Iteration 13520, loss = -13.0433
Iteration 13530, loss = -13.4705
Iteration 13540, loss = -13.7686
Iteration 13550, loss = -13.5095
Iteration 13560, loss = -13.3099
Iteration 13570, loss = -13.7566
Iteration 13580, loss = -13.3433
Iteration 13590, loss = -13.9063
Iteration 13600, loss = -13.4083
Iteration 13610, loss = -14.2907
Iteration 13620, loss = -13.7199
Iteration 13630, loss = -13.9773
Iteration 13640, loss = -13.6958
Iteration 13650, loss = -13.2705
Iteration 13660, loss = -13.6167
Iteration 13670, loss = -13.6389
Iteration 13680, loss = -13.4404
Iteration 13690, loss = -13.3049
Iteration 13700, loss = -13.0660
Iteration 13710, loss = -13.4411
Iteration 13720, loss = -13.5861
Iteration 13730, loss = -13.3345
Iteration 13740, loss = -13.6277
Iteration 13750, loss = -14.0363
Iteration 13760, loss = -12.8546
Iteration 13770, loss = -13.4228
Iteration 13780, loss = -13.6652
Iteration 13790, loss = -13.3152
Iteration 13800, loss = -13.6078
Iteration 13810, loss = -12.8423
Iteration 13820, loss = -13.9665
Iteration 13830, loss = -13.4603
Iteration 13840, loss = -13.4651
Iteration 13850, loss = -13.2816
Iteration 13860, loss = -13.1948
Iteration 13870, loss = -13.7004
Iteration 13880, loss = -13.0469
Iteration 13890, loss = -13.5154
Iteration 13900, loss = -13.5042
Iteration 13910, loss = -12.9955
Iteration 13920, loss = -13.7833
Iteration 13930, loss = -13.6529
Iteration 13940, loss = -12.5280
Iteration 13950, loss = -13.7618
Iteration 13960, loss = -13.8284
Iteration 13970, loss = -13.7748
Iteration 13980, loss = -13.2463
Iteration 13990, loss = -14.0208
Iteration 14000, loss = -13.1421
Om: 8.83%, s8: 6.51% accuracy
chi2: 1.795

Iteration 14010, loss = -13.2535
Iteration 14020, loss = -13.6246
Iteration 14030, loss = -13.6965
Iteration 14040, loss = -13.6009
Iteration 14050, loss = -13.3835
Iteration 14060, loss = -12.8878
Iteration 14070, loss = -14.0923
Iteration 14080, loss = -13.3717
Iteration 14090, loss = -12.9018
Iteration 14100, loss = -13.3267
Iteration 14110, loss = -13.4907
Iteration 14120, loss = -13.3114
Iteration 14130, loss = -13.4631
Iteration 14140, loss = -13.6445
Iteration 14150, loss = -13.3969
Iteration 14160, loss = -13.2218
Iteration 14170, loss = -13.4527
Iteration 14180, loss = -13.7215
Iteration 14190, loss = -13.4624
Iteration 14200, loss = -13.7402
Iteration 14210, loss = -13.5604
Iteration 14220, loss = -12.8075
Iteration 14230, loss = -13.3179
Iteration 14240, loss = -13.6372
Iteration 14250, loss = -13.8854
Iteration 14260, loss = -12.6537
Iteration 14270, loss = -13.6747
Iteration 14280, loss = -13.6198
Iteration 14290, loss = -13.4459
Iteration 14300, loss = -13.0749
Iteration 14310, loss = -13.8187
Iteration 14320, loss = -13.4254
Iteration 14330, loss = -13.0601
Iteration 14340, loss = -13.5165
Iteration 14350, loss = -13.5570
Iteration 14360, loss = -12.9706
Iteration 14370, loss = -13.3182
Iteration 14380, loss = -13.1166
Iteration 14390, loss = -13.0805
Iteration 14400, loss = -13.8343
Iteration 14410, loss = -13.4671
Iteration 14420, loss = -14.0530
Iteration 14430, loss = -12.4791
Iteration 14440, loss = -13.3863
Starting epoch 10
Iteration 14450, loss = -13.6384
Iteration 14460, loss = -12.9778
Iteration 14470, loss = -13.1678
Iteration 14480, loss = -13.8392
Iteration 14490, loss = -13.6472
Iteration 14500, loss = -13.6734
Iteration 14510, loss = -13.6683
Iteration 14520, loss = -13.4174
Iteration 14530, loss = -13.3217
Iteration 14540, loss = -13.4837
Iteration 14550, loss = -13.5691
Iteration 14560, loss = -13.9382
Iteration 14570, loss = -13.8626
Iteration 14580, loss = -11.7368
Iteration 14590, loss = -13.8033
Iteration 14600, loss = -13.3186
Iteration 14610, loss = -13.6626
Iteration 14620, loss = -13.2560
Iteration 14630, loss = -13.8163
Iteration 14640, loss = -13.3163
Iteration 14650, loss = -13.4832
Iteration 14660, loss = -13.6284
Iteration 14670, loss = -12.2996
Iteration 14680, loss = -13.2861
Iteration 14690, loss = -12.8028
Iteration 14700, loss = -13.8460
Iteration 14710, loss = -13.2552
Iteration 14720, loss = -13.6368
Iteration 14730, loss = -13.2296
Iteration 14740, loss = -12.7418
Iteration 14750, loss = -13.5320
Iteration 14760, loss = -13.0233
Iteration 14770, loss = -13.8006
Iteration 14780, loss = -13.2152
Iteration 14790, loss = -13.4494
Iteration 14800, loss = -13.5765
Iteration 14810, loss = -13.7264
Iteration 14820, loss = -12.5233
Iteration 14830, loss = -13.3842
Iteration 14840, loss = -13.1192
Iteration 14850, loss = -13.3277
Iteration 14860, loss = -13.7291
Iteration 14870, loss = -13.4840
Iteration 14880, loss = -13.5945
Iteration 14890, loss = -13.3667
Iteration 14900, loss = -13.2012
Iteration 14910, loss = -13.0971
Iteration 14920, loss = -13.2984
Iteration 14930, loss = -13.5654
Iteration 14940, loss = -13.2003
Iteration 14950, loss = -13.4267
Iteration 14960, loss = -13.4027
Iteration 14970, loss = -13.2777
Iteration 14980, loss = -13.1416
Iteration 14990, loss = -13.1322
Iteration 15000, loss = -12.9890
Om: 8.79%, s8: 6.41% accuracy
chi2: 1.584

Iteration 15010, loss = -13.6180
Iteration 15020, loss = -13.6470
Iteration 15030, loss = -13.6354
Iteration 15040, loss = -13.4480
Iteration 15050, loss = -13.6050
Iteration 15060, loss = -13.0757
Iteration 15070, loss = -13.5499
Iteration 15080, loss = -13.8411
Iteration 15090, loss = -13.6085
Iteration 15100, loss = -13.4809
Iteration 15110, loss = -12.9453
Iteration 15120, loss = -13.8048
Iteration 15130, loss = -13.7176
Iteration 15140, loss = -13.4481
Iteration 15150, loss = -14.1643
Iteration 15160, loss = -13.7206
Iteration 15170, loss = -13.6515
Iteration 15180, loss = -14.1473
Iteration 15190, loss = -13.5281
Iteration 15200, loss = -12.7783
Iteration 15210, loss = -13.4386
Iteration 15220, loss = -13.5822
Iteration 15230, loss = -13.9290
Iteration 15240, loss = -13.3007
Iteration 15250, loss = -13.3412
Iteration 15260, loss = -13.5943
Iteration 15270, loss = -13.5560
Iteration 15280, loss = -13.4489
Iteration 15290, loss = -13.2770
Iteration 15300, loss = -13.3177
Iteration 15310, loss = -13.6040
Iteration 15320, loss = -12.7464
Iteration 15330, loss = -13.6842
Iteration 15340, loss = -13.6285
Iteration 15350, loss = -14.0865
Iteration 15360, loss = -12.1667
Iteration 15370, loss = -13.1683
Iteration 15380, loss = -13.5720
Iteration 15390, loss = -12.6630
Iteration 15400, loss = -13.0326
Iteration 15410, loss = -13.5876
Iteration 15420, loss = -13.6144
Iteration 15430, loss = -13.4292
Iteration 15440, loss = -12.2034
Iteration 15450, loss = -13.3497
Iteration 15460, loss = -13.5541
Iteration 15470, loss = -13.8408
Iteration 15480, loss = -12.2499
Iteration 15490, loss = -13.8801
Iteration 15500, loss = -12.9319
Iteration 15510, loss = -13.3655
Iteration 15520, loss = -13.5454
Iteration 15530, loss = -13.2160
Iteration 15540, loss = -12.9314
Iteration 15550, loss = -12.8586
Iteration 15560, loss = -13.8520
Iteration 15570, loss = -14.0464
Iteration 15580, loss = -13.5049
Iteration 15590, loss = -14.0047
Iteration 15600, loss = -13.5908
Iteration 15610, loss = -13.3385
Iteration 15620, loss = -13.6207
Iteration 15630, loss = -13.0557
Iteration 15640, loss = -13.8325
Iteration 15650, loss = -13.3894
Iteration 15660, loss = -13.0966
Iteration 15670, loss = -13.3643
Iteration 15680, loss = -13.7745
Iteration 15690, loss = -13.3984
Iteration 15700, loss = -13.2416
Iteration 15710, loss = -13.2837
Iteration 15720, loss = -12.5647
Iteration 15730, loss = -13.7773
Iteration 15740, loss = -13.8323
Iteration 15750, loss = -13.3342
Iteration 15760, loss = -12.7242
Iteration 15770, loss = -12.7787
Iteration 15780, loss = -13.2644
Iteration 15790, loss = -14.1505
Iteration 15800, loss = -13.7173
Iteration 15810, loss = -13.5274
Iteration 15820, loss = -13.8713
Iteration 15830, loss = -13.5516
Iteration 15840, loss = -12.8920
Iteration 15850, loss = -14.2992
Iteration 15860, loss = -13.6713
Iteration 15870, loss = -14.1044
Iteration 15880, loss = -13.4511
Iteration 15890, loss = -13.9180
Starting epoch 11
Iteration 15900, loss = -13.3654
Iteration 15910, loss = -13.3690
Iteration 15920, loss = -13.5017
Iteration 15930, loss = -13.6987
Iteration 15940, loss = -13.4114
Iteration 15950, loss = -13.7467
Iteration 15960, loss = -13.4207
Iteration 15970, loss = -13.7832
Iteration 15980, loss = -12.9596
Iteration 15990, loss = -14.0577
Iteration 16000, loss = -13.3714
Om: 8.85%, s8: 6.46% accuracy
chi2: 1.751

Iteration 16010, loss = -13.5593
Iteration 16020, loss = -13.8679
Iteration 16030, loss = -13.2668
Iteration 16040, loss = -12.9456
Iteration 16050, loss = -13.0698
Iteration 16060, loss = -13.0492
Iteration 16070, loss = -13.6561
Iteration 16080, loss = -13.1638
Iteration 16090, loss = -13.3122
Iteration 16100, loss = -13.9141
Iteration 16110, loss = -13.6182
Iteration 16120, loss = -13.4644
Iteration 16130, loss = -12.5597
Iteration 16140, loss = -13.3697
Iteration 16150, loss = -13.7736
Iteration 16160, loss = -13.4010
Iteration 16170, loss = -13.1082
Iteration 16180, loss = -14.0946
Iteration 16190, loss = -13.8820
Iteration 16200, loss = -12.9293
Iteration 16210, loss = -13.0671
Iteration 16220, loss = -13.5283
Iteration 16230, loss = -13.3980
Iteration 16240, loss = -13.6327
Iteration 16250, loss = -13.3799
Iteration 16260, loss = -12.7957
Iteration 16270, loss = -14.0631
Iteration 16280, loss = -13.6363
Iteration 16290, loss = -13.2975
Iteration 16300, loss = -13.4024
Iteration 16310, loss = -13.1216
Iteration 16320, loss = -13.4923
Iteration 16330, loss = -13.2707
Iteration 16340, loss = -13.8083
Iteration 16350, loss = -13.4583
Iteration 16360, loss = -13.9263
Iteration 16370, loss = -13.6961
Iteration 16380, loss = -13.0300
Iteration 16390, loss = -14.0328
Iteration 16400, loss = -13.0834
Iteration 16410, loss = -13.0975
Iteration 16420, loss = -13.6434
Iteration 16430, loss = -13.8931
Iteration 16440, loss = -13.9077
Iteration 16450, loss = -12.8182
Iteration 16460, loss = -13.9734
Iteration 16470, loss = -13.1852
Iteration 16480, loss = -13.7970
Iteration 16490, loss = -14.0397
Iteration 16500, loss = -13.9087
Iteration 16510, loss = -13.4941
Iteration 16520, loss = -13.9878
Iteration 16530, loss = -13.6516
Iteration 16540, loss = -13.5789
Iteration 16550, loss = -13.6567
Iteration 16560, loss = -13.4994
Iteration 16570, loss = -13.4220
Iteration 16580, loss = -13.3778
Iteration 16590, loss = -12.9643
Iteration 16600, loss = -13.3631
Iteration 16610, loss = -13.5069
Iteration 16620, loss = -13.2436
Iteration 16630, loss = -13.6512
Iteration 16640, loss = -13.8749
Iteration 16650, loss = -13.2720
Iteration 16660, loss = -13.1624
Iteration 16670, loss = -13.6021
Iteration 16680, loss = -13.4671
Iteration 16690, loss = -13.4205
Iteration 16700, loss = -13.4461
Iteration 16710, loss = -14.1086
Iteration 16720, loss = -13.5948
Iteration 16730, loss = -13.1484
Iteration 16740, loss = -13.1950
Iteration 16750, loss = -13.5142
Iteration 16760, loss = -13.4902
Iteration 16770, loss = -13.3631
Iteration 16780, loss = -13.8366
Iteration 16790, loss = -13.8914
Iteration 16800, loss = -13.3625
Iteration 16810, loss = -13.3665
Iteration 16820, loss = -13.1588
Iteration 16830, loss = -12.7817
Iteration 16840, loss = -13.9782
Iteration 16850, loss = -14.1813
Iteration 16860, loss = -13.3809
Iteration 16870, loss = -13.3331
Iteration 16880, loss = -13.4167
Iteration 16890, loss = -13.0434
Iteration 16900, loss = -13.6737
Iteration 16910, loss = -13.2822
Iteration 16920, loss = -13.8498
Iteration 16930, loss = -13.4595
Iteration 16940, loss = -13.6911
Iteration 16950, loss = -13.0841
Iteration 16960, loss = -13.8324
Iteration 16970, loss = -12.9120
Iteration 16980, loss = -13.0465
Iteration 16990, loss = -13.1569
Iteration 17000, loss = -13.2180
Om: 8.92%, s8: 6.51% accuracy
chi2: 1.329

Iteration 17010, loss = -13.2961
Iteration 17020, loss = -13.8400
Iteration 17030, loss = -13.6733
Iteration 17040, loss = -13.4975
Iteration 17050, loss = -13.4419
Iteration 17060, loss = -13.3310
Iteration 17070, loss = -13.3303
Iteration 17080, loss = -13.9089
Iteration 17090, loss = -13.8778
Iteration 17100, loss = -13.9244
Iteration 17110, loss = -12.9714
Iteration 17120, loss = -13.6126
Iteration 17130, loss = -13.5862
Iteration 17140, loss = -13.6779
Iteration 17150, loss = -12.6567
Iteration 17160, loss = -13.9539
Iteration 17170, loss = -14.0035
Iteration 17180, loss = -13.2563
Iteration 17190, loss = -13.3766
Iteration 17200, loss = -14.1200
Iteration 17210, loss = -13.4824
Iteration 17220, loss = -13.4206
Iteration 17230, loss = -13.4816
Iteration 17240, loss = -13.4337
Iteration 17250, loss = -12.8452
Iteration 17260, loss = -13.2795
Iteration 17270, loss = -13.3988
Iteration 17280, loss = -13.3820
Iteration 17290, loss = -13.5931
Iteration 17300, loss = -13.6908
Iteration 17310, loss = -14.0185
Iteration 17320, loss = -12.5241
Iteration 17330, loss = -13.1827
Starting epoch 12
Iteration 17340, loss = -14.0279
Iteration 17350, loss = -13.2915
Iteration 17360, loss = -13.0980
Iteration 17370, loss = -13.8561
Iteration 17380, loss = -13.4790
Iteration 17390, loss = -13.6618
Iteration 17400, loss = -13.9460
Iteration 17410, loss = -13.9849
Iteration 17420, loss = -13.3005
Iteration 17430, loss = -13.9993
Iteration 17440, loss = -13.8729
Iteration 17450, loss = -13.6998
Iteration 17460, loss = -13.4668
Iteration 17470, loss = -12.8991
Iteration 17480, loss = -13.6360
Iteration 17490, loss = -13.3017
Iteration 17500, loss = -13.6979
Iteration 17510, loss = -13.2634
Iteration 17520, loss = -13.8853
Iteration 17530, loss = -13.6423
Iteration 17540, loss = -13.4789
Iteration 17550, loss = -13.4962
Iteration 17560, loss = -12.5907
Iteration 17570, loss = -13.5024
Iteration 17580, loss = -12.8500
Iteration 17590, loss = -13.7782
Iteration 17600, loss = -12.8706
Iteration 17610, loss = -13.4255
Iteration 17620, loss = -13.6164
Iteration 17630, loss = -13.5912
Iteration 17640, loss = -13.4593
Iteration 17650, loss = -12.9772
Iteration 17660, loss = -13.4879
Iteration 17670, loss = -13.2035
Iteration 17680, loss = -13.5883
Iteration 17690, loss = -13.6862
Iteration 17700, loss = -13.6098
Iteration 17710, loss = -13.4338
Iteration 17720, loss = -13.3132
Iteration 17730, loss = -13.2031
Iteration 17740, loss = -13.7412
Iteration 17750, loss = -13.6160
Iteration 17760, loss = -13.6383
Iteration 17770, loss = -13.5098
Iteration 17780, loss = -13.5665
Iteration 17790, loss = -13.2712
Iteration 17800, loss = -13.4749
Iteration 17810, loss = -13.2737
Iteration 17820, loss = -13.3809
Iteration 17830, loss = -13.0070
Iteration 17840, loss = -13.6282
Iteration 17850, loss = -13.3757
Iteration 17860, loss = -13.2044
Iteration 17870, loss = -13.3116
Iteration 17880, loss = -13.6596
Iteration 17890, loss = -13.0198
Iteration 17900, loss = -13.9378
Iteration 17910, loss = -13.7430
Iteration 17920, loss = -13.7243
Iteration 17930, loss = -13.2028
Iteration 17940, loss = -13.6390
Iteration 17950, loss = -13.0402
Iteration 17960, loss = -13.5574
Iteration 17970, loss = -13.8967
Iteration 17980, loss = -13.8344
Iteration 17990, loss = -13.8771
Iteration 18000, loss = -13.0924
Om: 8.87%, s8: 6.43% accuracy
chi2: 1.453

Iteration 18010, loss = -13.7897
Iteration 18020, loss = -13.6161
Iteration 18030, loss = -13.8213
Iteration 18040, loss = -14.1123
Iteration 18050, loss = -13.7545
Iteration 18060, loss = -13.8023
Iteration 18070, loss = -13.8566
Iteration 18080, loss = -13.3504
Iteration 18090, loss = -12.7403
Iteration 18100, loss = -13.6844
Iteration 18110, loss = -13.8434
Iteration 18120, loss = -14.0919
Iteration 18130, loss = -13.4877
Iteration 18140, loss = -13.3402
Iteration 18150, loss = -13.6306
Iteration 18160, loss = -13.4018
Iteration 18170, loss = -13.4628
Iteration 18180, loss = -13.6655
Iteration 18190, loss = -13.5038
Iteration 18200, loss = -13.8334
Iteration 18210, loss = -13.4073
Iteration 18220, loss = -14.0568
Iteration 18230, loss = -13.7321
Iteration 18240, loss = -13.8864
Iteration 18250, loss = -13.1084
Iteration 18260, loss = -13.5695
Iteration 18270, loss = -13.7645
Iteration 18280, loss = -12.7881
Iteration 18290, loss = -13.3908
Iteration 18300, loss = -13.5809
Iteration 18310, loss = -13.8554
Iteration 18320, loss = -13.0835
Iteration 18330, loss = -13.2017
Iteration 18340, loss = -13.6652
Iteration 18350, loss = -13.5541
Iteration 18360, loss = -13.8120
Iteration 18370, loss = -12.9472
Iteration 18380, loss = -14.0897
Iteration 18390, loss = -13.3248
Iteration 18400, loss = -13.3768
Iteration 18410, loss = -13.6203
Iteration 18420, loss = -12.9101
Iteration 18430, loss = -13.3012
Iteration 18440, loss = -13.1893
Iteration 18450, loss = -13.7291
Iteration 18460, loss = -13.9681
Iteration 18470, loss = -13.7383
Iteration 18480, loss = -14.2108
Iteration 18490, loss = -13.5047
Iteration 18500, loss = -13.4462
Iteration 18510, loss = -13.7197
Iteration 18520, loss = -13.1640
Iteration 18530, loss = -13.6965
Iteration 18540, loss = -13.8529
Iteration 18550, loss = -13.2403
Iteration 18560, loss = -13.6589
Iteration 18570, loss = -13.8123
Iteration 18580, loss = -13.4491
Iteration 18590, loss = -12.8888
Iteration 18600, loss = -13.2473
Iteration 18610, loss = -12.4967
Iteration 18620, loss = -13.7210
Iteration 18630, loss = -13.8577
Iteration 18640, loss = -13.8758
Iteration 18650, loss = -13.3172
Iteration 18660, loss = -12.6229
Iteration 18670, loss = -13.4676
Iteration 18680, loss = -13.8640
Iteration 18690, loss = -13.7605
Iteration 18700, loss = -13.5773
Iteration 18710, loss = -13.7029
Iteration 18720, loss = -13.6283
Iteration 18730, loss = -13.1762
Iteration 18740, loss = -14.0193
Iteration 18750, loss = -13.7864
Iteration 18760, loss = -13.9518
Iteration 18770, loss = -13.3489
Iteration 18780, loss = -14.0636
Starting epoch 13
Iteration 18790, loss = -13.5997
Iteration 18800, loss = -13.8792
Iteration 18810, loss = -13.5497
Iteration 18820, loss = -13.7627
Iteration 18830, loss = -13.7584
Iteration 18840, loss = -13.7486
Iteration 18850, loss = -13.1629
Iteration 18860, loss = -13.5627
Iteration 18870, loss = -13.4705
Iteration 18880, loss = -13.8400
Iteration 18890, loss = -13.5526
Iteration 18900, loss = -13.8621
Iteration 18910, loss = -14.1800
Iteration 18920, loss = -13.7710
Iteration 18930, loss = -13.6512
Iteration 18940, loss = -13.3738
Iteration 18950, loss = -12.9741
Iteration 18960, loss = -13.6753
Iteration 18970, loss = -13.0426
Iteration 18980, loss = -13.6023
Iteration 18990, loss = -13.7765
Iteration 19000, loss = -13.4164
Om: 8.76%, s8: 6.36% accuracy
chi2: 1.422

Iteration 19010, loss = -13.6649
Iteration 19020, loss = -13.1818
Iteration 19030, loss = -13.5177
Iteration 19040, loss = -13.7251
Iteration 19050, loss = -13.5494
Iteration 19060, loss = -13.2460
Iteration 19070, loss = -14.3148
Iteration 19080, loss = -13.8977
Iteration 19090, loss = -13.3337
Iteration 19100, loss = -13.0335
Iteration 19110, loss = -13.4484
Iteration 19120, loss = -13.5051
Iteration 19130, loss = -13.7811
Iteration 19140, loss = -13.4480
Iteration 19150, loss = -13.3197
Iteration 19160, loss = -13.6286
Iteration 19170, loss = -13.7803
Iteration 19180, loss = -13.5892
Iteration 19190, loss = -13.7417
Iteration 19200, loss = -13.2100
Iteration 19210, loss = -14.0548
Iteration 19220, loss = -13.6633
Iteration 19230, loss = -13.6515
Iteration 19240, loss = -13.2801
Iteration 19250, loss = -13.9785
Iteration 19260, loss = -13.4854
Iteration 19270, loss = -13.0898
Iteration 19280, loss = -14.1247
Iteration 19290, loss = -13.3604
Iteration 19300, loss = -13.7178
Iteration 19310, loss = -13.5902
Iteration 19320, loss = -13.7571
Iteration 19330, loss = -13.9408
Iteration 19340, loss = -13.2046
Iteration 19350, loss = -13.6761
Iteration 19360, loss = -13.7368
Iteration 19370, loss = -13.5979
Iteration 19380, loss = -13.7089
Iteration 19390, loss = -14.0179
Iteration 19400, loss = -13.9927
Iteration 19410, loss = -13.6182
Iteration 19420, loss = -13.7912
Iteration 19430, loss = -13.4980
Iteration 19440, loss = -13.9534
Iteration 19450, loss = -13.5644
Iteration 19460, loss = -13.4508
Iteration 19470, loss = -13.2023
Iteration 19480, loss = -13.0869
Iteration 19490, loss = -13.4247
Iteration 19500, loss = -13.7113
Iteration 19510, loss = -13.5662
Iteration 19520, loss = -13.3306
Iteration 19530, loss = -13.8069
Iteration 19540, loss = -13.0771
Iteration 19550, loss = -13.1397
Iteration 19560, loss = -13.7371
Iteration 19570, loss = -13.7340
Iteration 19580, loss = -13.5142
Iteration 19590, loss = -12.8138
Iteration 19600, loss = -13.9282
Iteration 19610, loss = -13.6869
Iteration 19620, loss = -13.1076
Iteration 19630, loss = -13.5090
Iteration 19640, loss = -12.8324
Iteration 19650, loss = -13.4921
Iteration 19660, loss = -13.4924
Iteration 19670, loss = -13.6918
Iteration 19680, loss = -13.6408
Iteration 19690, loss = -13.7868
Iteration 19700, loss = -13.3400
Iteration 19710, loss = -13.4006
Iteration 19720, loss = -13.2251
Iteration 19730, loss = -13.9556
Iteration 19740, loss = -13.9493
Iteration 19750, loss = -13.6451
Iteration 19760, loss = -13.6149
Iteration 19770, loss = -13.8639
Iteration 19780, loss = -13.3339
Iteration 19790, loss = -13.7125
Iteration 19800, loss = -13.4482
Iteration 19810, loss = -13.8903
Iteration 19820, loss = -13.5189
Iteration 19830, loss = -13.8352
Iteration 19840, loss = -13.1481
Iteration 19850, loss = -13.8632
Iteration 19860, loss = -12.9980
Iteration 19870, loss = -13.3072
Iteration 19880, loss = -13.2892
Iteration 19890, loss = -13.8189
Iteration 19900, loss = -13.5009
Iteration 19910, loss = -13.7153
Iteration 19920, loss = -13.8071
Iteration 19930, loss = -13.3239
Iteration 19940, loss = -13.4197
Iteration 19950, loss = -13.2939
Iteration 19960, loss = -13.0667
Iteration 19970, loss = -13.9531
Iteration 19980, loss = -13.5157
Iteration 19990, loss = -13.7466
Iteration 20000, loss = -13.3630
Om: 8.75%, s8: 6.33% accuracy
chi2: 1.807

Iteration 20010, loss = -13.6373
Iteration 20020, loss = -13.5363
Iteration 20030, loss = -13.4697
Iteration 20040, loss = -13.2692
Iteration 20050, loss = -13.9478
Iteration 20060, loss = -13.6551
Iteration 20070, loss = -13.4352
Iteration 20080, loss = -13.5245
Iteration 20090, loss = -14.0004
Iteration 20100, loss = -13.1751
Iteration 20110, loss = -12.9425
Iteration 20120, loss = -13.5230
Iteration 20130, loss = -13.5105
Iteration 20140, loss = -13.3631
Iteration 20150, loss = -13.5399
Iteration 20160, loss = -12.9558
Iteration 20170, loss = -13.2225
Iteration 20180, loss = -13.5849
Iteration 20190, loss = -13.7103
Iteration 20200, loss = -14.1249
Iteration 20210, loss = -12.6723
Iteration 20220, loss = -13.3665
Starting epoch 14
Iteration 20230, loss = -14.0566
Iteration 20240, loss = -12.9400
Iteration 20250, loss = -13.0729
Iteration 20260, loss = -13.8808
Iteration 20270, loss = -13.6705
Iteration 20280, loss = -13.9676
Iteration 20290, loss = -13.7768
Iteration 20300, loss = -13.3191
Iteration 20310, loss = -13.2842
Iteration 20320, loss = -13.6289
Iteration 20330, loss = -13.8161
Iteration 20340, loss = -13.6373
Iteration 20350, loss = -13.8280
Iteration 20360, loss = -12.7317
Iteration 20370, loss = -13.7292
Iteration 20380, loss = -13.2110
Iteration 20390, loss = -13.7686
Iteration 20400, loss = -13.1692
Iteration 20410, loss = -13.9534
Iteration 20420, loss = -13.6277
Iteration 20430, loss = -13.5411
Iteration 20440, loss = -13.6471
Iteration 20450, loss = -12.8171
Iteration 20460, loss = -13.4006
Iteration 20470, loss = -12.9816
Iteration 20480, loss = -14.0095
Iteration 20490, loss = -12.8890
Iteration 20500, loss = -13.4193
Iteration 20510, loss = -13.3335
Iteration 20520, loss = -13.3909
Iteration 20530, loss = -13.4203
Iteration 20540, loss = -12.9945
Iteration 20550, loss = -13.8203
Iteration 20560, loss = -13.5666
Iteration 20570, loss = -13.4619
Iteration 20580, loss = -13.9982
Iteration 20590, loss = -13.6976
Iteration 20600, loss = -12.9763
Iteration 20610, loss = -13.4713
Iteration 20620, loss = -13.3051
Iteration 20630, loss = -13.5806
Iteration 20640, loss = -13.4863
Iteration 20650, loss = -13.4268
Iteration 20660, loss = -13.6554
Iteration 20670, loss = -13.7194
Iteration 20680, loss = -13.0856
Iteration 20690, loss = -13.5638
Iteration 20700, loss = -13.5650
Iteration 20710, loss = -13.2045
Iteration 20720, loss = -13.1849
Iteration 20730, loss = -13.8216
Iteration 20740, loss = -13.8277
Iteration 20750, loss = -13.4996
Iteration 20760, loss = -13.4883
Iteration 20770, loss = -13.7973
Iteration 20780, loss = -12.4792
Iteration 20790, loss = -13.8316
Iteration 20800, loss = -13.7747
Iteration 20810, loss = -14.2866
Iteration 20820, loss = -13.5134
Iteration 20830, loss = -13.4493
Iteration 20840, loss = -13.1289
Iteration 20850, loss = -13.5488
Iteration 20860, loss = -13.7499
Iteration 20870, loss = -13.5278
Iteration 20880, loss = -13.5757
Iteration 20890, loss = -13.0235
Iteration 20900, loss = -13.8747
Iteration 20910, loss = -13.4056
Iteration 20920, loss = -14.0241
Iteration 20930, loss = -14.1789
Iteration 20940, loss = -13.7388
Iteration 20950, loss = -13.9563
Iteration 20960, loss = -14.0098
Iteration 20970, loss = -13.5563
Iteration 20980, loss = -13.1897
Iteration 20990, loss = -13.8855
Iteration 21000, loss = -13.3675
Om: 8.74%, s8: 6.39% accuracy
chi2: 1.850

Iteration 21010, loss = -13.9839
Iteration 21020, loss = -13.3602
Iteration 21030, loss = -13.7125
Iteration 21040, loss = -13.7836
Iteration 21050, loss = -13.4040
Iteration 21060, loss = -13.2367
Iteration 21070, loss = -13.7325
Iteration 21080, loss = -13.2615
Iteration 21090, loss = -13.4465
Iteration 21100, loss = -13.7083
Iteration 21110, loss = -13.4649
Iteration 21120, loss = -13.3356
Iteration 21130, loss = -13.6527
Iteration 21140, loss = -13.2485
Iteration 21150, loss = -13.3876
Iteration 21160, loss = -13.5129
Iteration 21170, loss = -13.2011
Iteration 21180, loss = -13.2587
Iteration 21190, loss = -13.6622
Iteration 21200, loss = -13.7836
Iteration 21210, loss = -13.5980
Iteration 21220, loss = -13.0872
Iteration 21230, loss = -13.7095
Iteration 21240, loss = -13.5808
Iteration 21250, loss = -13.5510
Iteration 21260, loss = -13.0488
Iteration 21270, loss = -13.8783
Iteration 21280, loss = -12.9132
Iteration 21290, loss = -12.9134
Iteration 21300, loss = -13.6739
Iteration 21310, loss = -13.1784
Iteration 21320, loss = -13.7283
Iteration 21330, loss = -13.1171
Iteration 21340, loss = -13.6212
Iteration 21350, loss = -13.8884
Iteration 21360, loss = -13.6753
Iteration 21370, loss = -14.0464
Iteration 21380, loss = -13.6258
Iteration 21390, loss = -13.3710
Iteration 21400, loss = -13.7062
Iteration 21410, loss = -13.3420
Iteration 21420, loss = -13.7319
Iteration 21430, loss = -13.8933
Iteration 21440, loss = -12.8304
Iteration 21450, loss = -13.7602
Iteration 21460, loss = -13.6937
Iteration 21470, loss = -13.2171
Iteration 21480, loss = -13.4677
Iteration 21490, loss = -13.4927
Iteration 21500, loss = -12.6385
Iteration 21510, loss = -13.7217
Iteration 21520, loss = -13.7179
Iteration 21530, loss = -13.6184
Iteration 21540, loss = -13.0407
Iteration 21550, loss = -12.8374
Iteration 21560, loss = -13.6304
Iteration 21570, loss = -14.1686
Iteration 21580, loss = -13.2557
Iteration 21590, loss = -13.8659
Iteration 21600, loss = -13.8724
Iteration 21610, loss = -13.2261
Iteration 21620, loss = -12.9932
Iteration 21630, loss = -14.1782
Iteration 21640, loss = -13.8137
Iteration 21650, loss = -14.1924
Iteration 21660, loss = -13.7593
Iteration 21670, loss = -13.8873
Starting epoch 15
Iteration 21680, loss = -13.1820
Iteration 21690, loss = -13.5256
Iteration 21700, loss = -13.7013
Iteration 21710, loss = -13.6381
Iteration 21720, loss = -13.8707
Iteration 21730, loss = -13.9753
Iteration 21740, loss = -13.4414
Iteration 21750, loss = -13.8793
Iteration 21760, loss = -13.6081
Iteration 21770, loss = -13.9752
Iteration 21780, loss = -13.4299
Iteration 21790, loss = -13.8082
Iteration 21800, loss = -13.9406
Iteration 21810, loss = -13.5583
Iteration 21820, loss = -13.1031
Iteration 21830, loss = -13.3853
Iteration 21840, loss = -13.0168
Iteration 21850, loss = -13.9086
Iteration 21860, loss = -13.1514
Iteration 21870, loss = -13.9233
Iteration 21880, loss = -13.9604
Iteration 21890, loss = -13.5933
Iteration 21900, loss = -13.6457
Iteration 21910, loss = -12.3896
Iteration 21920, loss = -13.7607
Iteration 21930, loss = -13.5734
Iteration 21940, loss = -13.7756
Iteration 21950, loss = -13.1962
Iteration 21960, loss = -14.2212
Iteration 21970, loss = -13.8818
Iteration 21980, loss = -12.9992
Iteration 21990, loss = -13.3969
Iteration 22000, loss = -13.7676
Om: 8.66%, s8: 6.31% accuracy
chi2: 1.867

Iteration 22010, loss = -13.5963
Iteration 22020, loss = -14.0762
Iteration 22030, loss = -13.6764
Iteration 22040, loss = -13.3746
Iteration 22050, loss = -13.8628
Iteration 22060, loss = -13.9397
Iteration 22070, loss = -13.1478
Iteration 22080, loss = -13.5735
Iteration 22090, loss = -13.3183
Iteration 22100, loss = -13.7783
Iteration 22110, loss = -13.8958
Iteration 22120, loss = -13.9887
Iteration 22130, loss = -13.1677
Iteration 22140, loss = -13.8295
Iteration 22150, loss = -13.7490
Iteration 22160, loss = -12.6485
Iteration 22170, loss = -13.9603
Iteration 22180, loss = -13.4282
Iteration 22190, loss = -13.6329
Iteration 22200, loss = -13.7862
Iteration 22210, loss = -13.9746
Iteration 22220, loss = -13.8105
Iteration 22230, loss = -12.9924
Iteration 22240, loss = -14.1789
Iteration 22250, loss = -13.7470
Iteration 22260, loss = -14.0912
Iteration 22270, loss = -13.9259
Iteration 22280, loss = -14.0064
Iteration 22290, loss = -13.8072
Iteration 22300, loss = -14.0116
Iteration 22310, loss = -13.7814
Iteration 22320, loss = -13.4666
Iteration 22330, loss = -13.4678
Iteration 22340, loss = -13.6487
Iteration 22350, loss = -13.5359
Iteration 22360, loss = -13.5953
Iteration 22370, loss = -13.4039
Iteration 22380, loss = -13.3842
Iteration 22390, loss = -13.8221
Iteration 22400, loss = -13.5337
Iteration 22410, loss = -13.4662
Iteration 22420, loss = -14.1931
Iteration 22430, loss = -13.4912
Iteration 22440, loss = -13.1115
Iteration 22450, loss = -13.7897
Iteration 22460, loss = -13.5407
Iteration 22470, loss = -13.6220
Iteration 22480, loss = -13.1793
Iteration 22490, loss = -14.0293
Iteration 22500, loss = -13.7402
Iteration 22510, loss = -13.3911
Iteration 22520, loss = -13.7472
Iteration 22530, loss = -13.6497
Iteration 22540, loss = -13.4705
Iteration 22550, loss = -13.7023
Iteration 22560, loss = -13.9349
Iteration 22570, loss = -13.6748
Iteration 22580, loss = -13.5569
Iteration 22590, loss = -13.5564
Iteration 22600, loss = -13.5410
Iteration 22610, loss = -13.2130
Iteration 22620, loss = -14.0763
Iteration 22630, loss = -14.0134
Iteration 22640, loss = -13.8955
Iteration 22650, loss = -13.1775
Iteration 22660, loss = -13.5877
Iteration 22670, loss = -13.4098
Iteration 22680, loss = -13.7078
Iteration 22690, loss = -13.7060
Iteration 22700, loss = -13.8015
Iteration 22710, loss = -13.7604
Iteration 22720, loss = -13.6918
Iteration 22730, loss = -12.7236
Iteration 22740, loss = -14.1359
Iteration 22750, loss = -13.2488
Iteration 22760, loss = -13.1487
Iteration 22770, loss = -12.8643
Iteration 22780, loss = -13.4541
Iteration 22790, loss = -13.5069
Iteration 22800, loss = -14.0424
Iteration 22810, loss = -13.6653
Iteration 22820, loss = -13.4448
Iteration 22830, loss = -13.4464
Iteration 22840, loss = -13.4977
Iteration 22850, loss = -13.5950
Iteration 22860, loss = -13.9705
Iteration 22870, loss = -13.7854
Iteration 22880, loss = -13.5372
Iteration 22890, loss = -13.0108
Iteration 22900, loss = -13.7421
Iteration 22910, loss = -13.5387
Iteration 22920, loss = -13.9071
Iteration 22930, loss = -13.0117
Iteration 22940, loss = -13.7213
Iteration 22950, loss = -13.7304
Iteration 22960, loss = -13.3268
Iteration 22970, loss = -13.4010
Iteration 22980, loss = -14.2576
Iteration 22990, loss = -13.7701
Iteration 23000, loss = -13.3272
Om: 9.03%, s8: 6.71% accuracy
chi2: 1.651

Iteration 23010, loss = -13.6538
Iteration 23020, loss = -13.2206
Iteration 23030, loss = -13.0272
Iteration 23040, loss = -13.2701
Iteration 23050, loss = -13.2755
Iteration 23060, loss = -13.5640
Iteration 23070, loss = -13.7383
Iteration 23080, loss = -13.6867
Iteration 23090, loss = -14.0641
Iteration 23100, loss = -12.2302
Iteration 23110, loss = -13.6289
Starting epoch 16
Iteration 23120, loss = -14.0067
Iteration 23130, loss = -13.1534
Iteration 23140, loss = -13.0803
Iteration 23150, loss = -13.4697
Iteration 23160, loss = -13.6197
Iteration 23170, loss = -13.9485
Iteration 23180, loss = -13.7567
Iteration 23190, loss = -13.9928
Iteration 23200, loss = -13.5822
Iteration 23210, loss = -13.5127
Iteration 23220, loss = -13.8989
Iteration 23230, loss = -14.0003
Iteration 23240, loss = -13.9667
Iteration 23250, loss = -12.7918
Iteration 23260, loss = -13.7917
Iteration 23270, loss = -13.4052
Iteration 23280, loss = -14.0701
Iteration 23290, loss = -13.4898
Iteration 23300, loss = -13.9167
Iteration 23310, loss = -13.8655
Iteration 23320, loss = -13.5695
Iteration 23330, loss = -13.5581
Iteration 23340, loss = -12.4518
Iteration 23350, loss = -13.6132
Iteration 23360, loss = -12.9291
Iteration 23370, loss = -13.8382
Iteration 23380, loss = -12.7752
Iteration 23390, loss = -13.6366
Iteration 23400, loss = -13.4837
Iteration 23410, loss = -13.6360
Iteration 23420, loss = -13.5300
Iteration 23430, loss = -13.3950
Iteration 23440, loss = -13.9729
Iteration 23450, loss = -13.5277
Iteration 23460, loss = -13.8209
Iteration 23470, loss = -13.5755
Iteration 23480, loss = -14.1214
Iteration 23490, loss = -13.1090
Iteration 23500, loss = -13.5949
Iteration 23510, loss = -13.3558
Iteration 23520, loss = -13.6322
Iteration 23530, loss = -13.4720
Iteration 23540, loss = -13.5661
Iteration 23550, loss = -13.6205
Iteration 23560, loss = -13.6082
Iteration 23570, loss = -13.3914
Iteration 23580, loss = -12.8359
Iteration 23590, loss = -13.4099
Iteration 23600, loss = -13.2864
Iteration 23610, loss = -13.0658
Iteration 23620, loss = -14.0663
Iteration 23630, loss = -13.7498
Iteration 23640, loss = -13.4002
Iteration 23650, loss = -13.2877
Iteration 23660, loss = -13.6251
Iteration 23670, loss = -13.1905
Iteration 23680, loss = -13.8994
Iteration 23690, loss = -13.8532
Iteration 23700, loss = -13.9876
Iteration 23710, loss = -13.8012
Iteration 23720, loss = -13.5323
Iteration 23730, loss = -13.3276
Iteration 23740, loss = -13.7495
Iteration 23750, loss = -13.6776
Iteration 23760, loss = -13.8307
Iteration 23770, loss = -13.4422
Iteration 23780, loss = -13.1357
Iteration 23790, loss = -13.4520
Iteration 23800, loss = -13.3694
Iteration 23810, loss = -13.8331
Iteration 23820, loss = -14.2141
Iteration 23830, loss = -13.8047
Iteration 23840, loss = -13.9562
Iteration 23850, loss = -14.2302
Iteration 23860, loss = -13.7640
Iteration 23870, loss = -13.2735
Iteration 23880, loss = -13.8412
Iteration 23890, loss = -13.7235
Iteration 23900, loss = -14.1943
Iteration 23910, loss = -13.6579
Iteration 23920, loss = -13.3390
Iteration 23930, loss = -13.7230
Iteration 23940, loss = -13.4560
Iteration 23950, loss = -13.5969
Iteration 23960, loss = -13.7092
Iteration 23970, loss = -13.1573
Iteration 23980, loss = -13.8470
Iteration 23990, loss = -13.4253
Iteration 24000, loss = -13.9902
Om: 8.48%, s8: 6.18% accuracy
chi2: 1.362

Iteration 24010, loss = -13.3451
Iteration 24020, loss = -14.1756
Iteration 24030, loss = -13.3841
Iteration 24040, loss = -13.5597
Iteration 24050, loss = -13.4165
Iteration 24060, loss = -13.0349
Iteration 24070, loss = -13.4104
Iteration 24080, loss = -13.7228
Iteration 24090, loss = -13.7097
Iteration 24100, loss = -13.5350
Iteration 24110, loss = -13.1072
Iteration 24120, loss = -13.7740
Iteration 24130, loss = -13.7709
Iteration 24140, loss = -13.6802
Iteration 24150, loss = -13.2165
Iteration 24160, loss = -14.3130
Iteration 24170, loss = -13.5828
Iteration 24180, loss = -13.5496
Iteration 24190, loss = -13.7398
Iteration 24200, loss = -13.5243
Iteration 24210, loss = -13.3811
Iteration 24220, loss = -12.7438
Iteration 24230, loss = -13.4919
Iteration 24240, loss = -14.0006
Iteration 24250, loss = -13.7104
Iteration 24260, loss = -14.4365
Iteration 24270, loss = -13.5261
Iteration 24280, loss = -13.9403
Iteration 24290, loss = -13.8427
Iteration 24300, loss = -13.2531
Iteration 24310, loss = -13.8002
Iteration 24320, loss = -13.7448
Iteration 24330, loss = -13.2804
Iteration 24340, loss = -13.4537
Iteration 24350, loss = -13.3333
Iteration 24360, loss = -13.6266
Iteration 24370, loss = -13.2176
Iteration 24380, loss = -13.3906
Iteration 24390, loss = -12.9203
Iteration 24400, loss = -13.7817
Iteration 24410, loss = -14.0498
Iteration 24420, loss = -13.4272
Iteration 24430, loss = -13.0897
Iteration 24440, loss = -12.9840
Iteration 24450, loss = -13.8946
Iteration 24460, loss = -14.0205
Iteration 24470, loss = -13.9660
Iteration 24480, loss = -13.9330
Iteration 24490, loss = -13.9868
Iteration 24500, loss = -13.4767
Iteration 24510, loss = -13.4751
Iteration 24520, loss = -13.8748
Iteration 24530, loss = -13.6752
Iteration 24540, loss = -14.2802
Iteration 24550, loss = -13.6113
Iteration 24560, loss = -13.9187
Starting epoch 17
Iteration 24570, loss = -13.7085
Iteration 24580, loss = -13.9304
Iteration 24590, loss = -13.9406
Iteration 24600, loss = -14.1566
Iteration 24610, loss = -13.7190
Iteration 24620, loss = -13.7904
Iteration 24630, loss = -13.4366
Iteration 24640, loss = -13.8818
Iteration 24650, loss = -13.5031
Iteration 24660, loss = -14.2483
Iteration 24670, loss = -13.5458
Iteration 24680, loss = -13.5140
Iteration 24690, loss = -14.1711
Iteration 24700, loss = -14.0358
Iteration 24710, loss = -12.7758
Iteration 24720, loss = -13.1874
Iteration 24730, loss = -13.3029
Iteration 24740, loss = -13.7688
Iteration 24750, loss = -13.3150
Iteration 24760, loss = -14.0041
Iteration 24770, loss = -13.7594
Iteration 24780, loss = -13.6909
Iteration 24790, loss = -13.5554
Iteration 24800, loss = -12.9747
Iteration 24810, loss = -13.7626
Iteration 24820, loss = -13.8467
Iteration 24830, loss = -13.6697
Iteration 24840, loss = -13.1082
Iteration 24850, loss = -14.3603
Iteration 24860, loss = -14.0644
Iteration 24870, loss = -13.1474
Iteration 24880, loss = -13.6493
Iteration 24890, loss = -13.4823
Iteration 24900, loss = -13.7315
Iteration 24910, loss = -13.7217
Iteration 24920, loss = -13.8413
Iteration 24930, loss = -13.6194
Iteration 24940, loss = -13.7463
Iteration 24950, loss = -13.7841
Iteration 24960, loss = -13.7426
Iteration 24970, loss = -13.8679
Iteration 24980, loss = -13.5187
Iteration 24990, loss = -14.0873
Iteration 25000, loss = -13.6385
Om: 8.25%, s8: 6.04% accuracy
chi2: 1.860

Iteration 25010, loss = -13.8115
Iteration 25020, loss = -13.5908
Iteration 25030, loss = -13.8957
Iteration 25040, loss = -13.5183
Iteration 25050, loss = -13.3898
Iteration 25060, loss = -13.8896
Iteration 25070, loss = -13.3394
Iteration 25080, loss = -13.2963
Iteration 25090, loss = -13.8072
Iteration 25100, loss = -14.1653
Iteration 25110, loss = -14.1821
Iteration 25120, loss = -13.0924
Iteration 25130, loss = -14.0970
Iteration 25140, loss = -13.7009
Iteration 25150, loss = -13.6640
Iteration 25160, loss = -13.7003
Iteration 25170, loss = -14.2129
Iteration 25180, loss = -13.9590
Iteration 25190, loss = -14.0283
Iteration 25200, loss = -13.6471
Iteration 25210, loss = -13.6537
Iteration 25220, loss = -13.5098
Iteration 25230, loss = -13.5507
Iteration 25240, loss = -13.8632
Iteration 25250, loss = -13.7233
Iteration 25260, loss = -13.3739
Iteration 25270, loss = -13.4147
Iteration 25280, loss = -13.7971
Iteration 25290, loss = -13.8738
Iteration 25300, loss = -13.6512
Iteration 25310, loss = -14.2213
Iteration 25320, loss = -13.0415
Iteration 25330, loss = -13.1768
Iteration 25340, loss = -14.0247
Iteration 25350, loss = -13.6315
Iteration 25360, loss = -13.6497
Iteration 25370, loss = -13.5299
Iteration 25380, loss = -14.0675
Iteration 25390, loss = -13.6032
Iteration 25400, loss = -13.5384
Iteration 25410, loss = -13.4098
Iteration 25420, loss = -13.7021
Iteration 25430, loss = -13.5491
Iteration 25440, loss = -13.6539
Iteration 25450, loss = -14.0673
Iteration 25460, loss = -14.0736
Iteration 25470, loss = -13.4427
Iteration 25480, loss = -13.9766
Iteration 25490, loss = -13.4138
Iteration 25500, loss = -13.8274
Iteration 25510, loss = -14.3827
Iteration 25520, loss = -14.2577
Iteration 25530, loss = -13.9492
Iteration 25540, loss = -13.4210
Iteration 25550, loss = -13.8034
Iteration 25560, loss = -13.4617
Iteration 25570, loss = -13.6730
Iteration 25580, loss = -13.7698
Iteration 25590, loss = -13.7981
Iteration 25600, loss = -13.4312
Iteration 25610, loss = -13.7199
Iteration 25620, loss = -12.9667
Iteration 25630, loss = -13.7327
Iteration 25640, loss = -13.6549
Iteration 25650, loss = -13.3062
Iteration 25660, loss = -13.2543
Iteration 25670, loss = -13.7594
Iteration 25680, loss = -13.4832
Iteration 25690, loss = -14.2053
Iteration 25700, loss = -13.9745
Iteration 25710, loss = -13.3841
Iteration 25720, loss = -13.6540
Iteration 25730, loss = -13.6184
Iteration 25740, loss = -14.0655
Iteration 25750, loss = -13.8155
Iteration 25760, loss = -13.4692
Iteration 25770, loss = -14.1814
Iteration 25780, loss = -13.0641
Iteration 25790, loss = -13.8990
Iteration 25800, loss = -13.7322
Iteration 25810, loss = -14.3130
Iteration 25820, loss = -13.1476
Iteration 25830, loss = -13.7765
Iteration 25840, loss = -13.9041
Iteration 25850, loss = -13.8761
Iteration 25860, loss = -13.6158
Iteration 25870, loss = -14.1630
Iteration 25880, loss = -13.6887
Iteration 25890, loss = -13.0439
Iteration 25900, loss = -13.7366
Iteration 25910, loss = -13.4165
Iteration 25920, loss = -13.3803
Iteration 25930, loss = -13.7635
Iteration 25940, loss = -13.4201
Iteration 25950, loss = -13.9280
Iteration 25960, loss = -13.8693
Iteration 25970, loss = -13.5293
Iteration 25980, loss = -13.9569
Iteration 25990, loss = -12.9284
Iteration 26000, loss = -13.5822
Om: 8.68%, s8: 6.28% accuracy
chi2: 2.354

Starting epoch 18
Iteration 26010, loss = -14.1166
Iteration 26020, loss = -12.7287
Iteration 26030, loss = -13.3246
Iteration 26040, loss = -13.9553
Iteration 26050, loss = -14.0017
Iteration 26060, loss = -13.9709
Iteration 26070, loss = -13.4534
Iteration 26080, loss = -13.6432
Iteration 26090, loss = -13.6573
Iteration 26100, loss = -13.8219
Iteration 26110, loss = -13.9220
Iteration 26120, loss = -14.2654
Iteration 26130, loss = -13.7140
Iteration 26140, loss = -12.8245
Iteration 26150, loss = -13.9551
Iteration 26160, loss = -13.4554
Iteration 26170, loss = -14.2797
Iteration 26180, loss = -13.4332
Iteration 26190, loss = -13.9635
Iteration 26200, loss = -13.4800
Iteration 26210, loss = -13.3116
Iteration 26220, loss = -13.7261
Iteration 26230, loss = -12.0924
Iteration 26240, loss = -13.6900
Iteration 26250, loss = -12.9048
Iteration 26260, loss = -14.1531
Iteration 26270, loss = -12.6922
Iteration 26280, loss = -13.3873
Iteration 26290, loss = -13.5105
Iteration 26300, loss = -13.7975
Iteration 26310, loss = -13.9324
Iteration 26320, loss = -13.5178
Iteration 26330, loss = -14.0291
Iteration 26340, loss = -13.3781
Iteration 26350, loss = -14.0886
Iteration 26360, loss = -13.7514
Iteration 26370, loss = -14.2589
Iteration 26380, loss = -13.4628
Iteration 26390, loss = -13.7350
Iteration 26400, loss = -12.9499
Iteration 26410, loss = -13.9687
Iteration 26420, loss = -13.5909
Iteration 26430, loss = -13.7471
Iteration 26440, loss = -13.6949
Iteration 26450, loss = -13.5737
Iteration 26460, loss = -13.6914
Iteration 26470, loss = -13.2975
Iteration 26480, loss = -13.6581
Iteration 26490, loss = -13.7690
Iteration 26500, loss = -13.1956
Iteration 26510, loss = -13.9877
Iteration 26520, loss = -13.6268
Iteration 26530, loss = -13.6699
Iteration 26540, loss = -13.5828
Iteration 26550, loss = -13.4738
Iteration 26560, loss = -13.8056
Iteration 26570, loss = -13.5781
Iteration 26580, loss = -14.0761
Iteration 26590, loss = -13.8890
Iteration 26600, loss = -13.7672
Iteration 26610, loss = -13.6920
Iteration 26620, loss = -13.5452
Iteration 26630, loss = -13.6467
Iteration 26640, loss = -13.7873
Iteration 26650, loss = -13.8595
Iteration 26660, loss = -13.0970
Iteration 26670, loss = -12.8024
Iteration 26680, loss = -13.8303
Iteration 26690, loss = -14.0926
Iteration 26700, loss = -13.4327
Iteration 26710, loss = -14.1446
Iteration 26720, loss = -13.9173
Iteration 26730, loss = -13.9656
Iteration 26740, loss = -14.4461
Iteration 26750, loss = -13.4724
Iteration 26760, loss = -13.4100
Iteration 26770, loss = -13.7698
Iteration 26780, loss = -13.8959
Iteration 26790, loss = -14.4538
Iteration 26800, loss = -13.9334
Iteration 26810, loss = -14.0388
Iteration 26820, loss = -13.8674
Iteration 26830, loss = -13.1197
Iteration 26840, loss = -13.8959
Iteration 26850, loss = -13.8125
Iteration 26860, loss = -13.4916
Iteration 26870, loss = -13.6335
Iteration 26880, loss = -13.4784
Iteration 26890, loss = -13.5758
Iteration 26900, loss = -13.5546
Iteration 26910, loss = -13.9804
Iteration 26920, loss = -13.2557
Iteration 26930, loss = -13.4409
Iteration 26940, loss = -14.0585
Iteration 26950, loss = -13.0936
Iteration 26960, loss = -13.0911
Iteration 26970, loss = -14.1988
Iteration 26980, loss = -13.9220
Iteration 26990, loss = -13.5744
Iteration 27000, loss = -13.3933
Om: 8.38%, s8: 6.16% accuracy
chi2: 1.503

Iteration 27010, loss = -13.8278
Iteration 27020, loss = -13.9881
Iteration 27030, loss = -13.8709
Iteration 27040, loss = -13.2710
Iteration 27050, loss = -14.2563
Iteration 27060, loss = -13.2053
Iteration 27070, loss = -13.6961
Iteration 27080, loss = -13.6539
Iteration 27090, loss = -13.6289
Iteration 27100, loss = -13.6277
Iteration 27110, loss = -13.2964
Iteration 27120, loss = -13.6703
Iteration 27130, loss = -14.2131
Iteration 27140, loss = -14.0020
Iteration 27150, loss = -14.3062
Iteration 27160, loss = -13.6778
Iteration 27170, loss = -14.1643
Iteration 27180, loss = -14.6443
Iteration 27190, loss = -13.7849
Iteration 27200, loss = -13.8583
Iteration 27210, loss = -13.4456
Iteration 27220, loss = -13.5440
Iteration 27230, loss = -13.9644
Iteration 27240, loss = -13.9092
Iteration 27250, loss = -13.5197
Iteration 27260, loss = -13.2781
Iteration 27270, loss = -13.1168
Iteration 27280, loss = -12.8659
Iteration 27290, loss = -14.1036
Iteration 27300, loss = -13.9394
Iteration 27310, loss = -13.7330
Iteration 27320, loss = -12.8861
Iteration 27330, loss = -12.9841
Iteration 27340, loss = -13.5965
Iteration 27350, loss = -13.3282
Iteration 27360, loss = -14.0705
Iteration 27370, loss = -13.8224
Iteration 27380, loss = -13.9513
Iteration 27390, loss = -13.7520
Iteration 27400, loss = -13.8508
Iteration 27410, loss = -14.1086
Iteration 27420, loss = -14.2309
Iteration 27430, loss = -14.3283
Iteration 27440, loss = -13.2515
Iteration 27450, loss = -13.9467
Starting epoch 19
Iteration 27460, loss = -13.5345
Iteration 27470, loss = -13.4972
Iteration 27480, loss = -13.9472
Iteration 27490, loss = -13.9631
Iteration 27500, loss = -13.8396
Iteration 27510, loss = -13.7130
Iteration 27520, loss = -13.4803
Iteration 27530, loss = -13.9955
Iteration 27540, loss = -12.8886
Iteration 27550, loss = -14.2480
Iteration 27560, loss = -13.3673
Iteration 27570, loss = -13.7355
Iteration 27580, loss = -14.4332
Iteration 27590, loss = -14.0085
Iteration 27600, loss = -13.2673
Iteration 27610, loss = -12.9931
Iteration 27620, loss = -13.2218
Iteration 27630, loss = -13.2728
Iteration 27640, loss = -13.6370
Iteration 27650, loss = -13.5568
Iteration 27660, loss = -13.9937
Iteration 27670, loss = -13.6763
Iteration 27680, loss = -13.8246
Iteration 27690, loss = -12.5455
Iteration 27700, loss = -13.7313
Iteration 27710, loss = -13.5182
Iteration 27720, loss = -13.7633
Iteration 27730, loss = -13.2734
Iteration 27740, loss = -14.1404
Iteration 27750, loss = -13.9950
Iteration 27760, loss = -13.4104
Iteration 27770, loss = -13.4300
Iteration 27780, loss = -13.8473
Iteration 27790, loss = -13.5384
Iteration 27800, loss = -13.8814
Iteration 27810, loss = -13.5671
Iteration 27820, loss = -13.2315
Iteration 27830, loss = -13.9322
Iteration 27840, loss = -13.7041
Iteration 27850, loss = -13.6525
Iteration 27860, loss = -13.7336
Iteration 27870, loss = -13.6026
Iteration 27880, loss = -14.1361
Iteration 27890, loss = -13.8254
Iteration 27900, loss = -13.9987
Iteration 27910, loss = -13.2465
Iteration 27920, loss = -14.2502
Iteration 27930, loss = -13.9055
Iteration 27940, loss = -13.5898
Iteration 27950, loss = -14.0064
Iteration 27960, loss = -13.5440
Iteration 27970, loss = -13.8323
Iteration 27980, loss = -13.5520
Iteration 27990, loss = -14.2719
Iteration 28000, loss = -14.2158
Om: 8.23%, s8: 6.02% accuracy
chi2: 2.145

Iteration 28010, loss = -13.0849
Iteration 28020, loss = -13.9151
Iteration 28030, loss = -13.3677
Iteration 28040, loss = -13.9897
Iteration 28050, loss = -14.0378
Iteration 28060, loss = -13.8655
Iteration 28070, loss = -13.8349
Iteration 28080, loss = -13.8539
Iteration 28090, loss = -13.9157
Iteration 28100, loss = -13.5953
Iteration 28110, loss = -13.8334
Iteration 28120, loss = -13.8082
Iteration 28130, loss = -14.0093
Iteration 28140, loss = -13.5963
Iteration 28150, loss = -13.3980
Iteration 28160, loss = -13.9897
Iteration 28170, loss = -13.6737
Iteration 28180, loss = -13.7641
Iteration 28190, loss = -13.9923
Iteration 28200, loss = -14.1744
Iteration 28210, loss = -12.6699
Iteration 28220, loss = -13.3480
Iteration 28230, loss = -13.8670
Iteration 28240, loss = -13.9512
Iteration 28250, loss = -13.8223
Iteration 28260, loss = -13.5984
Iteration 28270, loss = -14.1783
Iteration 28280, loss = -14.1172
Iteration 28290, loss = -13.6926
Iteration 28300, loss = -13.7885
Iteration 28310, loss = -13.9779
Iteration 28320, loss = -13.2733
Iteration 28330, loss = -13.7663
Iteration 28340, loss = -14.2085
Iteration 28350, loss = -13.9700
Iteration 28360, loss = -13.7771
Iteration 28370, loss = -13.7617
Iteration 28380, loss = -13.4546
Iteration 28390, loss = -13.2848
Iteration 28400, loss = -14.3116
Iteration 28410, loss = -14.2325
Iteration 28420, loss = -14.1596
Iteration 28430, loss = -13.1337
Iteration 28440, loss = -14.0492
Iteration 28450, loss = -13.1693
Iteration 28460, loss = -13.8329
Iteration 28470, loss = -13.1654
Iteration 28480, loss = -14.1333
Iteration 28490, loss = -13.5135
Iteration 28500, loss = -14.0910
Iteration 28510, loss = -13.2712
Iteration 28520, loss = -14.1152
Iteration 28530, loss = -13.6721
Iteration 28540, loss = -13.5891
Iteration 28550, loss = -13.1644
Iteration 28560, loss = -13.8871
Iteration 28570, loss = -13.5901
Iteration 28580, loss = -14.2445
Iteration 28590, loss = -13.9946
Iteration 28600, loss = -13.9141
Iteration 28610, loss = -14.1745
Iteration 28620, loss = -13.4890
Iteration 28630, loss = -14.0955
Iteration 28640, loss = -13.6498
Iteration 28650, loss = -14.0762
Iteration 28660, loss = -13.8544
Iteration 28670, loss = -13.0674
Iteration 28680, loss = -13.9193
Iteration 28690, loss = -13.5324
Iteration 28700, loss = -14.1658
Iteration 28710, loss = -12.8669
Iteration 28720, loss = -13.6242
Iteration 28730, loss = -13.9895
Iteration 28740, loss = -13.6532
Iteration 28750, loss = -13.5664
Iteration 28760, loss = -14.0349
Iteration 28770, loss = -13.6784
Iteration 28780, loss = -13.7680
Iteration 28790, loss = -13.6815
Iteration 28800, loss = -13.6045
Iteration 28810, loss = -13.7776
Iteration 28820, loss = -13.7098
Iteration 28830, loss = -13.1180
Iteration 28840, loss = -14.1588
Iteration 28850, loss = -14.0806
Iteration 28860, loss = -13.6164
Iteration 28870, loss = -14.3191
Iteration 28880, loss = -12.3343
Iteration 28890, loss = -13.8611
