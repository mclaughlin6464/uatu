-------------------------------------------------------------------------------
There are messages associated with the following module(s):
-------------------------------------------------------------------------------

py-tensorflow/1.6.0_py27:
    Warning: this module requires a GPU, it won't work on CPU nodes.

-------------------------------------------------------------------------------


The following have been reloaded with a version change:
  1) openmpi/2.1.1 => openmpi/2.0.2

/home/users/swmclau2/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
2019-05-11 14:33:08.147152: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-05-11 14:33:08.355368: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1212] Found device 0 with properties: 
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.076
pciBusID: 0000:04:00.0
totalMemory: 11.93GiB freeMemory: 11.82GiB
2019-05-11 14:33:08.444041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1212] Found device 1 with properties: 
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.076
pciBusID: 0000:05:00.0
totalMemory: 11.93GiB freeMemory: 11.82GiB
2019-05-11 14:33:08.444468: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1227] Device peer to peer matrix
2019-05-11 14:33:08.444499: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1233] DMA: 0 1 
2019-05-11 14:33:08.444507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1243] 0:   Y Y 
2019-05-11 14:33:08.444513: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1243] 1:   Y Y 
2019-05-11 14:33:08.444523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1312] Adding visible gpu devices: 0, 1
2019-05-11 14:33:15.232205: I tensorflow/core/common_runtime/gpu/gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11444 MB memory) -> physical GPU (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:04:00.0, compute capability: 5.2)
2019-05-11 14:33:15.431260: I tensorflow/core/common_runtime/gpu/gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 11444 MB memory) -> physical GPU (device: 1, name: GeForce GTX TITAN X, pci bus id: 0000:05:00.0, compute capability: 5.2)
False
Starting epoch 0
Iteration 0, loss = 0.2732
Om: 365.76%, s8: 476.39% accuracy
chi2: 312.807

Iteration 10, loss = 1.3089
Iteration 20, loss = -0.2666
Iteration 30, loss = -2.1957
Iteration 40, loss = -2.9795
Iteration 50, loss = -3.3246
Iteration 60, loss = -4.1042
Iteration 70, loss = -4.2294
Iteration 80, loss = -3.9145
Iteration 90, loss = -4.4713
Iteration 100, loss = -4.3405
Iteration 110, loss = -4.8014
Iteration 120, loss = -4.2141
Iteration 130, loss = -5.1297
Iteration 140, loss = -5.3598
Iteration 150, loss = -4.8066
Iteration 160, loss = -5.5604
Iteration 170, loss = -5.1407
Iteration 180, loss = -5.4616
Iteration 190, loss = -5.2122
Iteration 200, loss = -5.4338
Iteration 210, loss = -5.1145
Iteration 220, loss = -5.6079
Iteration 230, loss = -4.9097
Iteration 240, loss = -5.8409
Iteration 250, loss = -5.9157
Iteration 260, loss = -5.3397
Iteration 270, loss = -5.7751
Iteration 280, loss = -5.8645
Iteration 290, loss = -5.5742
Iteration 300, loss = -5.4363
Iteration 310, loss = -5.9083
Iteration 320, loss = -5.8896
Iteration 330, loss = -5.8608
Iteration 340, loss = -5.8307
Iteration 350, loss = -6.2545
Iteration 360, loss = -5.5579
Iteration 370, loss = -5.5241
Iteration 380, loss = -6.0480
Iteration 390, loss = -5.9602
Iteration 400, loss = -6.1538
Iteration 410, loss = -6.2138
Iteration 420, loss = -6.3695
Iteration 430, loss = -6.3185
Iteration 440, loss = -6.5195
Iteration 450, loss = -6.6883
Iteration 460, loss = -6.6428
Iteration 470, loss = -6.3727
Iteration 480, loss = -7.2438
Iteration 490, loss = -6.4529
Iteration 500, loss = -6.6972
Iteration 510, loss = -6.5996
Iteration 520, loss = -7.3813
Iteration 530, loss = -6.4423
Iteration 540, loss = -7.3762
Iteration 550, loss = -7.1543
Iteration 560, loss = -7.2002
Iteration 570, loss = -7.1358
Iteration 580, loss = -7.6986
Iteration 590, loss = -7.4169
Iteration 600, loss = -7.5819
Iteration 610, loss = -7.5264
Iteration 620, loss = -7.9583
Iteration 630, loss = -7.1882
Iteration 640, loss = -7.3907
Iteration 650, loss = -7.1599
Iteration 660, loss = -7.6551
Iteration 670, loss = -8.1686
Iteration 680, loss = -8.1012
Iteration 690, loss = -8.3863
Iteration 700, loss = -8.4749
Iteration 710, loss = -7.8854
Iteration 720, loss = -8.0780
Iteration 730, loss = -7.6884
Iteration 740, loss = -8.5617
Iteration 750, loss = -9.1308
Iteration 760, loss = -8.5984
Iteration 770, loss = -8.1781
Iteration 780, loss = -7.2851
Iteration 790, loss = -8.6807
Iteration 800, loss = -8.3421
Iteration 810, loss = -8.8823
Iteration 820, loss = -7.8815
Iteration 830, loss = -7.8180
Iteration 840, loss = -8.4498
Iteration 850, loss = -8.6115
Iteration 860, loss = -7.7535
Iteration 870, loss = -8.6641
Iteration 880, loss = -9.0251
Iteration 890, loss = -9.2762
Iteration 900, loss = -8.8919
Iteration 910, loss = -8.5124
Iteration 920, loss = -9.2889
Iteration 930, loss = -8.5569
Iteration 940, loss = -9.8288
Iteration 950, loss = -8.8774
Iteration 960, loss = -8.5231
Iteration 970, loss = -9.2054
Iteration 980, loss = -9.4833
Iteration 990, loss = -9.4377
Iteration 1000, loss = -9.0970
Om: 17.44%, s8: 10.67% accuracy
chi2: 1.559

Iteration 1010, loss = -9.7159
Iteration 1020, loss = -9.7102
Iteration 1030, loss = -9.8762
Iteration 1040, loss = -9.4081
Iteration 1050, loss = -9.6736
Iteration 1060, loss = -9.5743
Iteration 1070, loss = -9.6793
Iteration 1080, loss = -9.0784
Iteration 1090, loss = -9.9914
Iteration 1100, loss = -10.2994
Iteration 1110, loss = -9.2952
Iteration 1120, loss = -9.5630
Iteration 1130, loss = -9.8268
Iteration 1140, loss = -9.0476
Iteration 1150, loss = -10.0919
Iteration 1160, loss = -10.0557
Iteration 1170, loss = -10.1076
Iteration 1180, loss = -10.2011
Iteration 1190, loss = -10.0041
Iteration 1200, loss = -9.8399
Iteration 1210, loss = -9.3236
Iteration 1220, loss = -10.7131
Iteration 1230, loss = -9.2393
Iteration 1240, loss = -10.4147
Iteration 1250, loss = -10.9760
Iteration 1260, loss = -10.4689
Iteration 1270, loss = -10.0612
Iteration 1280, loss = -10.2798
Iteration 1290, loss = -10.9667
Iteration 1300, loss = -10.1531
Iteration 1310, loss = -10.6430
Iteration 1320, loss = -10.5272
Iteration 1330, loss = -11.1305
Iteration 1340, loss = -10.1279
Iteration 1350, loss = -11.1590
Iteration 1360, loss = -10.2172
Iteration 1370, loss = -10.2605
Iteration 1380, loss = -11.4384
Iteration 1390, loss = -10.7654
Iteration 1400, loss = -9.5100
Iteration 1410, loss = -10.4294
Iteration 1420, loss = -10.1448
Iteration 1430, loss = -10.2590
Iteration 1440, loss = -11.0819
Starting epoch 1
Iteration 1450, loss = -11.3394
Iteration 1460, loss = -10.8288
Iteration 1470, loss = -11.0978
Iteration 1480, loss = -10.5135
Iteration 1490, loss = -11.2844
Iteration 1500, loss = -10.8559
Iteration 1510, loss = -11.7419
Iteration 1520, loss = -11.6788
Iteration 1530, loss = -11.3874
Iteration 1540, loss = -11.7054
Iteration 1550, loss = -11.1895
Iteration 1560, loss = -11.5993
Iteration 1570, loss = -10.6526
Iteration 1580, loss = -11.1123
Iteration 1590, loss = -10.9873
Iteration 1600, loss = -10.5196
Iteration 1610, loss = -11.6515
Iteration 1620, loss = -10.9602
Iteration 1630, loss = -11.0661
Iteration 1640, loss = -11.1574
Iteration 1650, loss = -11.9338
Iteration 1660, loss = -11.9950
Iteration 1670, loss = -11.9372
Iteration 1680, loss = -11.7128
Iteration 1690, loss = -11.9924
Iteration 1700, loss = -11.2029
Iteration 1710, loss = -11.4492
Iteration 1720, loss = -11.6545
Iteration 1730, loss = -11.2157
Iteration 1740, loss = -11.8373
Iteration 1750, loss = -11.7127
Iteration 1760, loss = -11.1918
Iteration 1770, loss = -11.4760
Iteration 1780, loss = -12.0487
Iteration 1790, loss = -12.2485
Iteration 1800, loss = -11.8202
Iteration 1810, loss = -11.2776
Iteration 1820, loss = -10.7091
Iteration 1830, loss = -11.2322
Iteration 1840, loss = -11.5301
Iteration 1850, loss = -11.2023
Iteration 1860, loss = -11.2195
Iteration 1870, loss = -11.4718
Iteration 1880, loss = -10.3090
Iteration 1890, loss = -10.3140
Iteration 1900, loss = -10.6818
Iteration 1910, loss = -11.8233
Iteration 1920, loss = -11.6522
Iteration 1930, loss = -12.2383
Iteration 1940, loss = -11.9230
Iteration 1950, loss = -11.5486
Iteration 1960, loss = -10.7942
Iteration 1970, loss = -11.1773
Iteration 1980, loss = -10.1863
Iteration 1990, loss = -11.0522
Iteration 2000, loss = -10.9015
Om: 10.66%, s8: 7.85% accuracy
chi2: 0.688

Iteration 2010, loss = -12.0106
Iteration 2020, loss = -12.3099
Iteration 2030, loss = -12.1637
Iteration 2040, loss = -11.6824
Iteration 2050, loss = -11.7979
Iteration 2060, loss = -12.4964
Iteration 2070, loss = -11.6581
Iteration 2080, loss = -11.1052
Iteration 2090, loss = -10.1160
Iteration 2100, loss = -11.5059
Iteration 2110, loss = -11.7191
Iteration 2120, loss = -11.4960
Iteration 2130, loss = -11.7779
Iteration 2140, loss = -11.8764
Iteration 2150, loss = -11.8108
Iteration 2160, loss = -12.1352
Iteration 2170, loss = -11.9852
Iteration 2180, loss = -11.7920
Iteration 2190, loss = -11.1957
Iteration 2200, loss = -12.8610
Iteration 2210, loss = -12.0461
Iteration 2220, loss = -11.8638
Iteration 2230, loss = -11.4336
Iteration 2240, loss = -11.5281
Iteration 2250, loss = -12.0749
Iteration 2260, loss = -11.1912
Iteration 2270, loss = -11.9748
Iteration 2280, loss = -11.7160
Iteration 2290, loss = -11.4374
Iteration 2300, loss = -12.0524
Iteration 2310, loss = -11.6067
Iteration 2320, loss = -11.8738
Iteration 2330, loss = -11.7112
Iteration 2340, loss = -12.3715
Iteration 2350, loss = -12.5836
Iteration 2360, loss = -12.3741
Iteration 2370, loss = -11.5677
Iteration 2380, loss = -11.6755
Iteration 2390, loss = -13.0257
Iteration 2400, loss = -12.3441
Iteration 2410, loss = -11.9835
Iteration 2420, loss = -11.6012
Iteration 2430, loss = -12.3153
Iteration 2440, loss = -11.8968
Iteration 2450, loss = -12.3671
Iteration 2460, loss = -11.5070
Iteration 2470, loss = -11.9395
Iteration 2480, loss = -12.0752
Iteration 2490, loss = -11.1711
Iteration 2500, loss = -11.7686
Iteration 2510, loss = -12.1925
Iteration 2520, loss = -11.5980
Iteration 2530, loss = -11.9430
Iteration 2540, loss = -11.7518
Iteration 2550, loss = -12.2431
Iteration 2560, loss = -11.8712
Iteration 2570, loss = -11.9600
Iteration 2580, loss = -11.1866
Iteration 2590, loss = -11.8316
Iteration 2600, loss = -11.7397
Iteration 2610, loss = -11.6222
Iteration 2620, loss = -12.9060
Iteration 2630, loss = -12.1606
Iteration 2640, loss = -12.9890
Iteration 2650, loss = -12.1754
Iteration 2660, loss = -12.1413
Iteration 2670, loss = -12.1260
Iteration 2680, loss = -12.2682
Iteration 2690, loss = -12.0256
Iteration 2700, loss = -12.9140
Iteration 2710, loss = -11.9691
Iteration 2720, loss = -12.5850
Iteration 2730, loss = -11.7702
Iteration 2740, loss = -11.9033
Iteration 2750, loss = -13.0186
Iteration 2760, loss = -12.3187
Iteration 2770, loss = -12.2856
Iteration 2780, loss = -12.2985
Iteration 2790, loss = -11.8935
Iteration 2800, loss = -11.4988
Iteration 2810, loss = -12.8677
Iteration 2820, loss = -12.3650
Iteration 2830, loss = -11.9832
Iteration 2840, loss = -12.1357
Iteration 2850, loss = -12.4274
Iteration 2860, loss = -12.4673
Iteration 2870, loss = -12.2467
Iteration 2880, loss = -11.6366
Starting epoch 2
Iteration 2890, loss = -11.7199
Iteration 2900, loss = -11.7852
Iteration 2910, loss = -12.4932
Iteration 2920, loss = -11.2546
Iteration 2930, loss = -12.4655
Iteration 2940, loss = -12.1657
Iteration 2950, loss = -12.9271
Iteration 2960, loss = -12.7522
Iteration 2970, loss = -12.2177
Iteration 2980, loss = -12.1281
Iteration 2990, loss = -12.0178
Iteration 3000, loss = -12.4472
Om: 9.69%, s8: 7.43% accuracy
chi2: 1.046

Iteration 3010, loss = -12.5991
Iteration 3020, loss = -12.4645
Iteration 3030, loss = -11.8558
Iteration 3040, loss = -10.8208
Iteration 3050, loss = -10.8517
Iteration 3060, loss = -11.8481
Iteration 3070, loss = -12.7235
Iteration 3080, loss = -12.4687
Iteration 3090, loss = -12.1735
Iteration 3100, loss = -12.3950
Iteration 3110, loss = -12.4385
Iteration 3120, loss = -11.9264
Iteration 3130, loss = -12.4125
Iteration 3140, loss = -12.3967
Iteration 3150, loss = -12.6570
Iteration 3160, loss = -12.7634
Iteration 3170, loss = -11.6812
Iteration 3180, loss = -12.4693
Iteration 3190, loss = -11.9459
Iteration 3200, loss = -11.9528
Iteration 3210, loss = -12.7985
Iteration 3220, loss = -12.8293
Iteration 3230, loss = -12.4907
Iteration 3240, loss = -12.2905
Iteration 3250, loss = -12.1867
Iteration 3260, loss = -12.2586
Iteration 3270, loss = -12.2028
Iteration 3280, loss = -12.1542
Iteration 3290, loss = -11.8950
Iteration 3300, loss = -12.6820
Iteration 3310, loss = -11.8068
Iteration 3320, loss = -12.2802
Iteration 3330, loss = -12.3182
Iteration 3340, loss = -13.4624
Iteration 3350, loss = -11.7421
Iteration 3360, loss = -11.9424
Iteration 3370, loss = -12.6097
Iteration 3380, loss = -13.1664
Iteration 3390, loss = -12.3128
Iteration 3400, loss = -12.4739
Iteration 3410, loss = -12.1063
Iteration 3420, loss = -12.1192
Iteration 3430, loss = -12.9070
Iteration 3440, loss = -12.6080
Iteration 3450, loss = -12.3250
Iteration 3460, loss = -12.0690
Iteration 3470, loss = -12.5209
Iteration 3480, loss = -11.7036
Iteration 3490, loss = -12.3028
Iteration 3500, loss = -12.2114
Iteration 3510, loss = -12.7453
Iteration 3520, loss = -12.3288
Iteration 3530, loss = -11.4977
Iteration 3540, loss = -12.3950
Iteration 3550, loss = -12.7127
Iteration 3560, loss = -11.9010
Iteration 3570, loss = -11.8318
Iteration 3580, loss = -12.1623
Iteration 3590, loss = -12.5815
Iteration 3600, loss = -11.8061
Iteration 3610, loss = -12.2286
Iteration 3620, loss = -11.9232
Iteration 3630, loss = -12.1690
Iteration 3640, loss = -12.2905
Iteration 3650, loss = -12.3519
Iteration 3660, loss = -12.6142
Iteration 3670, loss = -12.4507
Iteration 3680, loss = -12.5774
Iteration 3690, loss = -12.7180
Iteration 3700, loss = -12.0325
Iteration 3710, loss = -12.8916
Iteration 3720, loss = -12.4451
Iteration 3730, loss = -12.4538
Iteration 3740, loss = -13.0841
Iteration 3750, loss = -12.7003
Iteration 3760, loss = -12.4322
Iteration 3770, loss = -11.6188
Iteration 3780, loss = -13.2426
Iteration 3790, loss = -12.1674
Iteration 3800, loss = -12.0942
Iteration 3810, loss = -12.8622
Iteration 3820, loss = -12.1693
Iteration 3830, loss = -11.5963
Iteration 3840, loss = -12.8667
Iteration 3850, loss = -11.6184
Iteration 3860, loss = -11.9169
Iteration 3870, loss = -11.6670
Iteration 3880, loss = -11.6975
Iteration 3890, loss = -12.1044
Iteration 3900, loss = -12.8252
Iteration 3910, loss = -13.1162
Iteration 3920, loss = -12.2619
Iteration 3930, loss = -12.8538
Iteration 3940, loss = -12.8217
Iteration 3950, loss = -13.2108
Iteration 3960, loss = -12.1410
Iteration 3970, loss = -12.4690
Iteration 3980, loss = -12.7368
Iteration 3990, loss = -12.5021
Iteration 4000, loss = -12.5871
Om: 9.80%, s8: 7.61% accuracy
chi2: 0.773

Iteration 4010, loss = -12.3277
Iteration 4020, loss = -12.3610
Iteration 4030, loss = -12.1223
Iteration 4040, loss = -12.9445
Iteration 4050, loss = -13.0169
Iteration 4060, loss = -12.9927
Iteration 4070, loss = -12.2256
Iteration 4080, loss = -12.4097
Iteration 4090, loss = -12.1055
Iteration 4100, loss = -12.8077
Iteration 4110, loss = -12.4993
Iteration 4120, loss = -12.6595
Iteration 4130, loss = -12.7206
Iteration 4140, loss = -12.2138
Iteration 4150, loss = -12.3895
Iteration 4160, loss = -12.3745
Iteration 4170, loss = -12.7724
Iteration 4180, loss = -12.5123
Iteration 4190, loss = -12.4303
Iteration 4200, loss = -12.5554
Iteration 4210, loss = -12.8275
Iteration 4220, loss = -12.7641
Iteration 4230, loss = -12.7175
Iteration 4240, loss = -12.3169
Iteration 4250, loss = -12.7880
Iteration 4260, loss = -12.4004
Iteration 4270, loss = -11.1483
Iteration 4280, loss = -11.0974
Iteration 4290, loss = -12.0475
Iteration 4300, loss = -12.3554
Iteration 4310, loss = -12.2086
Iteration 4320, loss = -12.2366
Iteration 4330, loss = -12.5139
Starting epoch 3
Iteration 4340, loss = -12.7134
Iteration 4350, loss = -12.1159
Iteration 4360, loss = -13.0782
Iteration 4370, loss = -12.2657
Iteration 4380, loss = -12.5976
Iteration 4390, loss = -11.7228
Iteration 4400, loss = -11.9746
Iteration 4410, loss = -13.0957
Iteration 4420, loss = -12.8481
Iteration 4430, loss = -11.6736
Iteration 4440, loss = -11.5913
Iteration 4450, loss = -12.5097
Iteration 4460, loss = -11.9737
Iteration 4470, loss = -12.8549
Iteration 4480, loss = -12.7993
Iteration 4490, loss = -12.8855
Iteration 4500, loss = -12.2179
Iteration 4510, loss = -12.0003
Iteration 4520, loss = -12.5895
Iteration 4530, loss = -12.2721
Iteration 4540, loss = -12.8675
Iteration 4550, loss = -11.7091
Iteration 4560, loss = -12.8565
Iteration 4570, loss = -12.5799
Iteration 4580, loss = -12.9287
Iteration 4590, loss = -12.7882
Iteration 4600, loss = -11.8132
Iteration 4610, loss = -12.3994
Iteration 4620, loss = -13.2517
Iteration 4630, loss = -12.7277
Iteration 4640, loss = -12.0393
Iteration 4650, loss = -11.9041
Iteration 4660, loss = -12.3268
Iteration 4670, loss = -12.5566
Iteration 4680, loss = -12.8815
Iteration 4690, loss = -12.9373
Iteration 4700, loss = -12.4863
Iteration 4710, loss = -11.3022
Iteration 4720, loss = -12.2254
Iteration 4730, loss = -12.8698
Iteration 4740, loss = -11.4892
Iteration 4750, loss = -12.2272
Iteration 4760, loss = -11.7067
Iteration 4770, loss = -12.0578
Iteration 4780, loss = -12.0336
Iteration 4790, loss = -13.0581
Iteration 4800, loss = -12.2653
Iteration 4810, loss = -13.2956
Iteration 4820, loss = -11.9948
Iteration 4830, loss = -12.4812
Iteration 4840, loss = -12.8292
Iteration 4850, loss = -12.9144
Iteration 4860, loss = -11.8666
Iteration 4870, loss = -12.8935
Iteration 4880, loss = -12.8211
Iteration 4890, loss = -12.7495
Iteration 4900, loss = -12.2331
Iteration 4910, loss = -12.5314
Iteration 4920, loss = -11.9485
Iteration 4930, loss = -12.8349
Iteration 4940, loss = -12.5304
Iteration 4950, loss = -12.8646
Iteration 4960, loss = -12.0975
Iteration 4970, loss = -12.6007
Iteration 4980, loss = -12.4331
Iteration 4990, loss = -12.4518
Iteration 5000, loss = -12.1672
Om: 9.61%, s8: 7.08% accuracy
chi2: 1.325

Iteration 5010, loss = -12.7615
Iteration 5020, loss = -12.6621
Iteration 5030, loss = -12.4041
Iteration 5040, loss = -11.4856
Iteration 5050, loss = -12.3184
Iteration 5060, loss = -13.1656
Iteration 5070, loss = -12.2373
Iteration 5080, loss = -12.2165
Iteration 5090, loss = -12.9914
Iteration 5100, loss = -12.6168
Iteration 5110, loss = -12.7452
Iteration 5120, loss = -12.7340
Iteration 5130, loss = -12.2566
Iteration 5140, loss = -12.4257
Iteration 5150, loss = -12.0513
Iteration 5160, loss = -13.0858
Iteration 5170, loss = -12.9735
Iteration 5180, loss = -12.2899
Iteration 5190, loss = -12.5806
Iteration 5200, loss = -12.6548
Iteration 5210, loss = -12.7174
Iteration 5220, loss = -11.9656
Iteration 5230, loss = -12.5407
Iteration 5240, loss = -12.9265
Iteration 5250, loss = -13.1403
Iteration 5260, loss = -12.4677
Iteration 5270, loss = -13.2389
Iteration 5280, loss = -13.4126
Iteration 5290, loss = -13.5217
Iteration 5300, loss = -13.1710
Iteration 5310, loss = -11.2181
Iteration 5320, loss = -12.3612
Iteration 5330, loss = -12.2646
Iteration 5340, loss = -12.3172
Iteration 5350, loss = -12.7841
Iteration 5360, loss = -12.3346
Iteration 5370, loss = -11.8381
Iteration 5380, loss = -12.4107
Iteration 5390, loss = -12.2407
Iteration 5400, loss = -12.4866
Iteration 5410, loss = -12.8833
Iteration 5420, loss = -12.7653
Iteration 5430, loss = -12.8769
Iteration 5440, loss = -12.6042
Iteration 5450, loss = -12.4223
Iteration 5460, loss = -13.1747
Iteration 5470, loss = -11.1200
Iteration 5480, loss = -11.8457
Iteration 5490, loss = -12.6836
Iteration 5500, loss = -12.4178
Iteration 5510, loss = -12.6406
Iteration 5520, loss = -12.9350
Iteration 5530, loss = -12.9886
Iteration 5540, loss = -13.0856
Iteration 5550, loss = -12.3480
Iteration 5560, loss = -12.1439
Iteration 5570, loss = -13.2823
Iteration 5580, loss = -13.7339
Iteration 5590, loss = -13.2522
Iteration 5600, loss = -12.7685
Iteration 5610, loss = -13.2869
Iteration 5620, loss = -13.5320
Iteration 5630, loss = -11.3798
Iteration 5640, loss = -13.4652
Iteration 5650, loss = -13.0046
Iteration 5660, loss = -12.5324
Iteration 5670, loss = -12.9817
Iteration 5680, loss = -12.2987
Iteration 5690, loss = -13.2125
Iteration 5700, loss = -13.2446
Iteration 5710, loss = -12.3383
Iteration 5720, loss = -12.2095
Iteration 5730, loss = -13.5325
Iteration 5740, loss = -13.1447
Iteration 5750, loss = -12.8738
Iteration 5760, loss = -13.0555
Iteration 5770, loss = -12.8482
Starting epoch 4
Iteration 5780, loss = -12.7501
Iteration 5790, loss = -11.7951
Iteration 5800, loss = -13.1199
Iteration 5810, loss = -11.7925
Iteration 5820, loss = -12.7938
Iteration 5830, loss = -12.6189
Iteration 5840, loss = -12.2178
Iteration 5850, loss = -13.3293
Iteration 5860, loss = -12.7500
Iteration 5870, loss = -12.5054
Iteration 5880, loss = -12.5456
Iteration 5890, loss = -13.0988
Iteration 5900, loss = -12.6642
Iteration 5910, loss = -13.0700
Iteration 5920, loss = -13.2684
Iteration 5930, loss = -12.8942
Iteration 5940, loss = -12.5333
Iteration 5950, loss = -13.2796
Iteration 5960, loss = -13.4229
Iteration 5970, loss = -12.7845
Iteration 5980, loss = -12.4692
Iteration 5990, loss = -12.4988
Iteration 6000, loss = -12.9352
Om: 9.45%, s8: 7.04% accuracy
chi2: 1.406

Iteration 6010, loss = -11.9295
Iteration 6020, loss = -12.9967
Iteration 6030, loss = -13.2133
Iteration 6040, loss = -12.7941
Iteration 6050, loss = -12.3510
Iteration 6060, loss = -13.1425
Iteration 6070, loss = -12.9159
Iteration 6080, loss = -12.3275
Iteration 6090, loss = -12.5371
Iteration 6100, loss = -12.3243
Iteration 6110, loss = -12.7001
Iteration 6120, loss = -12.6716
Iteration 6130, loss = -12.5040
Iteration 6140, loss = -12.5611
Iteration 6150, loss = -11.5009
Iteration 6160, loss = -12.8492
Iteration 6170, loss = -13.2161
Iteration 6180, loss = -13.0737
Iteration 6190, loss = -12.5378
Iteration 6200, loss = -13.0157
Iteration 6210, loss = -12.4823
Iteration 6220, loss = -13.1290
Iteration 6230, loss = -12.5189
Iteration 6240, loss = -13.0114
Iteration 6250, loss = -12.3289
Iteration 6260, loss = -12.9726
Iteration 6270, loss = -13.5092
Iteration 6280, loss = -12.4666
Iteration 6290, loss = -12.1969
Iteration 6300, loss = -12.2602
Iteration 6310, loss = -12.7259
Iteration 6320, loss = -12.8222
Iteration 6330, loss = -13.1369
Iteration 6340, loss = -12.1129
Iteration 6350, loss = -12.5271
Iteration 6360, loss = -12.9229
Iteration 6370, loss = -12.6557
Iteration 6380, loss = -12.6309
Iteration 6390, loss = -12.3045
Iteration 6400, loss = -13.2183
Iteration 6410, loss = -13.4159
Iteration 6420, loss = -11.9965
Iteration 6430, loss = -12.1166
Iteration 6440, loss = -13.2444
Iteration 6450, loss = -13.1442
Iteration 6460, loss = -12.5041
Iteration 6470, loss = -13.3240
Iteration 6480, loss = -13.3033
Iteration 6490, loss = -12.8730
Iteration 6500, loss = -12.8396
Iteration 6510, loss = -12.5859
Iteration 6520, loss = -13.1798
Iteration 6530, loss = -13.1668
Iteration 6540, loss = -12.7201
Iteration 6550, loss = -13.2161
Iteration 6560, loss = -12.6403
Iteration 6570, loss = -12.6746
Iteration 6580, loss = -12.7017
Iteration 6590, loss = -12.6440
Iteration 6600, loss = -12.7156
Iteration 6610, loss = -13.0601
Iteration 6620, loss = -13.2293
Iteration 6630, loss = -13.4849
Iteration 6640, loss = -13.6671
Iteration 6650, loss = -13.0896
Iteration 6660, loss = -12.7872
Iteration 6670, loss = -13.6377
Iteration 6680, loss = -12.4544
Iteration 6690, loss = -12.9441
Iteration 6700, loss = -13.1075
Iteration 6710, loss = -11.6734
Iteration 6720, loss = -12.6259
Iteration 6730, loss = -13.4333
Iteration 6740, loss = -12.3504
Iteration 6750, loss = -12.5324
Iteration 6760, loss = -12.4221
Iteration 6770, loss = -12.0746
Iteration 6780, loss = -12.7052
Iteration 6790, loss = -13.1215
Iteration 6800, loss = -13.5931
Iteration 6810, loss = -12.0246
Iteration 6820, loss = -13.5123
Iteration 6830, loss = -13.5761
Iteration 6840, loss = -12.3607
Iteration 6850, loss = -12.7255
Iteration 6860, loss = -13.4074
Iteration 6870, loss = -13.3184
Iteration 6880, loss = -12.3153
Iteration 6890, loss = -12.7988
Iteration 6900, loss = -12.7394
Iteration 6910, loss = -12.3229
Iteration 6920, loss = -12.4659
Iteration 6930, loss = -13.1125
Iteration 6940, loss = -12.8479
Iteration 6950, loss = -13.0005
Iteration 6960, loss = -12.8844
Iteration 6970, loss = -12.8400
Iteration 6980, loss = -12.3082
Iteration 6990, loss = -12.5763
Iteration 7000, loss = -12.5760
Om: 9.39%, s8: 6.92% accuracy
chi2: 1.434

Iteration 7010, loss = -13.0917
Iteration 7020, loss = -12.9743
Iteration 7030, loss = -13.0343
Iteration 7040, loss = -12.9931
Iteration 7050, loss = -13.2062
Iteration 7060, loss = -13.0433
Iteration 7070, loss = -13.2699
Iteration 7080, loss = -12.7957
Iteration 7090, loss = -12.8167
Iteration 7100, loss = -12.8808
Iteration 7110, loss = -13.1864
Iteration 7120, loss = -13.1180
Iteration 7130, loss = -13.2830
Iteration 7140, loss = -13.3442
Iteration 7150, loss = -12.4529
Iteration 7160, loss = -12.7090
Iteration 7170, loss = -12.3959
Iteration 7180, loss = -12.6111
Iteration 7190, loss = -12.7273
Iteration 7200, loss = -12.7415
Iteration 7210, loss = -12.9453
Iteration 7220, loss = -11.9923
Starting epoch 5
Iteration 7230, loss = -12.3320
Iteration 7240, loss = -12.5004
Iteration 7250, loss = -12.8268
Iteration 7260, loss = -12.9128
Iteration 7270, loss = -12.9052
Iteration 7280, loss = -12.5591
Iteration 7290, loss = -12.9138
Iteration 7300, loss = -13.3216
Iteration 7310, loss = -13.2836
Iteration 7320, loss = -13.3573
Iteration 7330, loss = -12.3875
Iteration 7340, loss = -13.1092
Iteration 7350, loss = -12.9828
Iteration 7360, loss = -12.9768
Iteration 7370, loss = -12.5629
Iteration 7380, loss = -13.3920
Iteration 7390, loss = -12.8057
Iteration 7400, loss = -12.7896
Iteration 7410, loss = -12.8295
Iteration 7420, loss = -13.1221
Iteration 7430, loss = -13.3211
Iteration 7440, loss = -12.5504
Iteration 7450, loss = -12.9916
Iteration 7460, loss = -13.3119
Iteration 7470, loss = -13.0710
Iteration 7480, loss = -13.2650
Iteration 7490, loss = -12.2291
Iteration 7500, loss = -13.3687
Iteration 7510, loss = -12.6269
Iteration 7520, loss = -13.1745
Iteration 7530, loss = -11.5895
Iteration 7540, loss = -12.3793
Iteration 7550, loss = -13.0801
Iteration 7560, loss = -13.5349
Iteration 7570, loss = -12.5368
Iteration 7580, loss = -12.8515
Iteration 7590, loss = -13.3995
Iteration 7600, loss = -12.3257
Iteration 7610, loss = -12.5820
Iteration 7620, loss = -12.2383
Iteration 7630, loss = -12.8479
Iteration 7640, loss = -12.7129
Iteration 7650, loss = -12.4443
Iteration 7660, loss = -13.8676
Iteration 7670, loss = -12.7251
Iteration 7680, loss = -12.9367
Iteration 7690, loss = -13.3727
Iteration 7700, loss = -12.9341
Iteration 7710, loss = -13.3066
Iteration 7720, loss = -13.0215
Iteration 7730, loss = -13.0748
Iteration 7740, loss = -13.1558
Iteration 7750, loss = -13.4441
Iteration 7760, loss = -13.2326
Iteration 7770, loss = -12.9665
Iteration 7780, loss = -12.3839
Iteration 7790, loss = -13.3855
Iteration 7800, loss = -12.8837
Iteration 7810, loss = -13.1472
Iteration 7820, loss = -12.7630
Iteration 7830, loss = -13.4363
Iteration 7840, loss = -12.8630
Iteration 7850, loss = -12.7667
Iteration 7860, loss = -13.2457
Iteration 7870, loss = -12.8898
Iteration 7880, loss = -12.7429
Iteration 7890, loss = -13.1555
Iteration 7900, loss = -13.5357
Iteration 7910, loss = -12.2221
Iteration 7920, loss = -13.3354
Iteration 7930, loss = -12.7884
Iteration 7940, loss = -13.2328
Iteration 7950, loss = -12.4142
Iteration 7960, loss = -12.8831
Iteration 7970, loss = -12.8470
Iteration 7980, loss = -13.3654
Iteration 7990, loss = -13.6853
Iteration 8000, loss = -13.2400
Om: 9.28%, s8: 6.87% accuracy
chi2: 1.635

Iteration 8010, loss = -12.5603
Iteration 8020, loss = -13.5052
Iteration 8030, loss = -13.2284
Iteration 8040, loss = -12.5030
Iteration 8050, loss = -12.3213
Iteration 8060, loss = -12.4883
Iteration 8070, loss = -13.1525
Iteration 8080, loss = -13.1764
Iteration 8090, loss = -13.5320
Iteration 8100, loss = -12.6545
Iteration 8110, loss = -12.9137
Iteration 8120, loss = -12.5942
Iteration 8130, loss = -13.8017
Iteration 8140, loss = -12.7934
Iteration 8150, loss = -12.6048
Iteration 8160, loss = -13.3227
Iteration 8170, loss = -13.1908
Iteration 8180, loss = -13.7355
Iteration 8190, loss = -13.4675
Iteration 8200, loss = -12.9838
Iteration 8210, loss = -13.1921
Iteration 8220, loss = -13.3709
Iteration 8230, loss = -13.0714
Iteration 8240, loss = -13.2422
Iteration 8250, loss = -13.0817
Iteration 8260, loss = -12.6627
Iteration 8270, loss = -13.5459
Iteration 8280, loss = -12.0720
Iteration 8290, loss = -13.0889
Iteration 8300, loss = -12.5996
Iteration 8310, loss = -12.9944
Iteration 8320, loss = -12.9634
Iteration 8330, loss = -12.2898
Iteration 8340, loss = -13.0854
Iteration 8350, loss = -13.4287
Iteration 8360, loss = -12.3337
Iteration 8370, loss = -12.6783
Iteration 8380, loss = -12.6835
Iteration 8390, loss = -12.6419
Iteration 8400, loss = -12.7184
Iteration 8410, loss = -13.6510
Iteration 8420, loss = -13.0369
Iteration 8430, loss = -13.3477
Iteration 8440, loss = -12.4603
Iteration 8450, loss = -13.2146
Iteration 8460, loss = -13.4356
Iteration 8470, loss = -13.3516
Iteration 8480, loss = -13.2800
Iteration 8490, loss = -13.3768
Iteration 8500, loss = -13.6404
Iteration 8510, loss = -13.7527
Iteration 8520, loss = -13.2514
Iteration 8530, loss = -13.3389
Iteration 8540, loss = -12.9831
Iteration 8550, loss = -12.8236
Iteration 8560, loss = -13.0658
Iteration 8570, loss = -13.2690
Iteration 8580, loss = -12.9944
Iteration 8590, loss = -13.4159
Iteration 8600, loss = -13.0167
Iteration 8610, loss = -12.4497
Iteration 8620, loss = -13.0183
Iteration 8630, loss = -13.5887
Iteration 8640, loss = -12.7645
Iteration 8650, loss = -12.3043
Iteration 8660, loss = -13.2919
Starting epoch 6
Iteration 8670, loss = -13.0947
Iteration 8680, loss = -12.5810
Iteration 8690, loss = -13.4361
Iteration 8700, loss = -12.7070
Iteration 8710, loss = -13.3772
Iteration 8720, loss = -12.9893
Iteration 8730, loss = -13.1160
Iteration 8740, loss = -13.1069
Iteration 8750, loss = -12.5637
Iteration 8760, loss = -13.2530
Iteration 8770, loss = -13.1782
Iteration 8780, loss = -13.1201
Iteration 8790, loss = -12.7793
Iteration 8800, loss = -13.0942
Iteration 8810, loss = -12.7411
Iteration 8820, loss = -13.5636
Iteration 8830, loss = -12.6079
Iteration 8840, loss = -13.3817
Iteration 8850, loss = -13.1863
Iteration 8860, loss = -13.3230
Iteration 8870, loss = -13.3485
Iteration 8880, loss = -13.3597
Iteration 8890, loss = -12.5164
Iteration 8900, loss = -12.5527
Iteration 8910, loss = -13.1947
Iteration 8920, loss = -13.6304
Iteration 8930, loss = -12.9561
Iteration 8940, loss = -12.9661
Iteration 8950, loss = -12.8782
Iteration 8960, loss = -13.0325
Iteration 8970, loss = -13.1603
Iteration 8980, loss = -13.5788
Iteration 8990, loss = -13.0667
Iteration 9000, loss = -12.5396
Om: 9.32%, s8: 6.89% accuracy
chi2: 2.274

Iteration 9010, loss = -12.3557
Iteration 9020, loss = -13.0969
Iteration 9030, loss = -13.2541
Iteration 9040, loss = -12.8794
Iteration 9050, loss = -13.0234
Iteration 9060, loss = -13.2270
Iteration 9070, loss = -12.8508
Iteration 9080, loss = -13.4480
Iteration 9090, loss = -13.0286
Iteration 9100, loss = -13.4020
Iteration 9110, loss = -13.0737
Iteration 9120, loss = -13.6456
Iteration 9130, loss = -13.7509
Iteration 9140, loss = -12.7777
Iteration 9150, loss = -13.4059
Iteration 9160, loss = -13.4263
Iteration 9170, loss = -12.9036
Iteration 9180, loss = -12.9495
Iteration 9190, loss = -12.5015
Iteration 9200, loss = -13.4126
Iteration 9210, loss = -12.7462
Iteration 9220, loss = -13.5877
Iteration 9230, loss = -13.2697
Iteration 9240, loss = -12.9216
Iteration 9250, loss = -13.1767
Iteration 9260, loss = -12.4936
Iteration 9270, loss = -12.8507
Iteration 9280, loss = -13.0541
Iteration 9290, loss = -13.7483
Iteration 9300, loss = -12.8723
Iteration 9310, loss = -13.4365
Iteration 9320, loss = -13.0257
Iteration 9330, loss = -13.5649
Iteration 9340, loss = -12.7707
Iteration 9350, loss = -13.3273
Iteration 9360, loss = -13.2535
Iteration 9370, loss = -12.7889
Iteration 9380, loss = -13.0892
Iteration 9390, loss = -13.2752
Iteration 9400, loss = -12.6078
Iteration 9410, loss = -13.0278
Iteration 9420, loss = -13.2700
Iteration 9430, loss = -13.1628
Iteration 9440, loss = -13.3817
Iteration 9450, loss = -13.2949
Iteration 9460, loss = -13.4782
Iteration 9470, loss = -12.9493
Iteration 9480, loss = -12.9489
Iteration 9490, loss = -12.8766
Iteration 9500, loss = -13.3149
Iteration 9510, loss = -13.8793
Iteration 9520, loss = -13.2362
Iteration 9530, loss = -13.7185
Iteration 9540, loss = -13.2038
Iteration 9550, loss = -13.2340
Iteration 9560, loss = -13.2354
Iteration 9570, loss = -12.7250
Iteration 9580, loss = -13.1393
Iteration 9590, loss = -13.1265
Iteration 9600, loss = -12.9612
Iteration 9610, loss = -13.5716
Iteration 9620, loss = -13.5300
Iteration 9630, loss = -12.9455
Iteration 9640, loss = -12.6114
Iteration 9650, loss = -12.6418
Iteration 9660, loss = -13.0472
Iteration 9670, loss = -13.4846
Iteration 9680, loss = -14.1166
Iteration 9690, loss = -14.0919
Iteration 9700, loss = -12.2215
Iteration 9710, loss = -13.5248
Iteration 9720, loss = -12.6917
Iteration 9730, loss = -13.0890
Iteration 9740, loss = -13.2019
Iteration 9750, loss = -13.5456
Iteration 9760, loss = -13.2498
Iteration 9770, loss = -13.2164
Iteration 9780, loss = -13.2351
Iteration 9790, loss = -13.3570
Iteration 9800, loss = -13.0524
Iteration 9810, loss = -12.8958
Iteration 9820, loss = -13.5621
Iteration 9830, loss = -13.6649
Iteration 9840, loss = -12.5581
Iteration 9850, loss = -12.8031
Iteration 9860, loss = -13.3510
Iteration 9870, loss = -12.8737
Iteration 9880, loss = -13.2211
Iteration 9890, loss = -13.2035
Iteration 9900, loss = -13.5396
Iteration 9910, loss = -12.3839
Iteration 9920, loss = -13.3089
Iteration 9930, loss = -12.8609
Iteration 9940, loss = -13.3043
Iteration 9950, loss = -13.2803
Iteration 9960, loss = -13.4527
Iteration 9970, loss = -13.2170
Iteration 9980, loss = -13.6041
Iteration 9990, loss = -13.5624
Iteration 10000, loss = -13.4963
Om: 9.16%, s8: 6.73% accuracy
chi2: 1.488

Iteration 10010, loss = -13.5790
Iteration 10020, loss = -13.6116
Iteration 10030, loss = -12.8103
Iteration 10040, loss = -13.3602
Iteration 10050, loss = -12.9658
Iteration 10060, loss = -12.7901
Iteration 10070, loss = -12.8882
Iteration 10080, loss = -12.7609
Iteration 10090, loss = -13.2391
Iteration 10100, loss = -13.3170
Iteration 10110, loss = -12.8952
Starting epoch 7
Iteration 10120, loss = -12.9554
Iteration 10130, loss = -13.5083
Iteration 10140, loss = -12.9682
Iteration 10150, loss = -13.3308
Iteration 10160, loss = -13.1286
Iteration 10170, loss = -13.7306
Iteration 10180, loss = -13.2344
Iteration 10190, loss = -13.8817
Iteration 10200, loss = -13.2007
Iteration 10210, loss = -13.0640
Iteration 10220, loss = -12.9863
Iteration 10230, loss = -12.6268
Iteration 10240, loss = -12.9921
Iteration 10250, loss = -13.7598
Iteration 10260, loss = -13.1707
Iteration 10270, loss = -13.3901
Iteration 10280, loss = -12.6146
Iteration 10290, loss = -12.9703
Iteration 10300, loss = -12.9986
Iteration 10310, loss = -13.1314
Iteration 10320, loss = -13.5961
Iteration 10330, loss = -13.4032
Iteration 10340, loss = -13.7610
Iteration 10350, loss = -13.9186
Iteration 10360, loss = -13.4495
Iteration 10370, loss = -13.6520
Iteration 10380, loss = -12.8080
Iteration 10390, loss = -13.5492
Iteration 10400, loss = -13.2435
Iteration 10410, loss = -13.8225
Iteration 10420, loss = -12.3109
Iteration 10430, loss = -12.9529
Iteration 10440, loss = -13.4417
Iteration 10450, loss = -13.7594
Iteration 10460, loss = -13.2360
Iteration 10470, loss = -13.2176
Iteration 10480, loss = -13.3106
Iteration 10490, loss = -12.9412
Iteration 10500, loss = -12.9940
Iteration 10510, loss = -13.0655
Iteration 10520, loss = -12.9121
Iteration 10530, loss = -13.3779
Iteration 10540, loss = -13.3446
Iteration 10550, loss = -13.0827
Iteration 10560, loss = -12.2527
Iteration 10570, loss = -13.6833
Iteration 10580, loss = -12.9835
Iteration 10590, loss = -13.2462
Iteration 10600, loss = -14.0466
Iteration 10610, loss = -12.9644
Iteration 10620, loss = -13.6195
Iteration 10630, loss = -13.4807
Iteration 10640, loss = -13.6837
Iteration 10650, loss = -12.9566
Iteration 10660, loss = -13.3575
Iteration 10670, loss = -12.9862
Iteration 10680, loss = -13.5653
Iteration 10690, loss = -13.5960
Iteration 10700, loss = -13.3818
Iteration 10710, loss = -13.2640
Iteration 10720, loss = -13.5408
Iteration 10730, loss = -13.1095
Iteration 10740, loss = -13.2355
Iteration 10750, loss = -12.4895
Iteration 10760, loss = -13.2027
Iteration 10770, loss = -12.9377
Iteration 10780, loss = -13.1961
Iteration 10790, loss = -13.0673
Iteration 10800, loss = -12.5318
Iteration 10810, loss = -12.8959
Iteration 10820, loss = -13.3436
Iteration 10830, loss = -13.5616
Iteration 10840, loss = -12.8820
Iteration 10850, loss = -13.6199
Iteration 10860, loss = -12.9764
Iteration 10870, loss = -13.0881
Iteration 10880, loss = -13.5694
Iteration 10890, loss = -13.6192
Iteration 10900, loss = -12.7517
Iteration 10910, loss = -13.4513
Iteration 10920, loss = -13.3628
Iteration 10930, loss = -13.2805
Iteration 10940, loss = -12.3937
Iteration 10950, loss = -13.0145
Iteration 10960, loss = -13.3293
Iteration 10970, loss = -13.2744
Iteration 10980, loss = -13.1802
Iteration 10990, loss = -13.3797
Iteration 11000, loss = -13.0360
Om: 9.18%, s8: 6.75% accuracy
chi2: 1.164

Iteration 11010, loss = -13.3447
Iteration 11020, loss = -13.9510
Iteration 11030, loss = -13.5509
Iteration 11040, loss = -12.5786
Iteration 11050, loss = -13.1788
Iteration 11060, loss = -13.6493
Iteration 11070, loss = -13.0506
Iteration 11080, loss = -13.2438
Iteration 11090, loss = -13.5197
Iteration 11100, loss = -12.8314
Iteration 11110, loss = -13.2598
Iteration 11120, loss = -13.2797
Iteration 11130, loss = -13.7269
Iteration 11140, loss = -13.2521
Iteration 11150, loss = -13.5701
Iteration 11160, loss = -13.2284
Iteration 11170, loss = -13.1804
Iteration 11180, loss = -12.8830
Iteration 11190, loss = -13.3021
Iteration 11200, loss = -13.1486
Iteration 11210, loss = -13.7985
Iteration 11220, loss = -13.0994
Iteration 11230, loss = -13.6498
Iteration 11240, loss = -13.2817
Iteration 11250, loss = -12.3765
Iteration 11260, loss = -12.9136
Iteration 11270, loss = -13.4011
Iteration 11280, loss = -12.7680
Iteration 11290, loss = -13.6620
Iteration 11300, loss = -13.5055
Iteration 11310, loss = -13.3434
Iteration 11320, loss = -12.3929
Iteration 11330, loss = -12.9772
Iteration 11340, loss = -13.0410
Iteration 11350, loss = -13.4413
Iteration 11360, loss = -13.7391
Iteration 11370, loss = -13.5647
Iteration 11380, loss = -13.8016
Iteration 11390, loss = -13.1656
Iteration 11400, loss = -13.8679
Iteration 11410, loss = -13.1529
Iteration 11420, loss = -13.7325
Iteration 11430, loss = -12.9012
Iteration 11440, loss = -13.0221
Iteration 11450, loss = -13.2744
Iteration 11460, loss = -13.6213
Iteration 11470, loss = -13.4503
Iteration 11480, loss = -13.4361
Iteration 11490, loss = -13.2027
Iteration 11500, loss = -12.9766
Iteration 11510, loss = -13.6688
Iteration 11520, loss = -13.3875
Iteration 11530, loss = -12.8687
Iteration 11540, loss = -13.1890
Iteration 11550, loss = -13.3007
Starting epoch 8
Iteration 11560, loss = -13.2163
Iteration 11570, loss = -13.3118
Iteration 11580, loss = -13.3370
Iteration 11590, loss = -13.2099
Iteration 11600, loss = -13.6769
Iteration 11610, loss = -13.6123
Iteration 11620, loss = -13.2796
Iteration 11630, loss = -13.6170
Iteration 11640, loss = -12.9213
Iteration 11650, loss = -13.2834
Iteration 11660, loss = -13.3714
Iteration 11670, loss = -13.6329
Iteration 11680, loss = -13.0866
Iteration 11690, loss = -13.3196
Iteration 11700, loss = -13.3000
Iteration 11710, loss = -13.0765
Iteration 11720, loss = -13.7293
Iteration 11730, loss = -13.6063
Iteration 11740, loss = -13.5698
Iteration 11750, loss = -13.6819
Iteration 11760, loss = -13.0464
Iteration 11770, loss = -13.7493
Iteration 11780, loss = -13.2291
Iteration 11790, loss = -13.2086
Iteration 11800, loss = -13.2877
Iteration 11810, loss = -13.6063
Iteration 11820, loss = -13.2596
Iteration 11830, loss = -13.0222
Iteration 11840, loss = -13.4336
Iteration 11850, loss = -12.8412
Iteration 11860, loss = -13.2281
Iteration 11870, loss = -13.3113
Iteration 11880, loss = -13.1781
Iteration 11890, loss = -13.7161
Iteration 11900, loss = -13.4534
Iteration 11910, loss = -13.7354
Iteration 11920, loss = -13.3677
Iteration 11930, loss = -13.2254
Iteration 11940, loss = -13.1523
Iteration 11950, loss = -13.2071
Iteration 11960, loss = -13.0425
Iteration 11970, loss = -13.5333
Iteration 11980, loss = -13.6890
Iteration 11990, loss = -12.9415
Iteration 12000, loss = -13.4416
Om: 9.09%, s8: 6.64% accuracy
chi2: 1.752

Iteration 12010, loss = -13.7075
Iteration 12020, loss = -13.4444
Iteration 12030, loss = -13.2599
Iteration 12040, loss = -13.4665
Iteration 12050, loss = -13.7646
Iteration 12060, loss = -13.0374
Iteration 12070, loss = -12.6340
Iteration 12080, loss = -12.6981
Iteration 12090, loss = -13.4259
Iteration 12100, loss = -13.2828
Iteration 12110, loss = -14.1274
Iteration 12120, loss = -13.3166
Iteration 12130, loss = -13.4925
Iteration 12140, loss = -13.6835
Iteration 12150, loss = -12.7714
Iteration 12160, loss = -13.2761
Iteration 12170, loss = -13.1618
Iteration 12180, loss = -13.5442
Iteration 12190, loss = -12.9801
Iteration 12200, loss = -13.2524
Iteration 12210, loss = -13.5264
Iteration 12220, loss = -13.6905
Iteration 12230, loss = -13.4883
Iteration 12240, loss = -13.4261
Iteration 12250, loss = -13.7535
Iteration 12260, loss = -13.2843
Iteration 12270, loss = -13.2460
Iteration 12280, loss = -13.1288
Iteration 12290, loss = -12.9974
Iteration 12300, loss = -13.4496
Iteration 12310, loss = -14.0913
Iteration 12320, loss = -13.6380
Iteration 12330, loss = -14.1219
Iteration 12340, loss = -13.7224
Iteration 12350, loss = -13.5967
Iteration 12360, loss = -13.0782
Iteration 12370, loss = -13.1573
Iteration 12380, loss = -13.2981
Iteration 12390, loss = -13.2594
Iteration 12400, loss = -13.4146
Iteration 12410, loss = -13.4218
Iteration 12420, loss = -13.4660
Iteration 12430, loss = -12.8215
Iteration 12440, loss = -12.5265
Iteration 12450, loss = -13.8291
Iteration 12460, loss = -12.8520
Iteration 12470, loss = -13.3760
Iteration 12480, loss = -12.5991
Iteration 12490, loss = -12.4706
Iteration 12500, loss = -13.1912
Iteration 12510, loss = -13.7947
Iteration 12520, loss = -13.3254
Iteration 12530, loss = -13.3534
Iteration 12540, loss = -13.0801
Iteration 12550, loss = -12.9286
Iteration 12560, loss = -13.3188
Iteration 12570, loss = -13.9331
Iteration 12580, loss = -13.6705
Iteration 12590, loss = -12.9859
Iteration 12600, loss = -13.7681
Iteration 12610, loss = -13.0686
Iteration 12620, loss = -13.3027
Iteration 12630, loss = -13.3963
Iteration 12640, loss = -13.7200
Iteration 12650, loss = -13.6719
Iteration 12660, loss = -13.5557
Iteration 12670, loss = -12.9556
Iteration 12680, loss = -13.4512
Iteration 12690, loss = -12.8851
Iteration 12700, loss = -13.1718
Iteration 12710, loss = -13.5140
Iteration 12720, loss = -13.6008
Iteration 12730, loss = -13.4786
Iteration 12740, loss = -12.9277
Iteration 12750, loss = -12.2591
Iteration 12760, loss = -12.9324
Iteration 12770, loss = -13.4126
Iteration 12780, loss = -12.9095
Iteration 12790, loss = -13.5462
Iteration 12800, loss = -12.8476
Iteration 12810, loss = -13.2907
Iteration 12820, loss = -12.9287
Iteration 12830, loss = -13.4929
Iteration 12840, loss = -13.3596
Iteration 12850, loss = -12.9223
Iteration 12860, loss = -13.1918
Iteration 12870, loss = -13.3690
Iteration 12880, loss = -13.4860
Iteration 12890, loss = -13.0702
Iteration 12900, loss = -13.6377
Iteration 12910, loss = -13.7312
Iteration 12920, loss = -13.2925
Iteration 12930, loss = -12.9528
Iteration 12940, loss = -13.4244
Iteration 12950, loss = -13.1613
Iteration 12960, loss = -13.5892
Iteration 12970, loss = -13.4414
Iteration 12980, loss = -13.4470
Iteration 12990, loss = -13.2712
Iteration 13000, loss = -13.1700
Om: 9.10%, s8: 6.64% accuracy
chi2: 1.608

Starting epoch 9
Iteration 13010, loss = -13.1542
Iteration 13020, loss = -13.2966
Iteration 13030, loss = -13.1267
Iteration 13040, loss = -13.7074
Iteration 13050, loss = -13.8428
Iteration 13060, loss = -13.3559
Iteration 13070, loss = -13.2235
Iteration 13080, loss = -14.1301
Iteration 13090, loss = -13.3339
Iteration 13100, loss = -12.4190
Iteration 13110, loss = -12.9997
Iteration 13120, loss = -12.9508
Iteration 13130, loss = -13.2237
Iteration 13140, loss = -13.5128
Iteration 13150, loss = -12.7832
Iteration 13160, loss = -13.6316
Iteration 13170, loss = -13.3487
Iteration 13180, loss = -13.6350
Iteration 13190, loss = -13.4215
Iteration 13200, loss = -13.7193
Iteration 13210, loss = -13.4347
Iteration 13220, loss = -13.4586
Iteration 13230, loss = -14.0053
Iteration 13240, loss = -13.9973
Iteration 13250, loss = -13.8510
Iteration 13260, loss = -13.7519
Iteration 13270, loss = -12.7705
Iteration 13280, loss = -13.7494
Iteration 13290, loss = -13.7359
Iteration 13300, loss = -13.9557
Iteration 13310, loss = -12.8795
Iteration 13320, loss = -13.3049
Iteration 13330, loss = -13.5945
Iteration 13340, loss = -13.8010
Iteration 13350, loss = -12.7737
Iteration 13360, loss = -13.5386
Iteration 13370, loss = -13.3324
Iteration 13380, loss = -12.8798
Iteration 13390, loss = -13.1937
Iteration 13400, loss = -12.8789
Iteration 13410, loss = -12.8778
Iteration 13420, loss = -12.9714
Iteration 13430, loss = -12.7777
Iteration 13440, loss = -13.3655
Iteration 13450, loss = -13.1219
Iteration 13460, loss = -13.3034
Iteration 13470, loss = -13.5557
Iteration 13480, loss = -13.8357
Iteration 13490, loss = -13.8666
Iteration 13500, loss = -13.2198
Iteration 13510, loss = -13.1464
Iteration 13520, loss = -13.5758
Iteration 13530, loss = -13.5083
Iteration 13540, loss = -13.4060
Iteration 13550, loss = -13.6506
Iteration 13560, loss = -12.7794
Iteration 13570, loss = -13.5098
Iteration 13580, loss = -13.3881
Iteration 13590, loss = -13.5086
Iteration 13600, loss = -13.7080
Iteration 13610, loss = -13.9697
Iteration 13620, loss = -13.0949
Iteration 13630, loss = -13.5796
Iteration 13640, loss = -13.6948
Iteration 13650, loss = -12.9476
Iteration 13660, loss = -13.6057
Iteration 13670, loss = -13.4529
Iteration 13680, loss = -13.7711
Iteration 13690, loss = -13.2875
Iteration 13700, loss = -13.2214
Iteration 13710, loss = -13.2212
Iteration 13720, loss = -13.4140
Iteration 13730, loss = -13.4378
Iteration 13740, loss = -13.5402
Iteration 13750, loss = -12.9316
Iteration 13760, loss = -13.1411
Iteration 13770, loss = -13.5176
Iteration 13780, loss = -13.0782
Iteration 13790, loss = -12.9216
Iteration 13800, loss = -14.1393
Iteration 13810, loss = -13.4271
Iteration 13820, loss = -13.0826
Iteration 13830, loss = -12.9867
Iteration 13840, loss = -13.0901
Iteration 13850, loss = -13.7671
Iteration 13860, loss = -13.3246
Iteration 13870, loss = -13.6670
Iteration 13880, loss = -13.4923
Iteration 13890, loss = -12.8895
Iteration 13900, loss = -13.5197
Iteration 13910, loss = -13.9641
Iteration 13920, loss = -13.6651
Iteration 13930, loss = -13.2016
Iteration 13940, loss = -13.2829
Iteration 13950, loss = -14.1571
Iteration 13960, loss = -13.1982
Iteration 13970, loss = -13.7795
Iteration 13980, loss = -13.8477
Iteration 13990, loss = -13.6744
Iteration 14000, loss = -13.5954
Om: 9.04%, s8: 6.58% accuracy
chi2: 1.258

Iteration 14010, loss = -13.1969
Iteration 14020, loss = -13.6919
Iteration 14030, loss = -13.6295
Iteration 14040, loss = -13.6435
Iteration 14050, loss = -13.7289
Iteration 14060, loss = -12.3955
Iteration 14070, loss = -13.4129
Iteration 14080, loss = -13.1574
Iteration 14090, loss = -13.5065
Iteration 14100, loss = -13.9369
Iteration 14110, loss = -13.1740
Iteration 14120, loss = -13.4384
Iteration 14130, loss = -14.0914
Iteration 14140, loss = -11.7354
Iteration 14150, loss = -13.3256
Iteration 14160, loss = -13.4855
Iteration 14170, loss = -12.8766
Iteration 14180, loss = -13.5768
Iteration 14190, loss = -13.7248
Iteration 14200, loss = -13.7224
Iteration 14210, loss = -13.2002
Iteration 14220, loss = -12.9417
Iteration 14230, loss = -13.2754
Iteration 14240, loss = -13.6115
Iteration 14250, loss = -13.4961
Iteration 14260, loss = -13.5183
Iteration 14270, loss = -13.8485
Iteration 14280, loss = -13.6795
Iteration 14290, loss = -13.8138
Iteration 14300, loss = -13.0358
Iteration 14310, loss = -13.8897
Iteration 14320, loss = -13.7706
Iteration 14330, loss = -13.3079
Iteration 14340, loss = -13.8327
Iteration 14350, loss = -13.4045
Iteration 14360, loss = -13.4718
Iteration 14370, loss = -13.5567
Iteration 14380, loss = -13.4707
Iteration 14390, loss = -13.3846
Iteration 14400, loss = -13.3748
Iteration 14410, loss = -13.3010
Iteration 14420, loss = -12.9971
Iteration 14430, loss = -13.2500
Iteration 14440, loss = -13.0999
Starting epoch 10
Iteration 14450, loss = -13.3930
Iteration 14460, loss = -13.1209
Iteration 14470, loss = -13.5014
Iteration 14480, loss = -13.2957
Iteration 14490, loss = -13.6202
Iteration 14500, loss = -13.5436
Iteration 14510, loss = -13.6379
Iteration 14520, loss = -13.6981
Iteration 14530, loss = -12.5706
Iteration 14540, loss = -13.7446
Iteration 14550, loss = -13.2201
Iteration 14560, loss = -13.8769
Iteration 14570, loss = -13.5181
Iteration 14580, loss = -13.4437
Iteration 14590, loss = -13.4229
Iteration 14600, loss = -13.6835
Iteration 14610, loss = -13.4161
Iteration 14620, loss = -13.5521
Iteration 14630, loss = -13.4358
Iteration 14640, loss = -13.8254
Iteration 14650, loss = -13.4807
Iteration 14660, loss = -13.4685
Iteration 14670, loss = -13.0200
Iteration 14680, loss = -12.5953
Iteration 14690, loss = -13.1916
Iteration 14700, loss = -13.6218
Iteration 14710, loss = -13.5580
Iteration 14720, loss = -13.2421
Iteration 14730, loss = -13.8445
Iteration 14740, loss = -13.3062
Iteration 14750, loss = -13.6133
Iteration 14760, loss = -13.3956
Iteration 14770, loss = -13.0511
Iteration 14780, loss = -13.4749
Iteration 14790, loss = -13.3861
Iteration 14800, loss = -13.7003
Iteration 14810, loss = -13.6985
Iteration 14820, loss = -13.2345
Iteration 14830, loss = -13.3523
Iteration 14840, loss = -13.7911
Iteration 14850, loss = -13.1588
Iteration 14860, loss = -13.8291
Iteration 14870, loss = -13.2692
Iteration 14880, loss = -13.2841
Iteration 14890, loss = -13.5325
Iteration 14900, loss = -13.5439
Iteration 14910, loss = -12.9888
Iteration 14920, loss = -13.6509
Iteration 14930, loss = -13.8108
Iteration 14940, loss = -13.7394
Iteration 14950, loss = -13.3906
Iteration 14960, loss = -13.3102
Iteration 14970, loss = -12.8800
Iteration 14980, loss = -13.7751
Iteration 14990, loss = -13.6473
Iteration 15000, loss = -14.2094
Om: 9.06%, s8: 6.58% accuracy
chi2: 1.855

Iteration 15010, loss = -12.9569
Iteration 15020, loss = -13.1317
Iteration 15030, loss = -13.9113
Iteration 15040, loss = -13.0091
Iteration 15050, loss = -13.2914
Iteration 15060, loss = -13.5946
Iteration 15070, loss = -13.6522
Iteration 15080, loss = -13.2819
Iteration 15090, loss = -13.6344
Iteration 15100, loss = -13.3745
Iteration 15110, loss = -13.9414
Iteration 15120, loss = -13.3274
Iteration 15130, loss = -13.3720
Iteration 15140, loss = -13.4543
Iteration 15150, loss = -13.3642
Iteration 15160, loss = -12.9674
Iteration 15170, loss = -12.4821
Iteration 15180, loss = -13.3638
Iteration 15190, loss = -13.3900
Iteration 15200, loss = -13.9002
Iteration 15210, loss = -13.3551
Iteration 15220, loss = -13.7443
Iteration 15230, loss = -13.7487
Iteration 15240, loss = -13.2720
Iteration 15250, loss = -13.1386
Iteration 15260, loss = -13.0138
Iteration 15270, loss = -13.0864
Iteration 15280, loss = -13.4354
Iteration 15290, loss = -13.6318
Iteration 15300, loss = -13.5505
Iteration 15310, loss = -13.7138
Iteration 15320, loss = -13.6652
Iteration 15330, loss = -12.8032
Iteration 15340, loss = -13.4573
Iteration 15350, loss = -13.5195
Iteration 15360, loss = -13.6871
Iteration 15370, loss = -12.9270
Iteration 15380, loss = -12.8054
Iteration 15390, loss = -13.3505
Iteration 15400, loss = -14.0437
Iteration 15410, loss = -13.4635
Iteration 15420, loss = -13.2594
Iteration 15430, loss = -13.6166
Iteration 15440, loss = -13.1473
Iteration 15450, loss = -13.0381
Iteration 15460, loss = -13.8453
Iteration 15470, loss = -13.5510
Iteration 15480, loss = -12.7289
Iteration 15490, loss = -13.8332
Iteration 15500, loss = -13.7153
Iteration 15510, loss = -13.4805
Iteration 15520, loss = -13.2976
Iteration 15530, loss = -13.7826
Iteration 15540, loss = -13.7873
Iteration 15550, loss = -13.4003
Iteration 15560, loss = -13.8868
Iteration 15570, loss = -13.6864
Iteration 15580, loss = -13.3855
Iteration 15590, loss = -13.5491
Iteration 15600, loss = -13.7523
Iteration 15610, loss = -13.7312
Iteration 15620, loss = -13.5498
Iteration 15630, loss = -13.5823
Iteration 15640, loss = -12.9695
Iteration 15650, loss = -13.3408
Iteration 15660, loss = -13.2907
Iteration 15670, loss = -12.8486
Iteration 15680, loss = -13.4626
Iteration 15690, loss = -13.3256
Iteration 15700, loss = -13.3547
Iteration 15710, loss = -12.9334
Iteration 15720, loss = -13.4268
Iteration 15730, loss = -13.6573
Iteration 15740, loss = -13.1104
Iteration 15750, loss = -13.3576
Iteration 15760, loss = -13.7878
Iteration 15770, loss = -13.4830
Iteration 15780, loss = -13.3639
Iteration 15790, loss = -13.8099
Iteration 15800, loss = -13.9345
Iteration 15810, loss = -13.4911
Iteration 15820, loss = -13.6295
Iteration 15830, loss = -13.0476
Iteration 15840, loss = -12.9161
Iteration 15850, loss = -13.0101
Iteration 15860, loss = -13.5933
Iteration 15870, loss = -13.5988
Iteration 15880, loss = -13.3177
Iteration 15890, loss = -13.1038
Starting epoch 11
Iteration 15900, loss = -13.5095
Iteration 15910, loss = -13.5064
Iteration 15920, loss = -13.0648
Iteration 15930, loss = -13.5555
Iteration 15940, loss = -13.7163
Iteration 15950, loss = -13.7273
Iteration 15960, loss = -13.5960
Iteration 15970, loss = -14.1390
Iteration 15980, loss = -13.5298
Iteration 15990, loss = -13.0091
Iteration 16000, loss = -13.4833
Om: 9.14%, s8: 6.63% accuracy
chi2: 1.828

Iteration 16010, loss = -13.3438
Iteration 16020, loss = -13.2729
Iteration 16030, loss = -13.6565
Iteration 16040, loss = -12.9039
Iteration 16050, loss = -13.7384
Iteration 16060, loss = -13.0698
Iteration 16070, loss = -13.5057
Iteration 16080, loss = -12.8428
Iteration 16090, loss = -13.7768
Iteration 16100, loss = -13.8202
Iteration 16110, loss = -13.3698
Iteration 16120, loss = -13.9364
Iteration 16130, loss = -13.8438
Iteration 16140, loss = -13.7343
Iteration 16150, loss = -13.9451
Iteration 16160, loss = -12.9030
Iteration 16170, loss = -13.7281
Iteration 16180, loss = -13.9291
Iteration 16190, loss = -14.1015
Iteration 16200, loss = -12.8846
Iteration 16210, loss = -13.3100
Iteration 16220, loss = -13.6295
Iteration 16230, loss = -13.9412
Iteration 16240, loss = -13.2404
Iteration 16250, loss = -13.7666
Iteration 16260, loss = -13.6949
Iteration 16270, loss = -12.8042
Iteration 16280, loss = -13.2342
Iteration 16290, loss = -13.0066
Iteration 16300, loss = -13.0684
Iteration 16310, loss = -13.5537
Iteration 16320, loss = -12.7667
Iteration 16330, loss = -13.3047
Iteration 16340, loss = -12.6774
Iteration 16350, loss = -13.6713
Iteration 16360, loss = -13.1823
Iteration 16370, loss = -13.9065
Iteration 16380, loss = -13.7712
Iteration 16390, loss = -12.9527
Iteration 16400, loss = -13.6494
Iteration 16410, loss = -14.1099
Iteration 16420, loss = -13.8274
Iteration 16430, loss = -13.6446
Iteration 16440, loss = -13.4126
Iteration 16450, loss = -13.3221
Iteration 16460, loss = -13.6480
Iteration 16470, loss = -13.4012
Iteration 16480, loss = -13.6371
Iteration 16490, loss = -13.6626
Iteration 16500, loss = -13.6294
Iteration 16510, loss = -13.2865
Iteration 16520, loss = -13.5962
Iteration 16530, loss = -13.6174
Iteration 16540, loss = -13.5455
Iteration 16550, loss = -13.3739
Iteration 16560, loss = -13.7992
Iteration 16570, loss = -13.6424
Iteration 16580, loss = -13.0782
Iteration 16590, loss = -13.2922
Iteration 16600, loss = -12.9377
Iteration 16610, loss = -13.5870
Iteration 16620, loss = -13.8437
Iteration 16630, loss = -13.6654
Iteration 16640, loss = -13.2460
Iteration 16650, loss = -13.4157
Iteration 16660, loss = -13.6793
Iteration 16670, loss = -13.5834
Iteration 16680, loss = -13.0939
Iteration 16690, loss = -13.7442
Iteration 16700, loss = -13.1319
Iteration 16710, loss = -13.2149
Iteration 16720, loss = -12.7480
Iteration 16730, loss = -13.3701
Iteration 16740, loss = -13.7622
Iteration 16750, loss = -13.3157
Iteration 16760, loss = -13.4715
Iteration 16770, loss = -13.5944
Iteration 16780, loss = -13.3563
Iteration 16790, loss = -13.3575
Iteration 16800, loss = -14.0565
Iteration 16810, loss = -13.6752
Iteration 16820, loss = -13.1186
Iteration 16830, loss = -13.6170
Iteration 16840, loss = -14.0413
Iteration 16850, loss = -13.5794
Iteration 16860, loss = -13.3367
Iteration 16870, loss = -13.9252
Iteration 16880, loss = -13.7604
Iteration 16890, loss = -13.8444
Iteration 16900, loss = -13.4699
Iteration 16910, loss = -13.6796
Iteration 16920, loss = -13.5138
Iteration 16930, loss = -13.5878
Iteration 16940, loss = -13.9025
Iteration 16950, loss = -13.1408
Iteration 16960, loss = -13.7276
Iteration 16970, loss = -13.1683
Iteration 16980, loss = -13.5578
Iteration 16990, loss = -13.6829
Iteration 17000, loss = -13.1902
Om: 8.92%, s8: 6.48% accuracy
chi2: 1.729

Iteration 17010, loss = -13.7780
Iteration 17020, loss = -13.9401
Iteration 17030, loss = -11.8720
Iteration 17040, loss = -13.0969
Iteration 17050, loss = -13.4950
Iteration 17060, loss = -13.1682
Iteration 17070, loss = -13.7101
Iteration 17080, loss = -13.7154
Iteration 17090, loss = -13.9355
Iteration 17100, loss = -13.0068
Iteration 17110, loss = -12.7790
Iteration 17120, loss = -13.1987
Iteration 17130, loss = -13.7129
Iteration 17140, loss = -13.8720
Iteration 17150, loss = -13.8414
Iteration 17160, loss = -13.8987
Iteration 17170, loss = -13.7283
Iteration 17180, loss = -14.0404
Iteration 17190, loss = -12.9933
Iteration 17200, loss = -14.1255
Iteration 17210, loss = -14.0675
Iteration 17220, loss = -13.3593
Iteration 17230, loss = -13.6780
Iteration 17240, loss = -13.7479
Iteration 17250, loss = -13.5417
Iteration 17260, loss = -13.9944
Iteration 17270, loss = -13.8992
Iteration 17280, loss = -13.5541
Iteration 17290, loss = -13.5636
Iteration 17300, loss = -13.4099
Iteration 17310, loss = -13.0800
Iteration 17320, loss = -13.7626
Iteration 17330, loss = -13.2342
Starting epoch 12
Iteration 17340, loss = -13.6349
Iteration 17350, loss = -13.0387
Iteration 17360, loss = -13.6770
Iteration 17370, loss = -13.2792
Iteration 17380, loss = -13.8274
Iteration 17390, loss = -13.5828
Iteration 17400, loss = -13.7444
Iteration 17410, loss = -13.4932
Iteration 17420, loss = -12.8373
Iteration 17430, loss = -13.7244
Iteration 17440, loss = -13.5342
Iteration 17450, loss = -13.9142
Iteration 17460, loss = -13.4522
Iteration 17470, loss = -13.5487
Iteration 17480, loss = -13.5469
Iteration 17490, loss = -13.2058
Iteration 17500, loss = -13.7101
Iteration 17510, loss = -13.9121
Iteration 17520, loss = -13.4539
Iteration 17530, loss = -13.9348
Iteration 17540, loss = -13.4302
Iteration 17550, loss = -13.1274
Iteration 17560, loss = -13.3042
Iteration 17570, loss = -12.3603
Iteration 17580, loss = -13.4792
Iteration 17590, loss = -13.8941
Iteration 17600, loss = -13.4211
Iteration 17610, loss = -13.5304
Iteration 17620, loss = -13.5981
Iteration 17630, loss = -13.5391
Iteration 17640, loss = -13.7822
Iteration 17650, loss = -13.6455
Iteration 17660, loss = -13.4287
Iteration 17670, loss = -13.2127
Iteration 17680, loss = -13.2848
Iteration 17690, loss = -13.6030
Iteration 17700, loss = -13.7130
Iteration 17710, loss = -13.3609
Iteration 17720, loss = -13.4858
Iteration 17730, loss = -13.9252
Iteration 17740, loss = -13.1781
Iteration 17750, loss = -13.5590
Iteration 17760, loss = -13.4928
Iteration 17770, loss = -13.7091
Iteration 17780, loss = -13.6579
Iteration 17790, loss = -13.7491
Iteration 17800, loss = -13.4228
Iteration 17810, loss = -13.7559
Iteration 17820, loss = -13.8525
Iteration 17830, loss = -13.9890
Iteration 17840, loss = -13.3603
Iteration 17850, loss = -13.0203
Iteration 17860, loss = -13.2467
Iteration 17870, loss = -13.6683
Iteration 17880, loss = -13.7608
Iteration 17890, loss = -14.3386
Iteration 17900, loss = -13.1773
Iteration 17910, loss = -13.5727
Iteration 17920, loss = -13.6968
Iteration 17930, loss = -12.8458
Iteration 17940, loss = -12.8710
Iteration 17950, loss = -13.5897
Iteration 17960, loss = -13.5510
Iteration 17970, loss = -13.4605
Iteration 17980, loss = -13.4825
Iteration 17990, loss = -13.6415
Iteration 18000, loss = -14.0998
Om: 8.63%, s8: 6.30% accuracy
chi2: 1.734

Iteration 18010, loss = -13.9465
Iteration 18020, loss = -13.7680
Iteration 18030, loss = -13.9699
Iteration 18040, loss = -13.1895
Iteration 18050, loss = -13.3423
Iteration 18060, loss = -13.0081
Iteration 18070, loss = -13.4443
Iteration 18080, loss = -13.4678
Iteration 18090, loss = -14.1123
Iteration 18100, loss = -13.4973
Iteration 18110, loss = -14.0328
Iteration 18120, loss = -13.9852
Iteration 18130, loss = -13.8229
Iteration 18140, loss = -13.4719
Iteration 18150, loss = -13.5238
Iteration 18160, loss = -13.2701
Iteration 18170, loss = -13.3385
Iteration 18180, loss = -13.8124
Iteration 18190, loss = -13.8226
Iteration 18200, loss = -14.1257
Iteration 18210, loss = -12.7865
Iteration 18220, loss = -12.7553
Iteration 18230, loss = -13.7524
Iteration 18240, loss = -13.3087
Iteration 18250, loss = -13.3469
Iteration 18260, loss = -13.6899
Iteration 18270, loss = -12.8978
Iteration 18280, loss = -13.4868
Iteration 18290, loss = -14.1318
Iteration 18300, loss = -13.4349
Iteration 18310, loss = -12.7469
Iteration 18320, loss = -13.1990
Iteration 18330, loss = -13.1288
Iteration 18340, loss = -13.4124
Iteration 18350, loss = -13.9514
Iteration 18360, loss = -14.0087
Iteration 18370, loss = -13.1843
Iteration 18380, loss = -14.0345
Iteration 18390, loss = -13.6571
Iteration 18400, loss = -13.7390
Iteration 18410, loss = -13.7531
Iteration 18420, loss = -13.7162
Iteration 18430, loss = -13.8116
Iteration 18440, loss = -13.5414
Iteration 18450, loss = -13.5516
Iteration 18460, loss = -13.6726
Iteration 18470, loss = -13.0727
Iteration 18480, loss = -13.6150
Iteration 18490, loss = -14.1068
Iteration 18500, loss = -14.1045
Iteration 18510, loss = -13.5979
Iteration 18520, loss = -13.0898
Iteration 18530, loss = -13.6588
Iteration 18540, loss = -13.2316
Iteration 18550, loss = -12.9791
Iteration 18560, loss = -12.7682
Iteration 18570, loss = -13.7248
Iteration 18580, loss = -12.8885
Iteration 18590, loss = -13.4365
Iteration 18600, loss = -13.3139
Iteration 18610, loss = -13.6115
Iteration 18620, loss = -13.9082
Iteration 18630, loss = -13.5419
Iteration 18640, loss = -13.3055
Iteration 18650, loss = -13.6169
Iteration 18660, loss = -13.6173
Iteration 18670, loss = -13.4740
Iteration 18680, loss = -13.4323
Iteration 18690, loss = -13.9721
Iteration 18700, loss = -13.8173
Iteration 18710, loss = -13.6850
Iteration 18720, loss = -13.7610
Iteration 18730, loss = -12.9181
Iteration 18740, loss = -13.3638
Iteration 18750, loss = -13.7004
Iteration 18760, loss = -14.0701
Iteration 18770, loss = -13.1537
Iteration 18780, loss = -13.3364
Starting epoch 13
Iteration 18790, loss = -13.0484
Iteration 18800, loss = -13.7750
Iteration 18810, loss = -13.4992
Iteration 18820, loss = -13.8929
Iteration 18830, loss = -14.0925
Iteration 18840, loss = -13.7634
Iteration 18850, loss = -13.5231
Iteration 18860, loss = -13.9892
Iteration 18870, loss = -13.8265
Iteration 18880, loss = -13.0071
Iteration 18890, loss = -13.4128
Iteration 18900, loss = -13.5530
Iteration 18910, loss = -13.7970
Iteration 18920, loss = -13.5833
Iteration 18930, loss = -13.6960
Iteration 18940, loss = -14.0659
Iteration 18950, loss = -13.4984
Iteration 18960, loss = -13.4752
Iteration 18970, loss = -13.4693
Iteration 18980, loss = -13.8189
Iteration 18990, loss = -14.0747
Iteration 19000, loss = -13.8132
Om: 8.46%, s8: 6.19% accuracy
chi2: 1.434

Iteration 19010, loss = -13.5929
Iteration 19020, loss = -13.9968
Iteration 19030, loss = -14.0919
Iteration 19040, loss = -14.2151
Iteration 19050, loss = -12.9692
Iteration 19060, loss = -14.0544
Iteration 19070, loss = -14.1086
Iteration 19080, loss = -14.3082
Iteration 19090, loss = -13.1372
Iteration 19100, loss = -13.6698
Iteration 19110, loss = -13.8760
Iteration 19120, loss = -14.1009
Iteration 19130, loss = -13.8988
Iteration 19140, loss = -13.6953
Iteration 19150, loss = -13.7482
Iteration 19160, loss = -13.5883
Iteration 19170, loss = -13.5115
Iteration 19180, loss = -13.6287
Iteration 19190, loss = -13.0758
Iteration 19200, loss = -13.5521
Iteration 19210, loss = -13.6206
Iteration 19220, loss = -13.7130
Iteration 19230, loss = -13.2240
Iteration 19240, loss = -13.4229
Iteration 19250, loss = -13.5180
Iteration 19260, loss = -13.6511
Iteration 19270, loss = -14.0836
Iteration 19280, loss = -13.2005
Iteration 19290, loss = -13.7379
Iteration 19300, loss = -13.9404
Iteration 19310, loss = -13.7269
Iteration 19320, loss = -13.9461
Iteration 19330, loss = -13.5890
Iteration 19340, loss = -13.5364
Iteration 19350, loss = -13.0550
Iteration 19360, loss = -13.1843
Iteration 19370, loss = -13.5016
Iteration 19380, loss = -13.5600
Iteration 19390, loss = -14.0303
Iteration 19400, loss = -13.4674
Iteration 19410, loss = -13.3568
Iteration 19420, loss = -13.5601
Iteration 19430, loss = -13.6584
Iteration 19440, loss = -13.4005
Iteration 19450, loss = -13.7002
Iteration 19460, loss = -13.6986
Iteration 19470, loss = -12.5604
Iteration 19480, loss = -13.2663
Iteration 19490, loss = -12.9308
Iteration 19500, loss = -13.5531
Iteration 19510, loss = -13.4518
Iteration 19520, loss = -13.6764
Iteration 19530, loss = -13.2514
Iteration 19540, loss = -13.1184
Iteration 19550, loss = -13.5129
Iteration 19560, loss = -13.9245
Iteration 19570, loss = -13.0680
Iteration 19580, loss = -14.0051
Iteration 19590, loss = -13.3075
Iteration 19600, loss = -13.2944
Iteration 19610, loss = -13.1758
Iteration 19620, loss = -13.8405
Iteration 19630, loss = -13.7620
Iteration 19640, loss = -13.3475
Iteration 19650, loss = -13.8485
Iteration 19660, loss = -13.5658
Iteration 19670, loss = -13.3112
Iteration 19680, loss = -13.6784
Iteration 19690, loss = -14.0850
Iteration 19700, loss = -13.5591
Iteration 19710, loss = -13.0300
Iteration 19720, loss = -13.6426
Iteration 19730, loss = -13.9715
Iteration 19740, loss = -13.7834
Iteration 19750, loss = -13.5978
Iteration 19760, loss = -13.7435
Iteration 19770, loss = -13.4444
Iteration 19780, loss = -13.7174
Iteration 19790, loss = -13.7265
Iteration 19800, loss = -13.8950
Iteration 19810, loss = -14.0979
Iteration 19820, loss = -14.0345
Iteration 19830, loss = -13.7968
Iteration 19840, loss = -13.1102
Iteration 19850, loss = -13.8252
Iteration 19860, loss = -13.2638
Iteration 19870, loss = -13.3929
Iteration 19880, loss = -14.0187
Iteration 19890, loss = -13.1745
Iteration 19900, loss = -13.7151
Iteration 19910, loss = -13.8360
Iteration 19920, loss = -12.5315
Iteration 19930, loss = -13.2236
Iteration 19940, loss = -13.7759
Iteration 19950, loss = -10.7456
Iteration 19960, loss = -12.3029
Iteration 19970, loss = -13.5811
Iteration 19980, loss = -13.6929
Iteration 19990, loss = -13.1658
Iteration 20000, loss = -13.1901
Om: 9.05%, s8: 6.61% accuracy
chi2: 1.968

Iteration 20010, loss = -13.1636
Iteration 20020, loss = -13.9473
Iteration 20030, loss = -14.1360
Iteration 20040, loss = -14.0518
Iteration 20050, loss = -13.8080
Iteration 20060, loss = -13.6675
Iteration 20070, loss = -14.0882
Iteration 20080, loss = -13.4839
Iteration 20090, loss = -13.8663
Iteration 20100, loss = -13.3137
Iteration 20110, loss = -13.3650
Iteration 20120, loss = -13.7639
Iteration 20130, loss = -13.5075
Iteration 20140, loss = -13.9099
Iteration 20150, loss = -13.8249
Iteration 20160, loss = -13.7986
Iteration 20170, loss = -13.6365
Iteration 20180, loss = -13.7911
Iteration 20190, loss = -13.5399
Iteration 20200, loss = -13.1980
Iteration 20210, loss = -13.6901
Iteration 20220, loss = -13.7072
Starting epoch 14
Iteration 20230, loss = -13.7429
Iteration 20240, loss = -13.5789
Iteration 20250, loss = -14.0716
Iteration 20260, loss = -13.1902
Iteration 20270, loss = -13.7948
Iteration 20280, loss = -13.6860
Iteration 20290, loss = -13.6694
Iteration 20300, loss = -13.7224
Iteration 20310, loss = -13.1688
Iteration 20320, loss = -13.9167
Iteration 20330, loss = -13.6088
Iteration 20340, loss = -13.9151
Iteration 20350, loss = -13.6888
Iteration 20360, loss = -13.4593
Iteration 20370, loss = -13.7954
Iteration 20380, loss = -13.5653
Iteration 20390, loss = -13.9837
Iteration 20400, loss = -13.8801
Iteration 20410, loss = -13.6439
Iteration 20420, loss = -13.9016
Iteration 20430, loss = -13.3422
Iteration 20440, loss = -13.7939
Iteration 20450, loss = -13.3580
Iteration 20460, loss = -12.9966
Iteration 20470, loss = -13.7438
Iteration 20480, loss = -13.9695
Iteration 20490, loss = -13.7094
Iteration 20500, loss = -13.5941
Iteration 20510, loss = -13.4861
Iteration 20520, loss = -13.3714
Iteration 20530, loss = -13.5517
Iteration 20540, loss = -13.6367
Iteration 20550, loss = -13.4257
Iteration 20560, loss = -13.6049
Iteration 20570, loss = -13.2663
Iteration 20580, loss = -14.2117
Iteration 20590, loss = -13.5725
Iteration 20600, loss = -13.3400
Iteration 20610, loss = -13.4480
Iteration 20620, loss = -13.9146
Iteration 20630, loss = -13.1034
Iteration 20640, loss = -13.9627
Iteration 20650, loss = -13.0445
Iteration 20660, loss = -12.9801
Iteration 20670, loss = -13.4849
Iteration 20680, loss = -13.9494
Iteration 20690, loss = -13.4679
Iteration 20700, loss = -14.1399
Iteration 20710, loss = -13.8714
Iteration 20720, loss = -14.3807
Iteration 20730, loss = -13.4444
Iteration 20740, loss = -12.8992
Iteration 20750, loss = -13.1632
Iteration 20760, loss = -13.9522
Iteration 20770, loss = -13.6185
Iteration 20780, loss = -14.2236
Iteration 20790, loss = -12.9375
Iteration 20800, loss = -13.0759
Iteration 20810, loss = -13.4862
Iteration 20820, loss = -13.0872
Iteration 20830, loss = -13.5706
Iteration 20840, loss = -13.9736
Iteration 20850, loss = -13.7143
Iteration 20860, loss = -13.9967
Iteration 20870, loss = -13.1380
Iteration 20880, loss = -13.2337
Iteration 20890, loss = -14.2773
Iteration 20900, loss = -13.4506
Iteration 20910, loss = -13.6011
Iteration 20920, loss = -13.8074
Iteration 20930, loss = -13.4387
Iteration 20940, loss = -13.2844
Iteration 20950, loss = -13.0332
Iteration 20960, loss = -13.3833
Iteration 20970, loss = -13.4911
Iteration 20980, loss = -13.5724
Iteration 20990, loss = -13.5983
Iteration 21000, loss = -13.8359
Om: 8.95%, s8: 6.51% accuracy
chi2: 1.624

Iteration 21010, loss = -13.6145
Iteration 21020, loss = -13.7441
Iteration 21030, loss = -13.4547
Iteration 21040, loss = -13.2333
Iteration 21050, loss = -13.4619
Iteration 21060, loss = -13.3238
Iteration 21070, loss = -13.6310
Iteration 21080, loss = -13.6028
Iteration 21090, loss = -13.7992
Iteration 21100, loss = -13.8300
Iteration 21110, loss = -13.0710
Iteration 21120, loss = -13.9437
Iteration 21130, loss = -13.4724
Iteration 21140, loss = -13.7965
Iteration 21150, loss = -13.4692
Iteration 21160, loss = -12.7750
Iteration 21170, loss = -13.6148
Iteration 21180, loss = -13.9949
Iteration 21190, loss = -13.7557
Iteration 21200, loss = -13.2565
Iteration 21210, loss = -13.5078
Iteration 21220, loss = -13.2545
Iteration 21230, loss = -13.5535
Iteration 21240, loss = -14.0463
Iteration 21250, loss = -13.7529
Iteration 21260, loss = -12.9383
Iteration 21270, loss = -14.0238
Iteration 21280, loss = -13.5496
Iteration 21290, loss = -13.7333
Iteration 21300, loss = -13.4709
Iteration 21310, loss = -13.6335
Iteration 21320, loss = -13.8721
Iteration 21330, loss = -13.5448
Iteration 21340, loss = -13.6813
Iteration 21350, loss = -14.0171
Iteration 21360, loss = -13.1126
Iteration 21370, loss = -13.1439
Iteration 21380, loss = -13.8499
Iteration 21390, loss = -13.8917
Iteration 21400, loss = -13.6325
Iteration 21410, loss = -12.9351
Iteration 21420, loss = -13.5295
Iteration 21430, loss = -13.2818
Iteration 21440, loss = -13.1259
Iteration 21450, loss = -12.9030
Iteration 21460, loss = -13.3700
Iteration 21470, loss = -13.0926
Iteration 21480, loss = -13.6395
Iteration 21490, loss = -12.8675
Iteration 21500, loss = -13.6233
Iteration 21510, loss = -13.6012
Iteration 21520, loss = -13.5153
Iteration 21530, loss = -13.3217
Iteration 21540, loss = -13.5246
Iteration 21550, loss = -13.7428
Iteration 21560, loss = -13.5649
Iteration 21570, loss = -13.8383
Iteration 21580, loss = -13.5813
Iteration 21590, loss = -13.6948
Iteration 21600, loss = -13.5989
Iteration 21610, loss = -13.3956
Iteration 21620, loss = -13.3367
Iteration 21630, loss = -13.2610
Iteration 21640, loss = -13.6575
Iteration 21650, loss = -13.3616
Iteration 21660, loss = -13.4686
Iteration 21670, loss = -13.3106
Starting epoch 15
Iteration 21680, loss = -13.4885
Iteration 21690, loss = -13.2878
Iteration 21700, loss = -13.2834
Iteration 21710, loss = -13.6040
Iteration 21720, loss = -13.6847
Iteration 21730, loss = -13.9475
Iteration 21740, loss = -13.5391
Iteration 21750, loss = -13.9558
Iteration 21760, loss = -13.9652
Iteration 21770, loss = -13.2734
Iteration 21780, loss = -13.6623
Iteration 21790, loss = -13.6828
Iteration 21800, loss = -13.4567
Iteration 21810, loss = -13.8594
Iteration 21820, loss = -13.0922
Iteration 21830, loss = -14.0235
Iteration 21840, loss = -13.3035
Iteration 21850, loss = -13.4697
Iteration 21860, loss = -13.2148
Iteration 21870, loss = -13.6500
Iteration 21880, loss = -13.8039
Iteration 21890, loss = -13.4714
Iteration 21900, loss = -14.2785
Iteration 21910, loss = -14.3792
Iteration 21920, loss = -13.8196
Iteration 21930, loss = -14.1657
Iteration 21940, loss = -12.8986
Iteration 21950, loss = -13.7245
Iteration 21960, loss = -13.8146
Iteration 21970, loss = -14.1012
Iteration 21980, loss = -12.8981
Iteration 21990, loss = -13.0997
Iteration 22000, loss = -13.7679
Om: 9.31%, s8: 6.75% accuracy
chi2: 2.439

Iteration 22010, loss = -14.0734
Iteration 22020, loss = -13.5480
Iteration 22030, loss = -13.6586
Iteration 22040, loss = -13.4138
Iteration 22050, loss = -12.8000
Iteration 22060, loss = -13.1668
Iteration 22070, loss = -13.0949
Iteration 22080, loss = -12.9705
Iteration 22090, loss = -13.3811
Iteration 22100, loss = -13.5408
Iteration 22110, loss = -13.9129
Iteration 22120, loss = -13.2505
Iteration 22130, loss = -13.6955
Iteration 22140, loss = -13.3784
Iteration 22150, loss = -13.7747
Iteration 22160, loss = -13.9798
Iteration 22170, loss = -13.3592
Iteration 22180, loss = -13.5332
Iteration 22190, loss = -14.0315
Iteration 22200, loss = -14.0035
Iteration 22210, loss = -13.8249
Iteration 22220, loss = -13.6990
Iteration 22230, loss = -13.2182
Iteration 22240, loss = -14.0057
Iteration 22250, loss = -13.4618
Iteration 22260, loss = -13.8145
Iteration 22270, loss = -13.2400
Iteration 22280, loss = -13.7609
Iteration 22290, loss = -13.4288
Iteration 22300, loss = -13.5828
Iteration 22310, loss = -13.8468
Iteration 22320, loss = -13.4735
Iteration 22330, loss = -13.3605
Iteration 22340, loss = -13.8060
Iteration 22350, loss = -13.7058
Iteration 22360, loss = -12.8625
Iteration 22370, loss = -13.2509
Iteration 22380, loss = -13.1821
Iteration 22390, loss = -13.5389
Iteration 22400, loss = -13.8117
Iteration 22410, loss = -13.8355
Iteration 22420, loss = -13.5329
Iteration 22430, loss = -13.3195
Iteration 22440, loss = -13.9155
Iteration 22450, loss = -13.7223
Iteration 22460, loss = -13.0308
Iteration 22470, loss = -13.9287
Iteration 22480, loss = -13.6788
Iteration 22490, loss = -13.3434
Iteration 22500, loss = -12.8719
Iteration 22510, loss = -13.6257
Iteration 22520, loss = -13.9559
Iteration 22530, loss = -13.4078
Iteration 22540, loss = -13.6904
Iteration 22550, loss = -13.7269
Iteration 22560, loss = -13.4631
Iteration 22570, loss = -13.8614
Iteration 22580, loss = -14.0361
Iteration 22590, loss = -13.6805
Iteration 22600, loss = -13.4483
Iteration 22610, loss = -13.3582
Iteration 22620, loss = -14.2591
Iteration 22630, loss = -13.3772
Iteration 22640, loss = -13.5087
Iteration 22650, loss = -13.9347
Iteration 22660, loss = -13.8810
Iteration 22670, loss = -13.9032
Iteration 22680, loss = -13.5724
Iteration 22690, loss = -13.9582
Iteration 22700, loss = -14.1388
Iteration 22710, loss = -13.9323
Iteration 22720, loss = -13.7763
Iteration 22730, loss = -13.2349
Iteration 22740, loss = -13.7313
Iteration 22750, loss = -13.6567
Iteration 22760, loss = -13.7732
Iteration 22770, loss = -13.8153
Iteration 22780, loss = -13.4532
Iteration 22790, loss = -13.7375
Iteration 22800, loss = -13.9016
Iteration 22810, loss = -12.0907
Iteration 22820, loss = -13.4341
Iteration 22830, loss = -13.8160
Iteration 22840, loss = -13.3364
Iteration 22850, loss = -12.9445
Iteration 22860, loss = -14.1899
Iteration 22870, loss = -13.7290
Iteration 22880, loss = -13.4818
Iteration 22890, loss = -12.9505
Iteration 22900, loss = -13.3959
Iteration 22910, loss = -14.0342
Iteration 22920, loss = -13.9107
Iteration 22930, loss = -14.0319
Iteration 22940, loss = -13.9300
Iteration 22950, loss = -13.6256
Iteration 22960, loss = -14.1694
Iteration 22970, loss = -13.4546
Iteration 22980, loss = -14.1373
Iteration 22990, loss = -13.8434
Iteration 23000, loss = -13.1546
Om: 8.96%, s8: 6.58% accuracy
chi2: 1.652

Iteration 23010, loss = -13.8899
Iteration 23020, loss = -13.7301
Iteration 23030, loss = -13.7752
Iteration 23040, loss = -13.8584
Iteration 23050, loss = -14.1265
Iteration 23060, loss = -13.5215
Iteration 23070, loss = -13.7184
Iteration 23080, loss = -13.7802
Iteration 23090, loss = -12.9125
Iteration 23100, loss = -13.4767
Iteration 23110, loss = -13.4378
Starting epoch 16
Iteration 23120, loss = -13.5267
Iteration 23130, loss = -13.1123
Iteration 23140, loss = -13.8477
Iteration 23150, loss = -13.3836
Iteration 23160, loss = -13.6798
Iteration 23170, loss = -13.5375
Iteration 23180, loss = -13.6012
Iteration 23190, loss = -13.6216
Iteration 23200, loss = -13.3693
Iteration 23210, loss = -13.5604
Iteration 23220, loss = -13.7622
Iteration 23230, loss = -14.1444
Iteration 23240, loss = -13.6741
Iteration 23250, loss = -13.5802
Iteration 23260, loss = -13.2492
Iteration 23270, loss = -13.5305
Iteration 23280, loss = -13.5256
Iteration 23290, loss = -13.5867
Iteration 23300, loss = -13.6489
Iteration 23310, loss = -13.9157
Iteration 23320, loss = -13.7740
Iteration 23330, loss = -13.9765
Iteration 23340, loss = -13.7223
Iteration 23350, loss = -12.6477
Iteration 23360, loss = -13.6578
Iteration 23370, loss = -13.8282
Iteration 23380, loss = -13.9084
Iteration 23390, loss = -13.7095
Iteration 23400, loss = -14.0555
Iteration 23410, loss = -13.4482
Iteration 23420, loss = -13.7914
Iteration 23430, loss = -13.5229
Iteration 23440, loss = -13.7175
Iteration 23450, loss = -13.5713
Iteration 23460, loss = -13.0282
Iteration 23470, loss = -13.5747
Iteration 23480, loss = -13.9203
Iteration 23490, loss = -13.2821
Iteration 23500, loss = -13.4217
Iteration 23510, loss = -13.9798
Iteration 23520, loss = -13.2031
Iteration 23530, loss = -13.6912
Iteration 23540, loss = -13.5803
Iteration 23550, loss = -13.7343
Iteration 23560, loss = -13.7722
Iteration 23570, loss = -13.7798
Iteration 23580, loss = -13.4434
Iteration 23590, loss = -14.1784
Iteration 23600, loss = -14.1295
Iteration 23610, loss = -13.9850
Iteration 23620, loss = -13.3805
Iteration 23630, loss = -13.5242
Iteration 23640, loss = -13.5687
Iteration 23650, loss = -13.8894
Iteration 23660, loss = -13.5545
Iteration 23670, loss = -14.2354
Iteration 23680, loss = -13.6061
Iteration 23690, loss = -13.4149
Iteration 23700, loss = -13.5426
Iteration 23710, loss = -13.1824
Iteration 23720, loss = -13.8328
Iteration 23730, loss = -14.1233
Iteration 23740, loss = -13.6192
Iteration 23750, loss = -14.1775
Iteration 23760, loss = -13.5759
Iteration 23770, loss = -13.4669
Iteration 23780, loss = -13.9114
Iteration 23790, loss = -13.4307
Iteration 23800, loss = -13.6204
Iteration 23810, loss = -13.8514
Iteration 23820, loss = -13.7684
Iteration 23830, loss = -13.1352
Iteration 23840, loss = -13.9699
Iteration 23850, loss = -13.6410
Iteration 23860, loss = -13.8614
Iteration 23870, loss = -14.0007
Iteration 23880, loss = -13.7668
Iteration 23890, loss = -14.4193
Iteration 23900, loss = -14.1317
Iteration 23910, loss = -13.8270
Iteration 23920, loss = -13.3870
Iteration 23930, loss = -13.7758
Iteration 23940, loss = -13.5653
Iteration 23950, loss = -13.8509
Iteration 23960, loss = -13.9453
Iteration 23970, loss = -13.9432
Iteration 23980, loss = -14.0750
Iteration 23990, loss = -13.2354
Iteration 24000, loss = -13.2860
Om: 8.15%, s8: 5.95% accuracy
chi2: 1.668

Iteration 24010, loss = -14.3608
Iteration 24020, loss = -13.1588
Iteration 24030, loss = -13.2561
Iteration 24040, loss = -13.6537
Iteration 24050, loss = -13.0245
Iteration 24060, loss = -13.4287
Iteration 24070, loss = -13.9543
Iteration 24080, loss = -13.5662
Iteration 24090, loss = -13.2859
Iteration 24100, loss = -13.7319
Iteration 24110, loss = -13.2915
Iteration 24120, loss = -13.6071
Iteration 24130, loss = -13.9043
Iteration 24140, loss = -14.2709
Iteration 24150, loss = -13.2248
Iteration 24160, loss = -14.0724
Iteration 24170, loss = -13.6398
Iteration 24180, loss = -13.6767
Iteration 24190, loss = -13.5068
Iteration 24200, loss = -13.2324
Iteration 24210, loss = -14.0322
Iteration 24220, loss = -13.7695
Iteration 24230, loss = -13.9093
Iteration 24240, loss = -14.1647
Iteration 24250, loss = -13.4521
Iteration 24260, loss = -13.6920
Iteration 24270, loss = -14.1870
Iteration 24280, loss = -14.0792
Iteration 24290, loss = -13.8994
Iteration 24300, loss = -12.8381
Iteration 24310, loss = -13.6453
Iteration 24320, loss = -14.0468
Iteration 24330, loss = -13.7529
Iteration 24340, loss = -13.4969
Iteration 24350, loss = -13.7261
Iteration 24360, loss = -13.2619
Iteration 24370, loss = -13.8428
Iteration 24380, loss = -13.7916
Iteration 24390, loss = -14.1985
Iteration 24400, loss = -13.7543
Iteration 24410, loss = -13.7485
Iteration 24420, loss = -13.9566
Iteration 24430, loss = -13.6929
Iteration 24440, loss = -13.6878
Iteration 24450, loss = -13.6577
Iteration 24460, loss = -13.4951
Iteration 24470, loss = -14.0142
Iteration 24480, loss = -13.8219
Iteration 24490, loss = -13.9577
Iteration 24500, loss = -14.0636
Iteration 24510, loss = -13.4976
Iteration 24520, loss = -13.8138
Iteration 24530, loss = -13.9116
Iteration 24540, loss = -13.9796
Iteration 24550, loss = -13.1454
Iteration 24560, loss = -13.7155
Starting epoch 17
Iteration 24570, loss = -13.8670
Iteration 24580, loss = -13.6731
Iteration 24590, loss = -13.9441
Iteration 24600, loss = -14.1006
Iteration 24610, loss = -13.7539
Iteration 24620, loss = -14.3392
Iteration 24630, loss = -13.7357
Iteration 24640, loss = -14.5046
Iteration 24650, loss = -13.8770
Iteration 24660, loss = -13.5168
Iteration 24670, loss = -13.5563
Iteration 24680, loss = -13.9614
Iteration 24690, loss = -13.9433
Iteration 24700, loss = -14.1067
Iteration 24710, loss = -13.5789
Iteration 24720, loss = -14.3250
Iteration 24730, loss = -13.3143
Iteration 24740, loss = -13.5170
Iteration 24750, loss = -13.9107
Iteration 24760, loss = -14.1444
Iteration 24770, loss = -14.3253
Iteration 24780, loss = -14.2041
Iteration 24790, loss = -14.5065
Iteration 24800, loss = -14.2058
Iteration 24810, loss = -13.8977
Iteration 24820, loss = -14.0618
Iteration 24830, loss = -13.2145
Iteration 24840, loss = -14.2794
Iteration 24850, loss = -13.7545
Iteration 24860, loss = -14.4637
Iteration 24870, loss = -12.4358
Iteration 24880, loss = -13.7716
Iteration 24890, loss = -14.1327
Iteration 24900, loss = -14.3115
Iteration 24910, loss = -13.7441
Iteration 24920, loss = -14.1220
Iteration 24930, loss = -14.1628
Iteration 24940, loss = -13.8792
Iteration 24950, loss = -13.5962
Iteration 24960, loss = -13.3795
Iteration 24970, loss = -13.4140
Iteration 24980, loss = -13.3639
Iteration 24990, loss = -13.5927
Iteration 25000, loss = -13.8256
Om: 8.11%, s8: 5.89% accuracy
chi2: 1.493

Iteration 25010, loss = -13.3452
Iteration 25020, loss = -13.6101
Iteration 25030, loss = -13.7832
Iteration 25040, loss = -13.8514
Iteration 25050, loss = -14.0326
Iteration 25060, loss = -13.7686
Iteration 25070, loss = -13.9829
Iteration 25080, loss = -14.2679
Iteration 25090, loss = -14.0569
Iteration 25100, loss = -13.2593
Iteration 25110, loss = -14.0441
Iteration 25120, loss = -13.5108
Iteration 25130, loss = -14.1283
Iteration 25140, loss = -13.8278
Iteration 25150, loss = -13.5009
Iteration 25160, loss = -13.8600
Iteration 25170, loss = -14.2533
Iteration 25180, loss = -13.3701
Iteration 25190, loss = -13.3696
Iteration 25200, loss = -14.2289
Iteration 25210, loss = -13.8805
Iteration 25220, loss = -13.8423
Iteration 25230, loss = -14.0913
Iteration 25240, loss = -14.2452
Iteration 25250, loss = -13.7102
Iteration 25260, loss = -13.7930
Iteration 25270, loss = -13.2735
Iteration 25280, loss = -14.0247
Iteration 25290, loss = -14.3962
Iteration 25300, loss = -14.2532
Iteration 25310, loss = -13.6506
Iteration 25320, loss = -13.2707
Iteration 25330, loss = -13.6326
Iteration 25340, loss = -13.9745
Iteration 25350, loss = -13.3145
Iteration 25360, loss = -13.9159
Iteration 25370, loss = -13.7219
Iteration 25380, loss = -13.7657
Iteration 25390, loss = -13.7267
Iteration 25400, loss = -14.0841
Iteration 25410, loss = -13.7564
Iteration 25420, loss = -13.4159
Iteration 25430, loss = -13.6424
Iteration 25440, loss = -13.5576
Iteration 25450, loss = -13.2590
Iteration 25460, loss = -13.6600
Iteration 25470, loss = -14.0374
Iteration 25480, loss = -13.8297
Iteration 25490, loss = -13.1523
Iteration 25500, loss = -13.3063
Iteration 25510, loss = -13.9604
Iteration 25520, loss = -13.7557
Iteration 25530, loss = -13.5977
Iteration 25540, loss = -13.7556
Iteration 25550, loss = -13.4736
Iteration 25560, loss = -14.1309
Iteration 25570, loss = -13.6088
Iteration 25580, loss = -14.1136
Iteration 25590, loss = -13.8839
Iteration 25600, loss = -13.8274
Iteration 25610, loss = -13.9172
Iteration 25620, loss = -13.0302
Iteration 25630, loss = -13.6506
Iteration 25640, loss = -13.5219
Iteration 25650, loss = -13.4741
Iteration 25660, loss = -14.2536
Iteration 25670, loss = -13.1998
Iteration 25680, loss = -13.8622
Iteration 25690, loss = -13.7824
Iteration 25700, loss = -12.6090
Iteration 25710, loss = -13.3081
Iteration 25720, loss = -13.5608
Iteration 25730, loss = -13.5049
Iteration 25740, loss = -13.8385
Iteration 25750, loss = -13.8849
Iteration 25760, loss = -13.7331
Iteration 25770, loss = -13.4583
Iteration 25780, loss = -13.2357
Iteration 25790, loss = -13.4584
Iteration 25800, loss = -13.8948
Iteration 25810, loss = -14.1894
Iteration 25820, loss = -13.8744
Iteration 25830, loss = -14.1023
Iteration 25840, loss = -13.8114
Iteration 25850, loss = -14.1232
Iteration 25860, loss = -13.6087
Iteration 25870, loss = -14.2736
Iteration 25880, loss = -14.0028
Iteration 25890, loss = -12.8465
Iteration 25900, loss = -14.0477
Iteration 25910, loss = -13.9096
Iteration 25920, loss = -13.8290
Iteration 25930, loss = -14.0478
Iteration 25940, loss = -13.6507
Iteration 25950, loss = -13.6954
Iteration 25960, loss = -13.7665
Iteration 25970, loss = -13.8947
Iteration 25980, loss = -13.3890
Iteration 25990, loss = -13.6838
Iteration 26000, loss = -13.4659
Om: 8.99%, s8: 6.38% accuracy
chi2: 1.384

Starting epoch 18
Iteration 26010, loss = -13.6985
Iteration 26020, loss = -13.4653
Iteration 26030, loss = -13.9388
Iteration 26040, loss = -13.3884
Iteration 26050, loss = -13.7050
Iteration 26060, loss = -13.9119
Iteration 26070, loss = -13.7894
Iteration 26080, loss = -13.7464
Iteration 26090, loss = -13.6508
Iteration 26100, loss = -13.7048
Iteration 26110, loss = -13.9102
Iteration 26120, loss = -14.0051
Iteration 26130, loss = -13.5941
Iteration 26140, loss = -13.6306
Iteration 26150, loss = -13.4466
Iteration 26160, loss = -13.7320
Iteration 26170, loss = -14.0069
Iteration 26180, loss = -13.8983
Iteration 26190, loss = -13.6054
Iteration 26200, loss = -13.9450
Iteration 26210, loss = -13.7552
Iteration 26220, loss = -13.7767
Iteration 26230, loss = -13.3618
Iteration 26240, loss = -13.0662
Iteration 26250, loss = -13.4865
Iteration 26260, loss = -14.2096
Iteration 26270, loss = -13.7404
Iteration 26280, loss = -13.5774
Iteration 26290, loss = -13.9715
Iteration 26300, loss = -13.7005
Iteration 26310, loss = -14.2001
Iteration 26320, loss = -13.9107
Iteration 26330, loss = -13.7785
Iteration 26340, loss = -13.4814
Iteration 26350, loss = -13.6621
Iteration 26360, loss = -14.1295
Iteration 26370, loss = -13.9330
Iteration 26380, loss = -13.4676
Iteration 26390, loss = -13.6457
Iteration 26400, loss = -13.9904
Iteration 26410, loss = -13.7202
Iteration 26420, loss = -14.0836
Iteration 26430, loss = -13.4979
Iteration 26440, loss = -13.3300
Iteration 26450, loss = -13.8150
Iteration 26460, loss = -14.0813
Iteration 26470, loss = -13.7605
Iteration 26480, loss = -14.3115
Iteration 26490, loss = -13.5052
Iteration 26500, loss = -14.1891
Iteration 26510, loss = -13.3910
Iteration 26520, loss = -13.3309
Iteration 26530, loss = -13.1747
Iteration 26540, loss = -13.6973
Iteration 26550, loss = -13.5438
Iteration 26560, loss = -14.1975
Iteration 26570, loss = -13.6783
Iteration 26580, loss = -13.6800
Iteration 26590, loss = -14.0953
Iteration 26600, loss = -13.0775
Iteration 26610, loss = -13.1850
Iteration 26620, loss = -14.2804
Iteration 26630, loss = -14.0319
Iteration 26640, loss = -14.3120
Iteration 26650, loss = -13.6083
Iteration 26660, loss = -13.8049
Iteration 26670, loss = -13.9182
Iteration 26680, loss = -14.0603
Iteration 26690, loss = -14.0823
Iteration 26700, loss = -13.9241
Iteration 26710, loss = -13.7459
Iteration 26720, loss = -13.2935
Iteration 26730, loss = -13.6540
Iteration 26740, loss = -13.7128
Iteration 26750, loss = -14.2068
Iteration 26760, loss = -14.1814
Iteration 26770, loss = -13.7735
Iteration 26780, loss = -14.2542
Iteration 26790, loss = -14.1331
Iteration 26800, loss = -13.9825
Iteration 26810, loss = -13.6423
Iteration 26820, loss = -13.5748
Iteration 26830, loss = -13.7890
Iteration 26840, loss = -14.1042
Iteration 26850, loss = -13.6572
Iteration 26860, loss = -13.9653
Iteration 26870, loss = -14.3463
Iteration 26880, loss = -13.3845
Iteration 26890, loss = -12.7743
Iteration 26900, loss = -14.1797
Iteration 26910, loss = -13.1611
Iteration 26920, loss = -13.2668
Iteration 26930, loss = -13.9896
Iteration 26940, loss = -13.5430
Iteration 26950, loss = -13.6000
Iteration 26960, loss = -14.1980
Iteration 26970, loss = -13.7970
Iteration 26980, loss = -12.9975
Iteration 26990, loss = -13.7050
Iteration 27000, loss = -13.3621
Om: 8.87%, s8: 6.44% accuracy
chi2: 1.525

Iteration 27010, loss = -13.9897
Iteration 27020, loss = -14.0542
Iteration 27030, loss = -14.1177
Iteration 27040, loss = -13.6245
Iteration 27050, loss = -14.1568
Iteration 27060, loss = -13.6876
Iteration 27070, loss = -13.8738
Iteration 27080, loss = -13.5253
Iteration 27090, loss = -13.8445
Iteration 27100, loss = -14.0023
Iteration 27110, loss = -13.6601
Iteration 27120, loss = -13.8129
Iteration 27130, loss = -14.4792
Iteration 27140, loss = -13.3266
Iteration 27150, loss = -13.8218
Iteration 27160, loss = -14.1550
Iteration 27170, loss = -13.8106
Iteration 27180, loss = -14.1904
Iteration 27190, loss = -13.1835
Iteration 27200, loss = -13.8621
Iteration 27210, loss = -13.7906
Iteration 27220, loss = -14.0210
Iteration 27230, loss = -13.3781
Iteration 27240, loss = -13.9451
Iteration 27250, loss = -13.3829
Iteration 27260, loss = -13.6962
Iteration 27270, loss = -13.6474
Iteration 27280, loss = -14.2427
Iteration 27290, loss = -14.1264
Iteration 27300, loss = -13.5278
Iteration 27310, loss = -13.8732
Iteration 27320, loss = -13.8781
Iteration 27330, loss = -13.9759
Iteration 27340, loss = -13.7732
Iteration 27350, loss = -13.7385
Iteration 27360, loss = -14.1499
Iteration 27370, loss = -13.7026
Iteration 27380, loss = -13.8276
Iteration 27390, loss = -13.7197
Iteration 27400, loss = -13.2271
Iteration 27410, loss = -13.9117
Iteration 27420, loss = -13.8832
Iteration 27430, loss = -14.0557
Iteration 27440, loss = -13.3583
Iteration 27450, loss = -13.5939
Starting epoch 19
Iteration 27460, loss = -13.8991
Iteration 27470, loss = -13.8179
Iteration 27480, loss = -13.9637
Iteration 27490, loss = -13.8088
Iteration 27500, loss = -13.8454
Iteration 27510, loss = -14.3477
Iteration 27520, loss = -14.0916
Iteration 27530, loss = -14.4398
Iteration 27540, loss = -13.8336
Iteration 27550, loss = -13.6991
Iteration 27560, loss = -13.6413
Iteration 27570, loss = -14.0320
Iteration 27580, loss = -13.9491
Iteration 27590, loss = -13.9995
Iteration 27600, loss = -13.5262
Iteration 27610, loss = -14.2184
Iteration 27620, loss = -13.0856
Iteration 27630, loss = -13.6204
Iteration 27640, loss = -14.0777
Iteration 27650, loss = -14.2608
Iteration 27660, loss = -14.3193
Iteration 27670, loss = -14.1139
Iteration 27680, loss = -14.2505
Iteration 27690, loss = -14.4386
Iteration 27700, loss = -14.0436
Iteration 27710, loss = -14.2654
Iteration 27720, loss = -13.1756
Iteration 27730, loss = -14.2430
Iteration 27740, loss = -14.0465
Iteration 27750, loss = -14.4717
Iteration 27760, loss = -13.2045
Iteration 27770, loss = -13.6630
Iteration 27780, loss = -14.3363
Iteration 27790, loss = -14.4477
Iteration 27800, loss = -13.7137
Iteration 27810, loss = -14.0663
Iteration 27820, loss = -14.2693
Iteration 27830, loss = -14.0057
Iteration 27840, loss = -13.4221
Iteration 27850, loss = -13.3043
Iteration 27860, loss = -13.2272
Iteration 27870, loss = -13.6404
Iteration 27880, loss = -13.7435
Iteration 27890, loss = -13.8088
Iteration 27900, loss = -13.5624
Iteration 27910, loss = -13.7241
Iteration 27920, loss = -13.9164
Iteration 27930, loss = -13.8488
Iteration 27940, loss = -14.0337
Iteration 27950, loss = -14.0312
Iteration 27960, loss = -13.7527
Iteration 27970, loss = -13.9004
Iteration 27980, loss = -14.1633
Iteration 27990, loss = -12.9685
Iteration 28000, loss = -13.8779
Om: 8.06%, s8: 5.91% accuracy
chi2: 1.718

Iteration 28010, loss = -13.5724
Iteration 28020, loss = -14.3094
Iteration 28030, loss = -13.8594
Iteration 28040, loss = -13.9039
Iteration 28050, loss = -14.0327
Iteration 28060, loss = -14.1480
Iteration 28070, loss = -13.6018
Iteration 28080, loss = -13.6395
Iteration 28090, loss = -14.2307
Iteration 28100, loss = -13.8162
Iteration 28110, loss = -13.8645
Iteration 28120, loss = -14.0646
Iteration 28130, loss = -14.2675
Iteration 28140, loss = -13.2749
Iteration 28150, loss = -13.7798
Iteration 28160, loss = -13.3989
Iteration 28170, loss = -14.2762
Iteration 28180, loss = -14.3203
Iteration 28190, loss = -14.2843
Iteration 28200, loss = -13.8814
Iteration 28210, loss = -13.7332
Iteration 28220, loss = -13.8029
Iteration 28230, loss = -13.8860
Iteration 28240, loss = -13.2465
Iteration 28250, loss = -14.3069
Iteration 28260, loss = -13.9455
Iteration 28270, loss = -13.8865
Iteration 28280, loss = -13.6575
Iteration 28290, loss = -13.9819
Iteration 28300, loss = -14.2409
Iteration 28310, loss = -14.1069
Iteration 28320, loss = -14.1780
Iteration 28330, loss = -13.9342
Iteration 28340, loss = -13.4788
Iteration 28350, loss = -13.8328
Iteration 28360, loss = -14.3215
Iteration 28370, loss = -14.1062
Iteration 28380, loss = -13.5493
Iteration 28390, loss = -13.7758
Iteration 28400, loss = -14.3186
Iteration 28410, loss = -13.8673
Iteration 28420, loss = -13.4543
Iteration 28430, loss = -13.6974
Iteration 28440, loss = -13.8795
Iteration 28450, loss = -14.2538
Iteration 28460, loss = -13.7649
Iteration 28470, loss = -14.1961
Iteration 28480, loss = -14.0949
Iteration 28490, loss = -14.0937
Iteration 28500, loss = -14.1762
Iteration 28510, loss = -13.5949
Iteration 28520, loss = -14.0559
Iteration 28530, loss = -12.9388
Iteration 28540, loss = -14.0757
Iteration 28550, loss = -13.9546
Iteration 28560, loss = -13.3180
Iteration 28570, loss = -13.9164
Iteration 28580, loss = -14.1449
Iteration 28590, loss = -12.7588
Iteration 28600, loss = -13.9388
Iteration 28610, loss = -13.9819
Iteration 28620, loss = -13.2013
Iteration 28630, loss = -13.9903
Iteration 28640, loss = -14.2869
Iteration 28650, loss = -13.9626
Iteration 28660, loss = -13.6711
Iteration 28670, loss = -13.0405
Iteration 28680, loss = -13.6892
Iteration 28690, loss = -14.0166
Iteration 28700, loss = -14.5233
Iteration 28710, loss = -13.9227
Iteration 28720, loss = -14.3287
Iteration 28730, loss = -14.0339
Iteration 28740, loss = -14.3334
Iteration 28750, loss = -13.0771
Iteration 28760, loss = -14.2362
Iteration 28770, loss = -14.3044
Iteration 28780, loss = -13.4731
Iteration 28790, loss = -14.1234
Iteration 28800, loss = -13.9913
Iteration 28810, loss = -13.9518
Iteration 28820, loss = -14.5300
Iteration 28830, loss = -14.2069
Iteration 28840, loss = -13.8308
Iteration 28850, loss = -14.0325
Iteration 28860, loss = -13.8107
Iteration 28870, loss = -13.2362
Iteration 28880, loss = -14.0107
Iteration 28890, loss = -13.7187
Starting epoch 20
Iteration 28900, loss = -13.9661
Iteration 28910, loss = -13.6301
Iteration 28920, loss = -14.4484
Iteration 28930, loss = -13.4130
Iteration 28940, loss = -14.1995
Iteration 28950, loss = -13.9300
Iteration 28960, loss = -13.8799
Iteration 28970, loss = -13.7804
Iteration 28980, loss = -13.7967
Iteration 28990, loss = -13.9644
Iteration 29000, loss = -14.0012
Om: 7.84%, s8: 5.72% accuracy
chi2: 1.805

Iteration 29010, loss = -14.0848
Iteration 29020, loss = -13.9949
Iteration 29030, loss = -13.9681
Iteration 29040, loss = -13.9059
Iteration 29050, loss = -13.5206
Iteration 29060, loss = -14.4879
Iteration 29070, loss = -14.0551
Iteration 29080, loss = -13.9504
Iteration 29090, loss = -14.4168
Iteration 29100, loss = -13.2132
Iteration 29110, loss = -13.9817
Iteration 29120, loss = -13.2976
Iteration 29130, loss = -12.9641
Iteration 29140, loss = -13.9592
Iteration 29150, loss = -14.2861
Iteration 29160, loss = -13.8350
Iteration 29170, loss = -13.9438
Iteration 29180, loss = -14.1474
Iteration 29190, loss = -13.8577
Iteration 29200, loss = -14.4955
Iteration 29210, loss = -14.2073
Iteration 29220, loss = -14.1070
Iteration 29230, loss = -13.6644
Iteration 29240, loss = -13.2330
Iteration 29250, loss = -14.0085
Iteration 29260, loss = -14.1954
Iteration 29270, loss = -13.7336
Iteration 29280, loss = -13.9331
Iteration 29290, loss = -14.2675
Iteration 29300, loss = -13.6119
Iteration 29310, loss = -14.2338
Iteration 29320, loss = -13.7819
Iteration 29330, loss = -13.9116
Iteration 29340, loss = -13.7694
Iteration 29350, loss = -13.8450
Iteration 29360, loss = -13.9507
Iteration 29370, loss = -14.3632
Iteration 29380, loss = -14.3328
Iteration 29390, loss = -14.3352
Iteration 29400, loss = -13.3612
Iteration 29410, loss = -13.5548
Iteration 29420, loss = -13.3743
Iteration 29430, loss = -14.0317
Iteration 29440, loss = -14.1147
Iteration 29450, loss = -14.1088
Iteration 29460, loss = -13.4236
Iteration 29470, loss = -13.5559
Iteration 29480, loss = -14.0193
Iteration 29490, loss = -13.5831
Iteration 29500, loss = -13.3028
Iteration 29510, loss = -14.4057
Iteration 29520, loss = -13.9150
Iteration 29530, loss = -14.3956
Iteration 29540, loss = -13.4423
Iteration 29550, loss = -13.5344
Iteration 29560, loss = -13.9613
Iteration 29570, loss = -14.0151
Iteration 29580, loss = -13.7701
Iteration 29590, loss = -14.0853
Iteration 29600, loss = -13.7981
Iteration 29610, loss = -13.4470
Iteration 29620, loss = -13.9591
Iteration 29630, loss = -13.8614
Iteration 29640, loss = -14.0709
Iteration 29650, loss = -13.9933
Iteration 29660, loss = -13.9151
Iteration 29670, loss = -14.3727
Iteration 29680, loss = -14.0141
Iteration 29690, loss = -14.2456
Iteration 29700, loss = -13.6093
Iteration 29710, loss = -13.8327
Iteration 29720, loss = -13.7368
Iteration 29730, loss = -13.8360
Iteration 29740, loss = -13.9347
Iteration 29750, loss = -14.1660
Iteration 29760, loss = -14.2188
Iteration 29770, loss = -13.4747
Iteration 29780, loss = -13.0148
Iteration 29790, loss = -14.3723
Iteration 29800, loss = -13.3306
Iteration 29810, loss = -13.6837
Iteration 29820, loss = -13.8608
Iteration 29830, loss = -13.4471
Iteration 29840, loss = -13.5828
Iteration 29850, loss = -14.2649
Iteration 29860, loss = -13.6680
Iteration 29870, loss = -13.6186
Iteration 29880, loss = -13.6971
Iteration 29890, loss = -13.5012
Iteration 29900, loss = -13.9577
Iteration 29910, loss = -14.1606
Iteration 29920, loss = -14.2978
Iteration 29930, loss = -13.5028
Iteration 29940, loss = -14.2855
Iteration 29950, loss = -13.2800
Iteration 29960, loss = -13.9269
Iteration 29970, loss = -13.7293
Iteration 29980, loss = -13.8675
Iteration 29990, loss = -14.3860
Iteration 30000, loss = -13.7292
Om: 7.93%, s8: 5.76% accuracy
chi2: 1.641

Iteration 30010, loss = -14.1212
Iteration 30020, loss = -14.3470
Iteration 30030, loss = -13.2771
Iteration 30040, loss = -13.6612
Iteration 30050, loss = -14.0713
Iteration 30060, loss = -14.0879
Iteration 30070, loss = -14.0334
Iteration 30080, loss = -13.2690
Iteration 30090, loss = -13.5231
Iteration 30100, loss = -13.5846
Iteration 30110, loss = -13.4615
Iteration 30120, loss = -13.2050
Iteration 30130, loss = -14.0157
Iteration 30140, loss = -13.0210
Iteration 30150, loss = -13.7809
Iteration 30160, loss = -13.8932
Iteration 30170, loss = -14.1115
Iteration 30180, loss = -14.1908
Iteration 30190, loss = -13.7827
Iteration 30200, loss = -13.7444
Iteration 30210, loss = -13.6295
Iteration 30220, loss = -13.9443
Iteration 30230, loss = -13.7590
Iteration 30240, loss = -13.6597
Iteration 30250, loss = -14.0803
Iteration 30260, loss = -14.0695
Iteration 30270, loss = -13.6748
Iteration 30280, loss = -13.7586
Iteration 30290, loss = -13.7641
Iteration 30300, loss = -13.9456
Iteration 30310, loss = -13.9191
Iteration 30320, loss = -14.0170
Iteration 30330, loss = -13.0939
Iteration 30340, loss = -13.7830
Starting epoch 21
Iteration 30350, loss = -13.8594
Iteration 30360, loss = -13.8336
Iteration 30370, loss = -13.8325
Iteration 30380, loss = -14.0743
Iteration 30390, loss = -13.8337
Iteration 30400, loss = -14.1191
Iteration 30410, loss = -14.1469
Iteration 30420, loss = -14.6043
Iteration 30430, loss = -13.7514
Iteration 30440, loss = -13.7007
Iteration 30450, loss = -13.5816
Iteration 30460, loss = -14.2024
Iteration 30470, loss = -14.0401
Iteration 30480, loss = -13.9051
Iteration 30490, loss = -13.8408
Iteration 30500, loss = -14.5047
Iteration 30510, loss = -13.5453
Iteration 30520, loss = -13.6661
Iteration 30530, loss = -13.9566
Iteration 30540, loss = -14.1282
Iteration 30550, loss = -14.5218
Iteration 30560, loss = -14.2418
Iteration 30570, loss = -14.0583
Iteration 30580, loss = -14.6252
Iteration 30590, loss = -14.1571
Iteration 30600, loss = -14.2114
Iteration 30610, loss = -13.2110
Iteration 30620, loss = -14.2028
Iteration 30630, loss = -14.2134
Iteration 30640, loss = -14.4935
Iteration 30650, loss = -13.1334
Iteration 30660, loss = -13.8450
Iteration 30670, loss = -14.4549
Iteration 30680, loss = -14.3894
Iteration 30690, loss = -13.6583
Iteration 30700, loss = -14.0520
Iteration 30710, loss = -14.1831
Iteration 30720, loss = -14.0119
Iteration 30730, loss = -13.5348
Iteration 30740, loss = -13.5430
Iteration 30750, loss = -13.4728
Iteration 30760, loss = -13.6508
Iteration 30770, loss = -13.2631
Iteration 30780, loss = -13.8477
Iteration 30790, loss = -13.6368
Iteration 30800, loss = -14.0280
Iteration 30810, loss = -13.8890
Iteration 30820, loss = -13.8829
Iteration 30830, loss = -14.1082
Iteration 30840, loss = -13.8924
Iteration 30850, loss = -13.8598
Iteration 30860, loss = -14.0401
Iteration 30870, loss = -13.9693
Iteration 30880, loss = -13.8241
Iteration 30890, loss = -14.0860
Iteration 30900, loss = -13.6075
Iteration 30910, loss = -14.3565
Iteration 30920, loss = -13.8118
Iteration 30930, loss = -14.1580
Iteration 30940, loss = -14.0544
Iteration 30950, loss = -13.8577
Iteration 30960, loss = -13.8358
Iteration 30970, loss = -13.7147
Iteration 30980, loss = -14.4133
Iteration 30990, loss = -13.3798
Iteration 31000, loss = -13.9076
Om: 8.02%, s8: 5.84% accuracy
chi2: 1.641

Iteration 31010, loss = -14.1352
Iteration 31020, loss = -14.2113
Iteration 31030, loss = -13.3808
Iteration 31040, loss = -13.5515
Iteration 31050, loss = -13.4640
Iteration 31060, loss = -14.3653
Iteration 31070, loss = -14.6439
Iteration 31080, loss = -14.4091
Iteration 31090, loss = -14.0754
Iteration 31100, loss = -13.2671
Iteration 31110, loss = -13.8220
Iteration 31120, loss = -14.1042
Iteration 31130, loss = -13.2750
Iteration 31140, loss = -14.3397
Iteration 31150, loss = -13.9260
Iteration 31160, loss = -14.1798
Iteration 31170, loss = -13.7693
Iteration 31180, loss = -13.5811
Iteration 31190, loss = -14.3168
Iteration 31200, loss = -14.2704
Iteration 31210, loss = -14.0215
Iteration 31220, loss = -13.3812
Iteration 31230, loss = -13.9078
Iteration 31240, loss = -14.0617
Iteration 31250, loss = -14.4371
Iteration 31260, loss = -14.1648
Iteration 31270, loss = -13.2420
Iteration 31280, loss = -13.7175
Iteration 31290, loss = -14.3772
Iteration 31300, loss = -13.9250
Iteration 31310, loss = -13.8008
Iteration 31320, loss = -13.9019
Iteration 31330, loss = -14.3679
Iteration 31340, loss = -14.1723
Iteration 31350, loss = -14.0687
Iteration 31360, loss = -14.3041
Iteration 31370, loss = -14.2479
Iteration 31380, loss = -13.9480
Iteration 31390, loss = -14.3975
Iteration 31400, loss = -13.5606
Iteration 31410, loss = -14.3926
Iteration 31420, loss = -13.0754
Iteration 31430, loss = -14.0565
Iteration 31440, loss = -13.8833
Iteration 31450, loss = -13.5022
Iteration 31460, loss = -13.7958
Iteration 31470, loss = -14.0100
Iteration 31480, loss = -13.1204
Iteration 31490, loss = -13.9131
Iteration 31500, loss = -13.5719
Iteration 31510, loss = -13.4631
Iteration 31520, loss = -14.3032
Iteration 31530, loss = -14.7267
Iteration 31540, loss = -14.2597
Iteration 31550, loss = -13.7826
Iteration 31560, loss = -13.0577
Iteration 31570, loss = -14.0775
Iteration 31580, loss = -14.1985
Iteration 31590, loss = -14.4340
Iteration 31600, loss = -14.1618
Iteration 31610, loss = -14.4436
Iteration 31620, loss = -14.2990
Iteration 31630, loss = -14.2189
Iteration 31640, loss = -13.5916
Iteration 31650, loss = -14.3223
Iteration 31660, loss = -14.5445
Iteration 31670, loss = -13.9161
Iteration 31680, loss = -14.1144
Iteration 31690, loss = -13.9708
Iteration 31700, loss = -14.2856
Iteration 31710, loss = -14.3418
Iteration 31720, loss = -14.0955
Iteration 31730, loss = -14.0912
Iteration 31740, loss = -14.1171
Iteration 31750, loss = -13.7981
Iteration 31760, loss = -13.2583
Iteration 31770, loss = -14.2080
Iteration 31780, loss = -13.6507
Starting epoch 22
Iteration 31790, loss = -14.3437
Iteration 31800, loss = -13.3513
Iteration 31810, loss = -14.2039
Iteration 31820, loss = -13.8636
Iteration 31830, loss = -14.3331
Iteration 31840, loss = -14.0156
Iteration 31850, loss = -14.3265
Iteration 31860, loss = -13.9163
Iteration 31870, loss = -13.7520
Iteration 31880, loss = -14.0194
Iteration 31890, loss = -14.3333
Iteration 31900, loss = -14.4570
Iteration 31910, loss = -14.0205
Iteration 31920, loss = -14.0838
Iteration 31930, loss = -13.7976
Iteration 31940, loss = -14.4883
Iteration 31950, loss = -14.1303
Iteration 31960, loss = -14.0441
Iteration 31970, loss = -13.9973
Iteration 31980, loss = -14.7185
Iteration 31990, loss = -13.5028
Iteration 32000, loss = -14.2857
Om: 7.17%, s8: 5.19% accuracy
chi2: 1.558

Iteration 32010, loss = -13.2498
Iteration 32020, loss = -13.5808
Iteration 32030, loss = -14.0534
Iteration 32040, loss = -14.6802
Iteration 32050, loss = -13.9096
Iteration 32060, loss = -13.8091
Iteration 32070, loss = -14.4987
Iteration 32080, loss = -13.7163
Iteration 32090, loss = -14.8691
Iteration 32100, loss = -14.2043
Iteration 32110, loss = -14.3053
Iteration 32120, loss = -13.9084
Iteration 32130, loss = -14.0022
Iteration 32140, loss = -14.4108
Iteration 32150, loss = -13.9011
Iteration 32160, loss = -13.6506
Iteration 32170, loss = -13.4336
Iteration 32180, loss = -14.3639
Iteration 32190, loss = -14.2301
Iteration 32200, loss = -14.5070
Iteration 32210, loss = -13.6546
Iteration 32220, loss = -13.9222
Iteration 32230, loss = -14.1045
Iteration 32240, loss = -14.3093
Iteration 32250, loss = -14.0055
Iteration 32260, loss = -14.3965
Iteration 32270, loss = -13.8598
Iteration 32280, loss = -14.4777
Iteration 32290, loss = -13.6365
Iteration 32300, loss = -14.0424
Iteration 32310, loss = -13.6069
Iteration 32320, loss = -14.4382
Iteration 32330, loss = -14.3607
Iteration 32340, loss = -14.2216
Iteration 32350, loss = -14.1977
Iteration 32360, loss = -14.0857
Iteration 32370, loss = -14.4484
Iteration 32380, loss = -14.0110
Iteration 32390, loss = -13.6285
Iteration 32400, loss = -14.3649
Iteration 32410, loss = -14.2825
Iteration 32420, loss = -14.1920
Iteration 32430, loss = -13.6648
Iteration 32440, loss = -13.7186
Iteration 32450, loss = -14.2745
Iteration 32460, loss = -14.4666
Iteration 32470, loss = -14.2302
Iteration 32480, loss = -14.1160
Iteration 32490, loss = -14.1869
Iteration 32500, loss = -13.7510
Iteration 32510, loss = -14.2507
Iteration 32520, loss = -14.0916
Iteration 32530, loss = -14.3811
Iteration 32540, loss = -14.3867
Iteration 32550, loss = -14.1695
Iteration 32560, loss = -14.5796
Iteration 32570, loss = -14.1915
Iteration 32580, loss = -14.4755
Iteration 32590, loss = -13.9394
Iteration 32600, loss = -13.8505
Iteration 32610, loss = -13.8772
Iteration 32620, loss = -14.2038
Iteration 32630, loss = -13.8077
Iteration 32640, loss = -14.5688
Iteration 32650, loss = -14.4381
Iteration 32660, loss = -14.0403
Iteration 32670, loss = -13.2983
Iteration 32680, loss = -13.8816
Iteration 32690, loss = -13.3630
Iteration 32700, loss = -13.9294
Iteration 32710, loss = -13.9732
Iteration 32720, loss = -13.4449
Iteration 32730, loss = -13.9004
Iteration 32740, loss = -14.6576
Iteration 32750, loss = -14.1539
Iteration 32760, loss = -13.1365
Iteration 32770, loss = -13.8110
Iteration 32780, loss = -13.9368
Iteration 32790, loss = -14.4705
Iteration 32800, loss = -14.2634
Iteration 32810, loss = -14.4448
Iteration 32820, loss = -13.6728
Iteration 32830, loss = -14.5719
Iteration 32840, loss = -14.1396
Iteration 32850, loss = -14.2574
Iteration 32860, loss = -14.2301
Iteration 32870, loss = -14.4729
Iteration 32880, loss = -14.8530
Iteration 32890, loss = -13.9361
Iteration 32900, loss = -14.4136
Iteration 32910, loss = -14.5884
Iteration 32920, loss = -13.5907
Iteration 32930, loss = -14.0619
Iteration 32940, loss = -14.5759
Iteration 32950, loss = -14.5072
Iteration 32960, loss = -14.1505
Iteration 32970, loss = -13.3229
Iteration 32980, loss = -14.0406
Iteration 32990, loss = -13.8719
Iteration 33000, loss = -14.2568
Om: 7.01%, s8: 5.14% accuracy
chi2: 1.808

Iteration 33010, loss = -13.7380
Iteration 33020, loss = -14.2775
Iteration 33030, loss = -13.7282
Iteration 33040, loss = -14.5126
Iteration 33050, loss = -13.9640
Iteration 33060, loss = -14.5810
Iteration 33070, loss = -14.4114
Iteration 33080, loss = -14.0169
Iteration 33090, loss = -14.4416
Iteration 33100, loss = -13.8644
Iteration 33110, loss = -14.5228
Iteration 33120, loss = -14.2292
Iteration 33130, loss = -14.1358
Iteration 33140, loss = -14.5938
Iteration 33150, loss = -14.0222
Iteration 33160, loss = -14.2317
Iteration 33170, loss = -14.0997
Iteration 33180, loss = -14.0595
Iteration 33190, loss = -14.4374
Iteration 33200, loss = -14.2905
Iteration 33210, loss = -14.8535
Iteration 33220, loss = -13.2594
Iteration 33230, loss = -14.1142
Starting epoch 23
Iteration 33240, loss = -14.3545
Iteration 33250, loss = -13.8247
Iteration 33260, loss = -13.8324
Iteration 33270, loss = -14.2625
Iteration 33280, loss = -13.8674
Iteration 33290, loss = -14.5621
Iteration 33300, loss = -14.3934
Iteration 33310, loss = -14.6132
Iteration 33320, loss = -13.6349
Iteration 33330, loss = -13.7234
Iteration 33340, loss = -14.1835
Iteration 33350, loss = -14.1790
Iteration 33360, loss = -14.3416
Iteration 33370, loss = -14.0589
Iteration 33380, loss = -13.9567
Iteration 33390, loss = -14.6518
Iteration 33400, loss = -13.7955
Iteration 33410, loss = -13.7806
Iteration 33420, loss = -14.5816
Iteration 33430, loss = -14.9217
Iteration 33440, loss = -14.7971
Iteration 33450, loss = -14.6467
Iteration 33460, loss = -14.5064
Iteration 33470, loss = -14.6598
Iteration 33480, loss = -14.5929
Iteration 33490, loss = -14.9180
Iteration 33500, loss = -13.3269
Iteration 33510, loss = -14.4933
Iteration 33520, loss = -14.3930
Iteration 33530, loss = -14.7319
Iteration 33540, loss = -13.8634
Iteration 33550, loss = -13.7210
Iteration 33560, loss = -14.5412
Iteration 33570, loss = -14.2893
Iteration 33580, loss = -14.0782
Iteration 33590, loss = -14.2623
Iteration 33600, loss = -14.5666
Iteration 33610, loss = -14.2437
Iteration 33620, loss = -13.7856
Iteration 33630, loss = -13.9135
Iteration 33640, loss = -13.8222
Iteration 33650, loss = -14.1186
Iteration 33660, loss = -12.8715
Iteration 33670, loss = -14.0199
Iteration 33680, loss = -13.9853
Iteration 33690, loss = -14.5498
Iteration 33700, loss = -14.2651
Iteration 33710, loss = -14.7382
Iteration 33720, loss = -14.6855
Iteration 33730, loss = -14.2263
Iteration 33740, loss = -14.5473
Iteration 33750, loss = -14.6377
Iteration 33760, loss = -14.5884
Iteration 33770, loss = -14.0152
Iteration 33780, loss = -14.5467
Iteration 33790, loss = -14.0006
Iteration 33800, loss = -14.6593
Iteration 33810, loss = -14.2634
Iteration 33820, loss = -13.9405
Iteration 33830, loss = -14.2863
Iteration 33840, loss = -14.5793
Iteration 33850, loss = -13.9218
Iteration 33860, loss = -14.4200
Iteration 33870, loss = -14.8050
Iteration 33880, loss = -13.3794
Iteration 33890, loss = -14.1438
Iteration 33900, loss = -14.2577
Iteration 33910, loss = -14.1938
Iteration 33920, loss = -14.2981
Iteration 33930, loss = -13.8992
Iteration 33940, loss = -14.0779
Iteration 33950, loss = -14.6272
Iteration 33960, loss = -14.5170
Iteration 33970, loss = -14.6376
Iteration 33980, loss = -14.5266
Iteration 33990, loss = -13.9751
Iteration 34000, loss = -14.2960
Om: 6.99%, s8: 5.03% accuracy
chi2: 1.419

Iteration 34010, loss = -14.3417
Iteration 34020, loss = -13.6652
Iteration 34030, loss = -14.7097
Iteration 34040, loss = -14.3126
Iteration 34050, loss = -14.1913
Iteration 34060, loss = -13.9897
Iteration 34070, loss = -14.2915
Iteration 34080, loss = -14.2632
Iteration 34090, loss = -14.2110
Iteration 34100, loss = -14.3789
Iteration 34110, loss = -14.4252
Iteration 34120, loss = -14.2181
Iteration 34130, loss = -14.0190
Iteration 34140, loss = -14.5018
Iteration 34150, loss = -14.1937
Iteration 34160, loss = -13.3768
Iteration 34170, loss = -14.2183
Iteration 34180, loss = -14.7394
Iteration 34190, loss = -14.1537
Iteration 34200, loss = -14.0519
Iteration 34210, loss = -14.0249
Iteration 34220, loss = -14.1874
Iteration 34230, loss = -14.1957
Iteration 34240, loss = -14.1275
Iteration 34250, loss = -14.2810
Iteration 34260, loss = -14.1774
Iteration 34270, loss = -14.2057
Iteration 34280, loss = -14.6584
Iteration 34290, loss = -13.8216
Iteration 34300, loss = -14.4571
Iteration 34310, loss = -13.1720
Iteration 34320, loss = -14.3032
Iteration 34330, loss = -14.4044
Iteration 34340, loss = -13.7639
Iteration 34350, loss = -14.6692
Iteration 34360, loss = -14.4842
Iteration 34370, loss = -12.8522
Iteration 34380, loss = -14.2082
Iteration 34390, loss = -14.2903
Iteration 34400, loss = -13.8493
Iteration 34410, loss = -14.3248
Iteration 34420, loss = -14.5798
Iteration 34430, loss = -14.4442
Iteration 34440, loss = -14.5351
Iteration 34450, loss = -13.6477
Iteration 34460, loss = -14.3649
Iteration 34470, loss = -14.5090
Iteration 34480, loss = -14.1923
Iteration 34490, loss = -14.4639
Iteration 34500, loss = -14.8375
Iteration 34510, loss = -14.6453
Iteration 34520, loss = -14.5863
Iteration 34530, loss = -14.0278
Iteration 34540, loss = -14.8075
Iteration 34550, loss = -15.0582
Iteration 34560, loss = -14.1579
Iteration 34570, loss = -14.0816
Iteration 34580, loss = -14.2918
Iteration 34590, loss = -14.3349
Iteration 34600, loss = -14.9932
Iteration 34610, loss = -14.3439
Iteration 34620, loss = -13.6662
Iteration 34630, loss = -14.2021
Iteration 34640, loss = -13.7711
Iteration 34650, loss = -13.6538
Iteration 34660, loss = -14.8679
Iteration 34670, loss = -14.2031
Starting epoch 24
Iteration 34680, loss = -14.7551
Iteration 34690, loss = -13.5150
Iteration 34700, loss = -14.4917
Iteration 34710, loss = -14.4185
Iteration 34720, loss = -14.6944
Iteration 34730, loss = -14.1712
Iteration 34740, loss = -14.6900
Iteration 34750, loss = -14.3973
Iteration 34760, loss = -13.9518
Iteration 34770, loss = -14.6164
Iteration 34780, loss = -14.3652
Iteration 34790, loss = -14.5037
Iteration 34800, loss = -14.3809
Iteration 34810, loss = -13.9391
Iteration 34820, loss = -14.0935
Iteration 34830, loss = -14.9041
Iteration 34840, loss = -14.4884
Iteration 34850, loss = -14.4139
Iteration 34860, loss = -13.7828
Iteration 34870, loss = -14.5501
Iteration 34880, loss = -14.2795
Iteration 34890, loss = -14.6908
Iteration 34900, loss = -13.6318
Iteration 34910, loss = -14.1003
Iteration 34920, loss = -13.8377
Iteration 34930, loss = -14.7659
Iteration 34940, loss = -14.0523
Iteration 34950, loss = -14.1584
Iteration 34960, loss = -14.5153
Iteration 34970, loss = -13.9192
Iteration 34980, loss = -15.1225
Iteration 34990, loss = -14.5215
Iteration 35000, loss = -14.4758
Om: 6.66%, s8: 4.75% accuracy
chi2: 1.986

Iteration 35010, loss = -14.3272
Iteration 35020, loss = -14.2467
Iteration 35030, loss = -14.9542
Iteration 35040, loss = -14.2351
Iteration 35050, loss = -13.6929
Iteration 35060, loss = -14.0438
Iteration 35070, loss = -14.4546
Iteration 35080, loss = -14.0087
Iteration 35090, loss = -14.4019
Iteration 35100, loss = -14.3503
Iteration 35110, loss = -14.0684
Iteration 35120, loss = -14.6106
Iteration 35130, loss = -14.5885
Iteration 35140, loss = -14.5023
Iteration 35150, loss = -14.8825
Iteration 35160, loss = -14.6274
Iteration 35170, loss = -14.3187
Iteration 35180, loss = -14.0161
Iteration 35190, loss = -14.1011
Iteration 35200, loss = -13.7394
Iteration 35210, loss = -14.5819
Iteration 35220, loss = -14.4272
Iteration 35230, loss = -14.2000
Iteration 35240, loss = -14.5396
Iteration 35250, loss = -14.1167
Iteration 35260, loss = -14.7558
Iteration 35270, loss = -13.5785
Iteration 35280, loss = -14.1538
Iteration 35290, loss = -14.8096
Iteration 35300, loss = -14.4175
Iteration 35310, loss = -14.5978
Iteration 35320, loss = -13.7352
Iteration 35330, loss = -13.8478
Iteration 35340, loss = -14.0650
Iteration 35350, loss = -14.6640
Iteration 35360, loss = -14.1854
Iteration 35370, loss = -14.5466
Iteration 35380, loss = -14.6033
Iteration 35390, loss = -14.3822
Iteration 35400, loss = -14.5950
Iteration 35410, loss = -14.2424
Iteration 35420, loss = -14.5916
Iteration 35430, loss = -14.7757
Iteration 35440, loss = -14.4801
Iteration 35450, loss = -15.0051
Iteration 35460, loss = -14.1631
Iteration 35470, loss = -14.3383
Iteration 35480, loss = -13.9559
Iteration 35490, loss = -14.3462
Iteration 35500, loss = -14.2478
Iteration 35510, loss = -14.4840
Iteration 35520, loss = -14.0435
Iteration 35530, loss = -14.6286
Iteration 35540, loss = -14.8479
Iteration 35550, loss = -14.2164
Iteration 35560, loss = -13.4194
Iteration 35570, loss = -14.2250
Iteration 35580, loss = -13.6657
Iteration 35590, loss = -14.2300
Iteration 35600, loss = -14.2453
Iteration 35610, loss = -13.8899
Iteration 35620, loss = -14.0364
Iteration 35630, loss = -14.8464
Iteration 35640, loss = -14.1892
Iteration 35650, loss = -13.7913
Iteration 35660, loss = -13.7438
Iteration 35670, loss = -14.1159
Iteration 35680, loss = -15.0227
Iteration 35690, loss = -14.5342
Iteration 35700, loss = -14.7280
Iteration 35710, loss = -13.8547
Iteration 35720, loss = -14.8810
Iteration 35730, loss = -14.2048
Iteration 35740, loss = -14.4842
Iteration 35750, loss = -14.5357
Iteration 35760, loss = -14.5045
Iteration 35770, loss = -14.9694
Iteration 35780, loss = -14.2118
Iteration 35790, loss = -14.5783
Iteration 35800, loss = -14.9658
Iteration 35810, loss = -13.7014
Iteration 35820, loss = -14.1277
Iteration 35830, loss = -14.4133
Iteration 35840, loss = -14.4880
Iteration 35850, loss = -14.3421
Iteration 35860, loss = -13.8526
Iteration 35870, loss = -14.3087
Iteration 35880, loss = -14.5270
Iteration 35890, loss = -14.4824
Iteration 35900, loss = -14.1474
Iteration 35910, loss = -14.3324
Iteration 35920, loss = -14.0220
Iteration 35930, loss = -14.7458
Iteration 35940, loss = -14.6576
Iteration 35950, loss = -14.8641
Iteration 35960, loss = -14.4964
Iteration 35970, loss = -14.3051
Iteration 35980, loss = -14.6459
Iteration 35990, loss = -13.8143
Iteration 36000, loss = -14.9618
Om: 6.56%, s8: 5.12% accuracy
chi2: 2.398

Iteration 36010, loss = -14.1671
Iteration 36020, loss = -14.1514
Iteration 36030, loss = -14.5610
Iteration 36040, loss = -14.3918
Iteration 36050, loss = -14.6460
Iteration 36060, loss = -14.6713
Iteration 36070, loss = -14.4395
Iteration 36080, loss = -14.8020
Iteration 36090, loss = -14.6127
Iteration 36100, loss = -15.0011
Iteration 36110, loss = -13.2858
Iteration 36120, loss = -14.2257
Starting epoch 25
Iteration 36130, loss = -14.7688
Iteration 36140, loss = -13.9579
Iteration 36150, loss = -14.1393
Iteration 36160, loss = -14.4513
Iteration 36170, loss = -14.0787
Iteration 36180, loss = -14.8715
Iteration 36190, loss = -14.3805
Iteration 36200, loss = -14.1950
Iteration 36210, loss = -13.8280
Iteration 36220, loss = -13.7975
Iteration 36230, loss = -14.4299
Iteration 36240, loss = -14.8159
Iteration 36250, loss = -14.7177
Iteration 36260, loss = -14.3652
Iteration 36270, loss = -13.8407
Iteration 36280, loss = -14.4586
Iteration 36290, loss = -14.2238
Iteration 36300, loss = -14.3694
Iteration 36310, loss = -14.7789
Iteration 36320, loss = -15.1415
Iteration 36330, loss = -14.8297
Iteration 36340, loss = -14.7022
Iteration 36350, loss = -14.9902
Iteration 36360, loss = -14.2186
Iteration 36370, loss = -14.8340
Iteration 36380, loss = -15.1994
Iteration 36390, loss = -13.9449
Iteration 36400, loss = -14.5943
Iteration 36410, loss = -14.7016
Iteration 36420, loss = -15.0593
Iteration 36430, loss = -14.1415
Iteration 36440, loss = -14.2549
Iteration 36450, loss = -14.6205
Iteration 36460, loss = -14.8433
Iteration 36470, loss = -14.6335
Iteration 36480, loss = -14.2647
Iteration 36490, loss = -14.1631
Iteration 36500, loss = -14.6520
Iteration 36510, loss = -14.1946
Iteration 36520, loss = -14.5334
Iteration 36530, loss = -14.5152
Iteration 36540, loss = -14.3305
Iteration 36550, loss = -13.1988
Iteration 36560, loss = -13.9609
Iteration 36570, loss = -13.7866
Iteration 36580, loss = -14.6212
Iteration 36590, loss = -14.5982
Iteration 36600, loss = -14.7617
Iteration 36610, loss = -14.6300
Iteration 36620, loss = -14.4402
Iteration 36630, loss = -14.8441
Iteration 36640, loss = -14.9412
Iteration 36650, loss = -14.9215
Iteration 36660, loss = -14.4791
Iteration 36670, loss = -14.7995
Iteration 36680, loss = -14.3622
Iteration 36690, loss = -14.7252
Iteration 36700, loss = -14.3051
Iteration 36710, loss = -14.1527
Iteration 36720, loss = -14.7598
Iteration 36730, loss = -15.1437
Iteration 36740, loss = -14.4617
Iteration 36750, loss = -14.0368
Iteration 36760, loss = -14.9406
Iteration 36770, loss = -13.3315
Iteration 36780, loss = -14.3035
Iteration 36790, loss = -14.6227
Iteration 36800, loss = -14.8573
Iteration 36810, loss = -14.5065
Iteration 36820, loss = -14.2424
Iteration 36830, loss = -14.1925
Iteration 36840, loss = -15.0809
Iteration 36850, loss = -14.7091
Iteration 36860, loss = -15.0458
Iteration 36870, loss = -14.5783
Iteration 36880, loss = -14.2934
Iteration 36890, loss = -14.4496
Iteration 36900, loss = -14.7369
Iteration 36910, loss = -14.1992
Iteration 36920, loss = -14.5677
Iteration 36930, loss = -14.3299
Iteration 36940, loss = -14.5976
Iteration 36950, loss = -14.3598
Iteration 36960, loss = -14.3303
Iteration 36970, loss = -14.1899
Iteration 36980, loss = -14.6028
Iteration 36990, loss = -14.4237
Iteration 37000, loss = -14.5054
Om: 5.98%, s8: 4.27% accuracy
chi2: 1.555

Iteration 37010, loss = -14.2750
Iteration 37020, loss = -14.1830
Iteration 37030, loss = -14.8849
Iteration 37040, loss = -14.4529
Iteration 37050, loss = -13.7884
Iteration 37060, loss = -14.1648
Iteration 37070, loss = -14.8580
Iteration 37080, loss = -14.4811
Iteration 37090, loss = -14.2334
Iteration 37100, loss = -14.3363
Iteration 37110, loss = -14.5274
Iteration 37120, loss = -14.4793
Iteration 37130, loss = -14.6487
Iteration 37140, loss = -14.9578
Iteration 37150, loss = -14.6435
Iteration 37160, loss = -14.1485
Iteration 37170, loss = -14.5752
Iteration 37180, loss = -14.2836
Iteration 37190, loss = -14.9558
Iteration 37200, loss = -14.2078
Iteration 37210, loss = -14.7538
Iteration 37220, loss = -14.7380
Iteration 37230, loss = -13.5255
Iteration 37240, loss = -14.5858
Iteration 37250, loss = -14.9684
Iteration 37260, loss = -13.6081
Iteration 37270, loss = -15.4825
Iteration 37280, loss = -14.4752
Iteration 37290, loss = -13.5243
Iteration 37300, loss = -14.8517
Iteration 37310, loss = -14.9573
Iteration 37320, loss = -14.7096
Iteration 37330, loss = -14.8280
Iteration 37340, loss = -14.1530
Iteration 37350, loss = -14.5795
Iteration 37360, loss = -15.0801
Iteration 37370, loss = -13.9385
Iteration 37380, loss = -14.6555
Iteration 37390, loss = -14.5538
Iteration 37400, loss = -14.9785
Iteration 37410, loss = -15.2929
Iteration 37420, loss = -14.2998
Iteration 37430, loss = -14.9386
Iteration 37440, loss = -14.9646
Iteration 37450, loss = -14.3074
Iteration 37460, loss = -14.3531
Iteration 37470, loss = -14.6682
Iteration 37480, loss = -14.2720
Iteration 37490, loss = -14.8300
Iteration 37500, loss = -14.1304
Iteration 37510, loss = -14.2925
Iteration 37520, loss = -13.9515
Iteration 37530, loss = -14.3656
Iteration 37540, loss = -14.3335
Iteration 37550, loss = -14.1357
Iteration 37560, loss = -14.1314
Starting epoch 26
Iteration 37570, loss = -15.0161
Iteration 37580, loss = -14.1238
Iteration 37590, loss = -14.6573
Iteration 37600, loss = -14.3860
Iteration 37610, loss = -15.1389
Iteration 37620, loss = -14.2795
Iteration 37630, loss = -14.0909
Iteration 37640, loss = -14.6217
Iteration 37650, loss = -14.5984
Iteration 37660, loss = -14.5786
Iteration 37670, loss = -14.8163
Iteration 37680, loss = -14.5326
Iteration 37690, loss = -14.7667
Iteration 37700, loss = -14.9341
Iteration 37710, loss = -14.1339
Iteration 37720, loss = -15.0944
Iteration 37730, loss = -14.6307
Iteration 37740, loss = -14.5208
Iteration 37750, loss = -13.9901
Iteration 37760, loss = -14.7700
Iteration 37770, loss = -14.5944
Iteration 37780, loss = -14.8981
Iteration 37790, loss = -14.1813
Iteration 37800, loss = -14.0147
Iteration 37810, loss = -14.6279
Iteration 37820, loss = -14.9122
Iteration 37830, loss = -14.1231
Iteration 37840, loss = -13.7639
Iteration 37850, loss = -14.7550
Iteration 37860, loss = -14.6483
Iteration 37870, loss = -14.7601
Iteration 37880, loss = -14.5988
Iteration 37890, loss = -14.8376
Iteration 37900, loss = -14.6627
Iteration 37910, loss = -14.8212
Iteration 37920, loss = -14.8025
Iteration 37930, loss = -14.9471
Iteration 37940, loss = -14.6029
Iteration 37950, loss = -14.5999
Iteration 37960, loss = -15.3228
Iteration 37970, loss = -14.3449
Iteration 37980, loss = -14.5561
Iteration 37990, loss = -14.8238
Iteration 38000, loss = -14.5541
Om: 5.82%, s8: 4.16% accuracy
chi2: 1.502

Iteration 38010, loss = -14.9679
Iteration 38020, loss = -15.0637
Iteration 38030, loss = -14.5352
Iteration 38040, loss = -14.9069
Iteration 38050, loss = -14.8830
Iteration 38060, loss = -14.0891
Iteration 38070, loss = -14.1855
Iteration 38080, loss = -14.3411
Iteration 38090, loss = -13.8368
Iteration 38100, loss = -14.8353
Iteration 38110, loss = -14.4549
Iteration 38120, loss = -14.1616
Iteration 38130, loss = -14.8006
Iteration 38140, loss = -14.8201
Iteration 38150, loss = -15.2604
Iteration 38160, loss = -14.2833
Iteration 38170, loss = -14.8364
Iteration 38180, loss = -14.1043
Iteration 38190, loss = -14.8784
Iteration 38200, loss = -14.8889
Iteration 38210, loss = -14.1658
Iteration 38220, loss = -14.3418
Iteration 38230, loss = -14.5600
Iteration 38240, loss = -14.6307
Iteration 38250, loss = -14.4205
Iteration 38260, loss = -14.8198
Iteration 38270, loss = -15.1339
Iteration 38280, loss = -14.6914
Iteration 38290, loss = -14.8472
Iteration 38300, loss = -14.7225
Iteration 38310, loss = -14.5334
Iteration 38320, loss = -14.2282
Iteration 38330, loss = -14.8097
Iteration 38340, loss = -15.2821
Iteration 38350, loss = -14.7878
Iteration 38360, loss = -15.0735
Iteration 38370, loss = -14.4076
Iteration 38380, loss = -14.2759
Iteration 38390, loss = -14.7376
Iteration 38400, loss = -14.3436
Iteration 38410, loss = -14.5473
Iteration 38420, loss = -15.0649
Iteration 38430, loss = -15.1006
Iteration 38440, loss = -13.7298
Iteration 38450, loss = -13.4627
Iteration 38460, loss = -15.1026
Iteration 38470, loss = -14.5552
Iteration 38480, loss = -14.7394
Iteration 38490, loss = -14.8152
Iteration 38500, loss = -14.3484
Iteration 38510, loss = -14.3448
Iteration 38520, loss = -14.9481
Iteration 38530, loss = -14.9019
Iteration 38540, loss = -14.7683
Iteration 38550, loss = -13.7520
Iteration 38560, loss = -14.6976
Iteration 38570, loss = -14.5109
Iteration 38580, loss = -14.1492
Iteration 38590, loss = -14.5942
Iteration 38600, loss = -14.2446
Iteration 38610, loss = -15.1024
Iteration 38620, loss = -14.7182
Iteration 38630, loss = -15.2158
Iteration 38640, loss = -14.6036
Iteration 38650, loss = -14.5643
Iteration 38660, loss = -15.3971
Iteration 38670, loss = -14.8322
Iteration 38680, loss = -14.4945
Iteration 38690, loss = -15.0349
Iteration 38700, loss = -13.8561
Iteration 38710, loss = -14.4547
Iteration 38720, loss = -14.7120
Iteration 38730, loss = -14.7527
Iteration 38740, loss = -15.0785
Iteration 38750, loss = -13.5381
Iteration 38760, loss = -14.7388
Iteration 38770, loss = -14.5282
Iteration 38780, loss = -14.8871
Iteration 38790, loss = -14.8498
Iteration 38800, loss = -14.9916
Iteration 38810, loss = -14.4176
Iteration 38820, loss = -14.8102
Iteration 38830, loss = -14.7370
Iteration 38840, loss = -14.7777
Iteration 38850, loss = -15.0602
Iteration 38860, loss = -14.9420
Iteration 38870, loss = -14.7655
Iteration 38880, loss = -14.4877
Iteration 38890, loss = -15.0066
Iteration 38900, loss = -15.0907
Iteration 38910, loss = -14.8980
Iteration 38920, loss = -15.1197
Iteration 38930, loss = -14.6897
Iteration 38940, loss = -14.9487
Iteration 38950, loss = -14.8016
Iteration 38960, loss = -14.8159
Iteration 38970, loss = -15.1549
Iteration 38980, loss = -14.4510
Iteration 38990, loss = -15.1466
Iteration 39000, loss = -13.5797
Om: 7.22%, s8: 5.01% accuracy
chi2: 2.322

Iteration 39010, loss = -14.4536
Starting epoch 27
Iteration 39020, loss = -15.1559
Iteration 39030, loss = -14.5210
Iteration 39040, loss = -14.4876
Iteration 39050, loss = -14.4458
Iteration 39060, loss = -14.5748
Iteration 39070, loss = -14.3194
Iteration 39080, loss = -14.7382
Iteration 39090, loss = -15.0588
Iteration 39100, loss = -14.1913
Iteration 39110, loss = -14.9765
Iteration 39120, loss = -14.3601
Iteration 39130, loss = -14.7851
Iteration 39140, loss = -14.8989
Iteration 39150, loss = -14.8894
Iteration 39160, loss = -14.4661
Iteration 39170, loss = -14.4785
Iteration 39180, loss = -14.4914
Iteration 39190, loss = -14.7576
Iteration 39200, loss = -15.0619
Iteration 39210, loss = -15.3460
Iteration 39220, loss = -14.8507
Iteration 39230, loss = -14.4813
Iteration 39240, loss = -15.2535
Iteration 39250, loss = -15.1222
Iteration 39260, loss = -15.2617
Iteration 39270, loss = -15.0804
Iteration 39280, loss = -14.2188
Iteration 39290, loss = -14.9888
Iteration 39300, loss = -14.8999
Iteration 39310, loss = -14.7727
Iteration 39320, loss = -14.4212
Iteration 39330, loss = -14.7677
Iteration 39340, loss = -14.9861
Iteration 39350, loss = -15.4036
Iteration 39360, loss = -14.8406
Iteration 39370, loss = -14.9253
Iteration 39380, loss = -14.7216
Iteration 39390, loss = -14.7062
Iteration 39400, loss = -14.6771
Iteration 39410, loss = -15.2371
Iteration 39420, loss = -14.1891
Iteration 39430, loss = -15.1125
Iteration 39440, loss = -14.2501
Iteration 39450, loss = -14.5850
Iteration 39460, loss = -14.4462
Iteration 39470, loss = -15.1275
Iteration 39480, loss = -15.1637
Iteration 39490, loss = -15.0986
Iteration 39500, loss = -15.2542
Iteration 39510, loss = -14.5863
Iteration 39520, loss = -15.0250
Iteration 39530, loss = -15.3682
Iteration 39540, loss = -15.0657
Iteration 39550, loss = -14.9419
Iteration 39560, loss = -15.0512
Iteration 39570, loss = -14.6699
Iteration 39580, loss = -15.1996
Iteration 39590, loss = -14.6474
Iteration 39600, loss = -15.0397
Iteration 39610, loss = -14.8265
Iteration 39620, loss = -15.4308
Iteration 39630, loss = -15.2377
Iteration 39640, loss = -14.9955
Iteration 39650, loss = -15.0463
Iteration 39660, loss = -14.3351
Iteration 39670, loss = -14.6900
Iteration 39680, loss = -14.8885
Iteration 39690, loss = -15.3266
Iteration 39700, loss = -14.5665
Iteration 39710, loss = -14.7917
Iteration 39720, loss = -14.4836
Iteration 39730, loss = -15.0567
Iteration 39740, loss = -14.6052
Iteration 39750, loss = -15.0856
Iteration 39760, loss = -15.3599
Iteration 39770, loss = -14.7176
Iteration 39780, loss = -14.5602
Iteration 39790, loss = -15.1941
Iteration 39800, loss = -14.1973
Iteration 39810, loss = -14.9722
Iteration 39820, loss = -14.8130
Iteration 39830, loss = -15.0463
Iteration 39840, loss = -14.9351
Iteration 39850, loss = -15.1737
Iteration 39860, loss = -15.0081
Iteration 39870, loss = -15.2343
Iteration 39880, loss = -14.4642
Iteration 39890, loss = -14.9481
Iteration 39900, loss = -14.5000
Iteration 39910, loss = -13.8344
Iteration 39920, loss = -14.8893
Iteration 39930, loss = -14.9721
Iteration 39940, loss = -13.8764
Iteration 39950, loss = -14.4754
Iteration 39960, loss = -14.8271
Iteration 39970, loss = -15.0973
Iteration 39980, loss = -14.3068
Iteration 39990, loss = -14.0774
Iteration 40000, loss = -14.4678
Om: 6.00%, s8: 4.50% accuracy
chi2: 1.378

Iteration 40010, loss = -14.8769
Iteration 40020, loss = -15.0990
Iteration 40030, loss = -15.0066
Iteration 40040, loss = -15.0465
Iteration 40050, loss = -14.4341
Iteration 40060, loss = -14.5564
Iteration 40070, loss = -14.8236
Iteration 40080, loss = -15.0598
Iteration 40090, loss = -14.5357
Iteration 40100, loss = -14.9422
Iteration 40110, loss = -15.0801
Iteration 40120, loss = -14.2695
Iteration 40130, loss = -14.8936
Iteration 40140, loss = -15.1933
Iteration 40150, loss = -13.9111
Iteration 40160, loss = -15.1380
Iteration 40170, loss = -15.0273
Iteration 40180, loss = -14.2803
Iteration 40190, loss = -15.2545
Iteration 40200, loss = -15.4250
Iteration 40210, loss = -14.3641
Iteration 40220, loss = -14.4031
Iteration 40230, loss = -14.6054
Iteration 40240, loss = -14.8192
Iteration 40250, loss = -15.2883
Iteration 40260, loss = -13.9463
Iteration 40270, loss = -14.7859
Iteration 40280, loss = -15.0257
Iteration 40290, loss = -15.4469
Iteration 40300, loss = -15.1555
Iteration 40310, loss = -14.6211
Iteration 40320, loss = -15.1409
Iteration 40330, loss = -15.1523
Iteration 40340, loss = -14.6966
Iteration 40350, loss = -14.1055
Iteration 40360, loss = -13.9363
Iteration 40370, loss = -14.8728
Iteration 40380, loss = -15.2213
Iteration 40390, loss = -14.7446
Iteration 40400, loss = -14.1432
Iteration 40410, loss = -14.3766
Iteration 40420, loss = -14.8461
Iteration 40430, loss = -14.4677
Iteration 40440, loss = -14.2706
Iteration 40450, loss = -14.2071
Starting epoch 28
Iteration 40460, loss = -14.9327
Iteration 40470, loss = -14.4291
Iteration 40480, loss = -14.9269
Iteration 40490, loss = -14.1484
Iteration 40500, loss = -15.2816
Iteration 40510, loss = -14.4286
Iteration 40520, loss = -14.9779
Iteration 40530, loss = -14.8790
Iteration 40540, loss = -14.7142
Iteration 40550, loss = -15.0259
Iteration 40560, loss = -14.3150
Iteration 40570, loss = -14.8847
Iteration 40580, loss = -14.8376
Iteration 40590, loss = -15.0075
Iteration 40600, loss = -14.5748
Iteration 40610, loss = -15.2475
Iteration 40620, loss = -14.6026
Iteration 40630, loss = -14.5005
Iteration 40640, loss = -13.9732
Iteration 40650, loss = -14.4316
Iteration 40660, loss = -14.5566
Iteration 40670, loss = -15.0499
Iteration 40680, loss = -14.3236
Iteration 40690, loss = -13.8093
Iteration 40700, loss = -14.8863
Iteration 40710, loss = -15.3305
Iteration 40720, loss = -15.1116
Iteration 40730, loss = -14.3787
Iteration 40740, loss = -15.0450
Iteration 40750, loss = -14.7993
Iteration 40760, loss = -15.0075
Iteration 40770, loss = -14.6644
Iteration 40780, loss = -15.1743
Iteration 40790, loss = -15.3418
Iteration 40800, loss = -15.1377
Iteration 40810, loss = -15.1847
Iteration 40820, loss = -15.4561
Iteration 40830, loss = -15.2304
Iteration 40840, loss = -14.8791
Iteration 40850, loss = -15.1122
Iteration 40860, loss = -14.5204
Iteration 40870, loss = -14.8363
Iteration 40880, loss = -14.7961
Iteration 40890, loss = -13.8930
Iteration 40900, loss = -15.3039
Iteration 40910, loss = -14.7291
Iteration 40920, loss = -15.1445
Iteration 40930, loss = -15.2250
Iteration 40940, loss = -15.3895
Iteration 40950, loss = -15.1332
Iteration 40960, loss = -13.6236
Iteration 40970, loss = -14.2971
Iteration 40980, loss = -14.6761
Iteration 40990, loss = -14.5293
Iteration 41000, loss = -14.9421
Om: 5.26%, s8: 4.01% accuracy
chi2: 1.563

Iteration 41010, loss = -14.5192
Iteration 41020, loss = -14.8958
Iteration 41030, loss = -14.8473
Iteration 41040, loss = -15.1591
Iteration 41050, loss = -14.7460
Iteration 41060, loss = -15.2897
Iteration 41070, loss = -14.6325
Iteration 41080, loss = -14.9509
Iteration 41090, loss = -15.5015
Iteration 41100, loss = -14.5245
Iteration 41110, loss = -14.4139
Iteration 41120, loss = -14.6990
Iteration 41130, loss = -14.9732
Iteration 41140, loss = -14.8223
Iteration 41150, loss = -14.4984
Iteration 41160, loss = -15.3752
Iteration 41170, loss = -15.2011
Iteration 41180, loss = -15.1776
Iteration 41190, loss = -14.8177
Iteration 41200, loss = -14.8128
Iteration 41210, loss = -14.8096
Iteration 41220, loss = -14.9260
Iteration 41230, loss = -15.3829
Iteration 41240, loss = -14.7440
Iteration 41250, loss = -15.2393
Iteration 41260, loss = -15.1754
Iteration 41270, loss = -14.4489
Iteration 41280, loss = -15.0958
Iteration 41290, loss = -14.7260
Iteration 41300, loss = -14.9984
Iteration 41310, loss = -14.8189
Iteration 41320, loss = -15.2572
Iteration 41330, loss = -14.4759
Iteration 41340, loss = -14.4608
Iteration 41350, loss = -15.3132
Iteration 41360, loss = -14.7873
Iteration 41370, loss = -14.9188
Iteration 41380, loss = -15.0755
Iteration 41390, loss = -14.4448
Iteration 41400, loss = -14.3069
Iteration 41410, loss = -14.9346
Iteration 41420, loss = -15.0810
Iteration 41430, loss = -14.8029
Iteration 41440, loss = -14.3978
Iteration 41450, loss = -14.8004
Iteration 41460, loss = -15.4849
Iteration 41470, loss = -15.1195
Iteration 41480, loss = -15.1339
Iteration 41490, loss = -14.5316
Iteration 41500, loss = -15.4769
Iteration 41510, loss = -15.2948
Iteration 41520, loss = -15.5731
Iteration 41530, loss = -14.4511
Iteration 41540, loss = -14.9642
Iteration 41550, loss = -15.2980
Iteration 41560, loss = -14.7281
Iteration 41570, loss = -14.9062
Iteration 41580, loss = -14.5627
Iteration 41590, loss = -14.3050
Iteration 41600, loss = -14.5929
Iteration 41610, loss = -14.7531
Iteration 41620, loss = -15.5593
Iteration 41630, loss = -13.2620
Iteration 41640, loss = -13.5985
Iteration 41650, loss = -13.7200
Iteration 41660, loss = -14.1505
Iteration 41670, loss = -13.9932
Iteration 41680, loss = -13.7543
Iteration 41690, loss = -14.1632
Iteration 41700, loss = -13.7762
Iteration 41710, loss = -14.5858
Iteration 41720, loss = -14.0405
Iteration 41730, loss = -14.7639
Iteration 41740, loss = -14.3108
Iteration 41750, loss = -14.9090
Iteration 41760, loss = -15.1357
Iteration 41770, loss = -14.4546
Iteration 41780, loss = -15.0372
Iteration 41790, loss = -14.7208
Iteration 41800, loss = -14.2225
Iteration 41810, loss = -15.0839
Iteration 41820, loss = -14.8343
Iteration 41830, loss = -15.0273
Iteration 41840, loss = -15.2932
Iteration 41850, loss = -14.7763
Iteration 41860, loss = -15.2645
Iteration 41870, loss = -14.5262
Iteration 41880, loss = -15.3098
Iteration 41890, loss = -13.3409
Iteration 41900, loss = -14.5328
Starting epoch 29
Iteration 41910, loss = -14.8245
Iteration 41920, loss = -14.3477
Iteration 41930, loss = -14.3332
Iteration 41940, loss = -14.2711
Iteration 41950, loss = -14.2538
Iteration 41960, loss = -14.5968
Iteration 41970, loss = -14.7112
Iteration 41980, loss = -14.8580
Iteration 41990, loss = -14.0026
Iteration 42000, loss = -14.7713
Om: 5.42%, s8: 4.06% accuracy
chi2: 1.913

Iteration 42010, loss = -14.8062
Iteration 42020, loss = -15.0100
Iteration 42030, loss = -15.0452
Iteration 42040, loss = -14.6601
Iteration 42050, loss = -14.4433
Iteration 42060, loss = -14.3753
Iteration 42070, loss = -14.5007
Iteration 42080, loss = -14.1195
Iteration 42090, loss = -14.8583
Iteration 42100, loss = -15.2902
Iteration 42110, loss = -14.7861
Iteration 42120, loss = -14.4449
Iteration 42130, loss = -15.1183
Iteration 42140, loss = -15.0212
Iteration 42150, loss = -15.4532
Iteration 42160, loss = -15.6125
Iteration 42170, loss = -14.1544
Iteration 42180, loss = -15.2102
Iteration 42190, loss = -14.8731
Iteration 42200, loss = -15.1634
Iteration 42210, loss = -14.8061
Iteration 42220, loss = -14.1046
Iteration 42230, loss = -14.3846
Iteration 42240, loss = -15.4180
Iteration 42250, loss = -15.0543
Iteration 42260, loss = -14.4065
Iteration 42270, loss = -15.2620
Iteration 42280, loss = -15.0181
Iteration 42290, loss = -14.9295
Iteration 42300, loss = -14.4869
Iteration 42310, loss = -14.5793
Iteration 42320, loss = -15.2678
Iteration 42330, loss = -14.2549
Iteration 42340, loss = -14.7721
Iteration 42350, loss = -14.7542
Iteration 42360, loss = -15.0486
Iteration 42370, loss = -15.1416
Iteration 42380, loss = -15.2517
Iteration 42390, loss = -14.7336
Iteration 42400, loss = -14.5884
Iteration 42410, loss = -15.1917
Iteration 42420, loss = -15.1737
Iteration 42430, loss = -15.1209
Iteration 42440, loss = -15.2864
Iteration 42450, loss = -15.3492
Iteration 42460, loss = -14.5768
Iteration 42470, loss = -15.2035
Iteration 42480, loss = -14.8780
Iteration 42490, loss = -14.7914
Iteration 42500, loss = -15.1468
Iteration 42510, loss = -15.6067
Iteration 42520, loss = -14.7836
Iteration 42530, loss = -14.9514
Iteration 42540, loss = -15.1011
Iteration 42550, loss = -13.8795
Iteration 42560, loss = -15.0932
Iteration 42570, loss = -15.2453
Iteration 42580, loss = -15.1401
Iteration 42590, loss = -15.4833
Iteration 42600, loss = -15.1601
Iteration 42610, loss = -14.5505
Iteration 42620, loss = -15.2959
Iteration 42630, loss = -15.4988
Iteration 42640, loss = -15.1372
Iteration 42650, loss = -15.2477
Iteration 42660, loss = -15.1508
Iteration 42670, loss = -14.7391
Iteration 42680, loss = -15.4531
Iteration 42690, loss = -14.5008
Iteration 42700, loss = -15.3962
Iteration 42710, loss = -15.2456
Iteration 42720, loss = -15.2801
Iteration 42730, loss = -14.7149
Iteration 42740, loss = -14.9538
Iteration 42750, loss = -15.1812
Iteration 42760, loss = -15.0521
Iteration 42770, loss = -14.8981
Iteration 42780, loss = -15.3983
Iteration 42790, loss = -14.8663
Iteration 42800, loss = -14.6388
Iteration 42810, loss = -15.5940
Iteration 42820, loss = -15.5451
Iteration 42830, loss = -13.7547
Iteration 42840, loss = -14.0502
Iteration 42850, loss = -15.1597
Iteration 42860, loss = -15.6935
Iteration 42870, loss = -15.3291
Iteration 42880, loss = -14.8259
Iteration 42890, loss = -15.4797
Iteration 42900, loss = -14.9591
Iteration 42910, loss = -15.4841
Iteration 42920, loss = -15.3294
Iteration 42930, loss = -15.3682
Iteration 42940, loss = -15.0166
Iteration 42950, loss = -15.0109
Iteration 42960, loss = -15.4551
Iteration 42970, loss = -14.9688
Iteration 42980, loss = -15.0447
Iteration 42990, loss = -14.5568
Iteration 43000, loss = -14.6335
Om: 4.69%, s8: 3.63% accuracy
chi2: 2.075

Iteration 43010, loss = -14.9212
Iteration 43020, loss = -15.1395
Iteration 43030, loss = -15.1350
Iteration 43040, loss = -14.0853
Iteration 43050, loss = -15.2373
Iteration 43060, loss = -15.0082
Iteration 43070, loss = -14.1535
Iteration 43080, loss = -14.8303
Iteration 43090, loss = -15.0560
Iteration 43100, loss = -14.5334
Iteration 43110, loss = -14.9150
Iteration 43120, loss = -15.0530
Iteration 43130, loss = -15.0926
Iteration 43140, loss = -15.4326
Iteration 43150, loss = -13.8453
Iteration 43160, loss = -14.7129
Iteration 43170, loss = -15.3383
Iteration 43180, loss = -15.3684
Iteration 43190, loss = -15.4111
Iteration 43200, loss = -14.8340
Iteration 43210, loss = -15.3733
Iteration 43220, loss = -15.4649
Iteration 43230, loss = -15.0992
Iteration 43240, loss = -14.4838
Iteration 43250, loss = -14.1578
Iteration 43260, loss = -14.6806
Iteration 43270, loss = -15.2724
Iteration 43280, loss = -14.5056
Iteration 43290, loss = -14.1994
Iteration 43300, loss = -14.7526
Iteration 43310, loss = -15.4039
Iteration 43320, loss = -15.1311
Iteration 43330, loss = -15.1266
Iteration 43340, loss = -13.4368
Starting epoch 30
Iteration 43350, loss = -15.1773
Iteration 43360, loss = -14.1772
Iteration 43370, loss = -15.4816
Iteration 43380, loss = -15.1454
Iteration 43390, loss = -15.9225
Iteration 43400, loss = -14.9203
Iteration 43410, loss = -14.6929
Iteration 43420, loss = -14.1735
Iteration 43430, loss = -15.2291
Iteration 43440, loss = -15.1782
Iteration 43450, loss = -15.4787
Iteration 43460, loss = -15.3981
Iteration 43470, loss = -15.5468
Iteration 43480, loss = -15.0140
Iteration 43490, loss = -15.0084
Iteration 43500, loss = -16.1271
Iteration 43510, loss = -15.1799
Iteration 43520, loss = -15.4705
Iteration 43530, loss = -15.1889
Iteration 43540, loss = -14.4122
Iteration 43550, loss = -14.9483
Iteration 43560, loss = -15.2069
Iteration 43570, loss = -14.9923
Iteration 43580, loss = -15.1119
Iteration 43590, loss = -14.4379
Iteration 43600, loss = -14.9872
Iteration 43610, loss = -15.0513
Iteration 43620, loss = -14.5656
Iteration 43630, loss = -15.0641
Iteration 43640, loss = -14.6551
Iteration 43650, loss = -15.1370
Iteration 43660, loss = -14.9118
Iteration 43670, loss = -15.4964
Iteration 43680, loss = -15.7296
Iteration 43690, loss = -14.8543
Iteration 43700, loss = -15.6873
Iteration 43710, loss = -15.5236
Iteration 43720, loss = -15.1275
Iteration 43730, loss = -15.4371
Iteration 43740, loss = -15.3658
Iteration 43750, loss = -15.1621
Iteration 43760, loss = -15.2510
Iteration 43770, loss = -14.8337
Iteration 43780, loss = -14.9325
Iteration 43790, loss = -15.5766
Iteration 43800, loss = -15.4006
Iteration 43810, loss = -15.0104
Iteration 43820, loss = -15.4169
Iteration 43830, loss = -15.5206
Iteration 43840, loss = -14.2673
Iteration 43850, loss = -14.9223
Iteration 43860, loss = -14.9745
Iteration 43870, loss = -14.6688
Iteration 43880, loss = -14.9720
Iteration 43890, loss = -14.2536
Iteration 43900, loss = -15.0956
Iteration 43910, loss = -15.2401
Iteration 43920, loss = -15.2964
Iteration 43930, loss = -15.5454
Iteration 43940, loss = -15.0839
Iteration 43950, loss = -15.0115
Iteration 43960, loss = -14.4394
Iteration 43970, loss = -15.2153
Iteration 43980, loss = -14.9885
Iteration 43990, loss = -14.7560
Iteration 44000, loss = -14.8666
Om: 5.05%, s8: 3.72% accuracy
chi2: 2.184

Iteration 44010, loss = -15.3365
Iteration 44020, loss = -15.5634
Iteration 44030, loss = -15.2826
Iteration 44040, loss = -15.0201
Iteration 44050, loss = -15.5442
Iteration 44060, loss = -14.9381
Iteration 44070, loss = -14.6812
Iteration 44080, loss = -14.8100
Iteration 44090, loss = -15.5666
Iteration 44100, loss = -15.5522
Iteration 44110, loss = -15.7024
Iteration 44120, loss = -15.7339
Iteration 44130, loss = -15.2313
Iteration 44140, loss = -14.5018
Iteration 44150, loss = -15.1305
Iteration 44160, loss = -14.8037
Iteration 44170, loss = -15.3948
Iteration 44180, loss = -15.6336
Iteration 44190, loss = -15.2455
Iteration 44200, loss = -14.3600
Iteration 44210, loss = -15.4819
Iteration 44220, loss = -14.6024
Iteration 44230, loss = -14.9480
Iteration 44240, loss = -15.3743
Iteration 44250, loss = -14.9291
Iteration 44260, loss = -15.2802
Iteration 44270, loss = -15.2579
Iteration 44280, loss = -15.4472
Iteration 44290, loss = -15.3636
Iteration 44300, loss = -15.3980
Iteration 44310, loss = -15.3569
Iteration 44320, loss = -14.9336
Iteration 44330, loss = -14.9212
Iteration 44340, loss = -15.4236
Iteration 44350, loss = -16.4127
Iteration 44360, loss = -14.9474
Iteration 44370, loss = -15.5732
Iteration 44380, loss = -15.4321
Iteration 44390, loss = -15.8852
Iteration 44400, loss = -15.9181
Iteration 44410, loss = -15.2744
Iteration 44420, loss = -15.0257
Iteration 44430, loss = -15.5357
Iteration 44440, loss = -16.0026
Iteration 44450, loss = -14.9934
Iteration 44460, loss = -15.4394
Iteration 44470, loss = -15.8655
Iteration 44480, loss = -14.6478
Iteration 44490, loss = -15.0911
Iteration 44500, loss = -14.0110
Iteration 44510, loss = -15.1108
Iteration 44520, loss = -15.5538
Iteration 44530, loss = -15.0111
Iteration 44540, loss = -14.9285
Iteration 44550, loss = -14.9794
Iteration 44560, loss = -15.0527
Iteration 44570, loss = -15.4036
Iteration 44580, loss = -14.9852
Iteration 44590, loss = -15.0912
Iteration 44600, loss = -14.8079
Iteration 44610, loss = -14.3307
Iteration 44620, loss = -15.3897
Iteration 44630, loss = -15.4811
Iteration 44640, loss = -15.0964
Iteration 44650, loss = -15.7395
Iteration 44660, loss = -13.8492
Iteration 44670, loss = -15.0807
Iteration 44680, loss = -15.3700
Iteration 44690, loss = -14.8317
Iteration 44700, loss = -15.5989
Iteration 44710, loss = -15.0190
Iteration 44720, loss = -15.4870
Iteration 44730, loss = -15.6204
Iteration 44740, loss = -15.5335
Iteration 44750, loss = -15.1505
Iteration 44760, loss = -15.2299
Iteration 44770, loss = -15.7848
Iteration 44780, loss = -13.5690
Iteration 44790, loss = -14.7956
Starting epoch 31
Iteration 44800, loss = -15.9866
Iteration 44810, loss = -14.6867
Iteration 44820, loss = -14.9241
Iteration 44830, loss = -14.6255
Iteration 44840, loss = -14.5791
Iteration 44850, loss = -15.0146
Iteration 44860, loss = -14.9472
Iteration 44870, loss = -15.3426
Iteration 44880, loss = -15.0768
Iteration 44890, loss = -15.2219
Iteration 44900, loss = -14.9437
Iteration 44910, loss = -15.1753
Iteration 44920, loss = -14.4694
Iteration 44930, loss = -15.0574
Iteration 44940, loss = -15.0042
Iteration 44950, loss = -14.9076
Iteration 44960, loss = -14.7482
Iteration 44970, loss = -14.2584
Iteration 44980, loss = -14.7686
Iteration 44990, loss = -15.2163
Iteration 45000, loss = -15.7310
Om: 5.03%, s8: 3.58% accuracy
chi2: 2.816

Iteration 45010, loss = -15.3899
Iteration 45020, loss = -15.5217
Iteration 45030, loss = -15.3200
Iteration 45040, loss = -15.6518
Iteration 45050, loss = -15.6428
Iteration 45060, loss = -14.5232
Iteration 45070, loss = -14.9454
Iteration 45080, loss = -15.5875
Iteration 45090, loss = -15.8815
Iteration 45100, loss = -15.1411
Iteration 45110, loss = -15.4026
Iteration 45120, loss = -15.2950
Iteration 45130, loss = -15.8853
Iteration 45140, loss = -14.9369
Iteration 45150, loss = -15.4491
Iteration 45160, loss = -15.2919
Iteration 45170, loss = -15.3541
Iteration 45180, loss = -14.8372
Iteration 45190, loss = -15.1578
Iteration 45200, loss = -15.0424
Iteration 45210, loss = -15.6574
Iteration 45220, loss = -14.0457
Iteration 45230, loss = -15.3446
Iteration 45240, loss = -14.5921
Iteration 45250, loss = -15.3504
Iteration 45260, loss = -15.6469
Iteration 45270, loss = -15.6001
Iteration 45280, loss = -15.3167
Iteration 45290, loss = -15.1232
Iteration 45300, loss = -15.6330
Iteration 45310, loss = -15.3743
Iteration 45320, loss = -15.9222
Iteration 45330, loss = -14.7244
Iteration 45340, loss = -15.3626
Iteration 45350, loss = -14.7290
Iteration 45360, loss = -15.5299
Iteration 45370, loss = -15.4842
Iteration 45380, loss = -15.4080
Iteration 45390, loss = -15.6668
Iteration 45400, loss = -16.1627
Iteration 45410, loss = -15.1879
Iteration 45420, loss = -15.3372
Iteration 45430, loss = -15.9331
Iteration 45440, loss = -14.7629
Iteration 45450, loss = -15.4597
Iteration 45460, loss = -15.6492
Iteration 45470, loss = -15.3516
Iteration 45480, loss = -15.4637
Iteration 45490, loss = -15.4936
Iteration 45500, loss = -15.0014
Iteration 45510, loss = -15.6613
Iteration 45520, loss = -15.7005
Iteration 45530, loss = -15.7398
Iteration 45540, loss = -15.3329
Iteration 45550, loss = -15.0892
Iteration 45560, loss = -15.0878
Iteration 45570, loss = -15.3719
Iteration 45580, loss = -14.7636
Iteration 45590, loss = -15.3402
Iteration 45600, loss = -15.7594
Iteration 45610, loss = -15.4605
Iteration 45620, loss = -15.2721
Iteration 45630, loss = -15.7760
Iteration 45640, loss = -15.3555
Iteration 45650, loss = -15.4857
Iteration 45660, loss = -14.9998
Iteration 45670, loss = -15.5445
Iteration 45680, loss = -14.3970
Iteration 45690, loss = -15.0816
Iteration 45700, loss = -15.3426
Iteration 45710, loss = -15.6007
Iteration 45720, loss = -14.7399
Iteration 45730, loss = -15.0305
Iteration 45740, loss = -15.6410
Iteration 45750, loss = -15.6914
Iteration 45760, loss = -15.3835
Iteration 45770, loss = -11.3915
Iteration 45780, loss = -14.5052
Iteration 45790, loss = -14.3315
Iteration 45800, loss = -15.2559
Iteration 45810, loss = -15.2026
Iteration 45820, loss = -15.6159
Iteration 45830, loss = -15.0141
Iteration 45840, loss = -14.4484
Iteration 45850, loss = -15.6092
Iteration 45860, loss = -15.1468
Iteration 45870, loss = -15.0613
Iteration 45880, loss = -15.2277
Iteration 45890, loss = -15.5093
Iteration 45900, loss = -15.2274
Iteration 45910, loss = -16.0297
Iteration 45920, loss = -15.6182
Iteration 45930, loss = -14.4216
Iteration 45940, loss = -15.4651
Iteration 45950, loss = -15.2352
Iteration 45960, loss = -14.7124
Iteration 45970, loss = -15.5659
Iteration 45980, loss = -15.5365
Iteration 45990, loss = -14.9853
Iteration 46000, loss = -15.2910
Om: 5.98%, s8: 4.85% accuracy
chi2: 3.264

Iteration 46010, loss = -14.9161
Iteration 46020, loss = -15.1477
Iteration 46030, loss = -15.7072
Iteration 46040, loss = -13.5688
Iteration 46050, loss = -14.4927
Iteration 46060, loss = -15.3283
Iteration 46070, loss = -15.5385
Iteration 46080, loss = -15.9023
Iteration 46090, loss = -14.5553
Iteration 46100, loss = -15.6651
Iteration 46110, loss = -14.7092
Iteration 46120, loss = -15.3822
Iteration 46130, loss = -14.7804
Iteration 46140, loss = -14.6849
Iteration 46150, loss = -14.9202
Iteration 46160, loss = -15.6892
Iteration 46170, loss = -14.4436
Iteration 46180, loss = -15.3124
Iteration 46190, loss = -15.4308
Iteration 46200, loss = -15.5462
Iteration 46210, loss = -14.8810
Iteration 46220, loss = -15.0766
Iteration 46230, loss = -14.1501
Starting epoch 32
Iteration 46240, loss = -15.7175
Iteration 46250, loss = -14.7852
Iteration 46260, loss = -15.4879
Iteration 46270, loss = -14.8163
Iteration 46280, loss = -15.4189
Iteration 46290, loss = -14.9022
Iteration 46300, loss = -15.6594
Iteration 46310, loss = -14.7191
Iteration 46320, loss = -14.7938
Iteration 46330, loss = -15.9262
Iteration 46340, loss = -15.9659
Iteration 46350, loss = -15.2089
Iteration 46360, loss = -15.4765
Iteration 46370, loss = -15.8379
Iteration 46380, loss = -15.1180
Iteration 46390, loss = -14.8643
Iteration 46400, loss = -14.3922
Iteration 46410, loss = -15.5755
Iteration 46420, loss = -14.9683
Iteration 46430, loss = -15.4067
Iteration 46440, loss = -15.2122
Iteration 46450, loss = -15.8339
Iteration 46460, loss = -14.8709
Iteration 46470, loss = -14.9071
Iteration 46480, loss = -15.5096
Iteration 46490, loss = -15.4106
Iteration 46500, loss = -15.2220
Iteration 46510, loss = -14.7110
Iteration 46520, loss = -15.3979
Iteration 46530, loss = -14.8960
Iteration 46540, loss = -15.8151
Iteration 46550, loss = -15.3282
Iteration 46560, loss = -15.5290
Iteration 46570, loss = -15.6563
Iteration 46580, loss = -15.4727
Iteration 46590, loss = -15.7062
Iteration 46600, loss = -15.5989
Iteration 46610, loss = -15.3564
Iteration 46620, loss = -15.5192
Iteration 46630, loss = -15.8158
Iteration 46640, loss = -15.2581
Iteration 46650, loss = -15.5511
Iteration 46660, loss = -15.2978
Iteration 46670, loss = -15.1200
Iteration 46680, loss = -15.3020
Iteration 46690, loss = -15.3135
Iteration 46700, loss = -15.1797
Iteration 46710, loss = -15.7469
Iteration 46720, loss = -14.6042
Iteration 46730, loss = -15.1095
Iteration 46740, loss = -14.6259
Iteration 46750, loss = -14.9654
Iteration 46760, loss = -14.2759
Iteration 46770, loss = -15.2654
Iteration 46780, loss = -15.1608
Iteration 46790, loss = -15.2638
Iteration 46800, loss = -15.4511
Iteration 46810, loss = -15.5358
Iteration 46820, loss = -15.3723
Iteration 46830, loss = -14.8808
Iteration 46840, loss = -15.6012
Iteration 46850, loss = -15.2429
Iteration 46860, loss = -15.5052
Iteration 46870, loss = -15.3594
Iteration 46880, loss = -15.0512
Iteration 46890, loss = -15.2979
Iteration 46900, loss = -14.8457
Iteration 46910, loss = -15.2213
Iteration 46920, loss = -15.4185
Iteration 46930, loss = -15.5043
Iteration 46940, loss = -16.1571
Iteration 46950, loss = -15.5063
Iteration 46960, loss = -15.4978
Iteration 46970, loss = -15.1589
Iteration 46980, loss = -15.4353
Iteration 46990, loss = -15.5259
Iteration 47000, loss = -15.9861
Om: 4.58%, s8: 3.42% accuracy
chi2: 2.354

Iteration 47010, loss = -15.7168
Iteration 47020, loss = -15.4790
Iteration 47030, loss = -14.8842
Iteration 47040, loss = -15.4240
Iteration 47050, loss = -14.6208
Iteration 47060, loss = -15.4567
Iteration 47070, loss = -15.8464
Iteration 47080, loss = -15.6363
Iteration 47090, loss = -15.7421
Iteration 47100, loss = -16.1016
Iteration 47110, loss = -15.5222
Iteration 47120, loss = -15.0642
Iteration 47130, loss = -15.8973
Iteration 47140, loss = -14.7099
Iteration 47150, loss = -15.4308
Iteration 47160, loss = -15.4844
Iteration 47170, loss = -15.4496
Iteration 47180, loss = -14.6548
Iteration 47190, loss = -15.3189
Iteration 47200, loss = -14.6733
Iteration 47210, loss = -15.3057
Iteration 47220, loss = -14.5396
Iteration 47230, loss = -15.5088
Iteration 47240, loss = -16.4747
Iteration 47250, loss = -15.0635
Iteration 47260, loss = -15.4981
Iteration 47270, loss = -15.4716
Iteration 47280, loss = -15.9176
Iteration 47290, loss = -16.3309
Iteration 47300, loss = -15.6657
Iteration 47310, loss = -15.3636
Iteration 47320, loss = -15.5692
Iteration 47330, loss = -16.0891
Iteration 47340, loss = -15.4027
Iteration 47350, loss = -15.6058
Iteration 47360, loss = -15.9091
Iteration 47370, loss = -14.9205
Iteration 47380, loss = -14.9531
Iteration 47390, loss = -15.3512
Iteration 47400, loss = -14.9840
Iteration 47410, loss = -15.7520
Iteration 47420, loss = -15.7202
Iteration 47430, loss = -15.3798
Iteration 47440, loss = -15.3017
Iteration 47450, loss = -15.1617
Iteration 47460, loss = -15.6321
Iteration 47470, loss = -15.5491
Iteration 47480, loss = -15.1309
Iteration 47490, loss = -14.9496
Iteration 47500, loss = -14.9325
Iteration 47510, loss = -15.0596
Iteration 47520, loss = -15.7879
Iteration 47530, loss = -15.4389
Iteration 47540, loss = -16.2175
Iteration 47550, loss = -14.6675
Iteration 47560, loss = -14.9838
Iteration 47570, loss = -16.0473
Iteration 47580, loss = -15.2944
Iteration 47590, loss = -15.5825
Iteration 47600, loss = -15.4969
Iteration 47610, loss = -15.1861
Iteration 47620, loss = -15.0832
Iteration 47630, loss = -15.4537
Iteration 47640, loss = -15.9614
Iteration 47650, loss = -15.4873
Iteration 47660, loss = -15.8647
Iteration 47670, loss = -14.1624
Iteration 47680, loss = -14.9037
Starting epoch 33
Iteration 47690, loss = -15.8108
Iteration 47700, loss = -15.5394
Iteration 47710, loss = -14.8714
Iteration 47720, loss = -14.9227
Iteration 47730, loss = -14.8993
Iteration 47740, loss = -14.7650
Iteration 47750, loss = -15.4579
Iteration 47760, loss = -15.6525
Iteration 47770, loss = -14.9238
Iteration 47780, loss = -15.4711
Iteration 47790, loss = -15.6882
Iteration 47800, loss = -15.4139
Iteration 47810, loss = -15.3674
Iteration 47820, loss = -15.5313
Iteration 47830, loss = -15.4044
Iteration 47840, loss = -15.2851
Iteration 47850, loss = -15.2382
Iteration 47860, loss = -15.3870
Iteration 47870, loss = -15.9555
Iteration 47880, loss = -15.8711
Iteration 47890, loss = -15.8810
Iteration 47900, loss = -14.6772
Iteration 47910, loss = -15.5320
Iteration 47920, loss = -14.6427
Iteration 47930, loss = -15.7827
Iteration 47940, loss = -16.4335
Iteration 47950, loss = -15.2765
Iteration 47960, loss = -15.5110
Iteration 47970, loss = -15.4623
Iteration 47980, loss = -15.5734
Iteration 47990, loss = -15.6617
Iteration 48000, loss = -15.4397
Om: 4.43%, s8: 3.43% accuracy
chi2: 2.124

Iteration 48010, loss = -15.7621
Iteration 48020, loss = -15.5175
Iteration 48030, loss = -15.3436
Iteration 48040, loss = -15.8014
Iteration 48050, loss = -15.3426
Iteration 48060, loss = -15.3607
Iteration 48070, loss = -15.5507
Iteration 48080, loss = -15.3683
Iteration 48090, loss = -14.9834
Iteration 48100, loss = -15.0758
Iteration 48110, loss = -15.1693
Iteration 48120, loss = -15.6685
Iteration 48130, loss = -15.7790
Iteration 48140, loss = -15.8153
Iteration 48150, loss = -15.6549
Iteration 48160, loss = -15.2654
Iteration 48170, loss = -15.7180
Iteration 48180, loss = -15.6051
Iteration 48190, loss = -14.7617
Iteration 48200, loss = -15.1911
Iteration 48210, loss = -15.8463
Iteration 48220, loss = -15.6232
Iteration 48230, loss = -15.4118
Iteration 48240, loss = -15.2112
Iteration 48250, loss = -15.7569
Iteration 48260, loss = -15.3459
Iteration 48270, loss = -14.9285
Iteration 48280, loss = -15.8672
Iteration 48290, loss = -16.0523
Iteration 48300, loss = -15.3753
Iteration 48310, loss = -15.6711
Iteration 48320, loss = -15.4951
Iteration 48330, loss = -15.2758
Iteration 48340, loss = -15.2642
Iteration 48350, loss = -15.3594
Iteration 48360, loss = -15.6891
Iteration 48370, loss = -15.5188
Iteration 48380, loss = -15.6016
Iteration 48390, loss = -15.1392
Iteration 48400, loss = -16.0320
Iteration 48410, loss = -15.6987
Iteration 48420, loss = -15.5372
Iteration 48430, loss = -15.5621
Iteration 48440, loss = -15.6341
Iteration 48450, loss = -15.1973
Iteration 48460, loss = -15.7651
Iteration 48470, loss = -14.5894
Iteration 48480, loss = -15.4747
Iteration 48490, loss = -15.7420
Iteration 48500, loss = -15.6526
Iteration 48510, loss = -15.4828
Iteration 48520, loss = -16.0779
Iteration 48530, loss = -15.3082
Iteration 48540, loss = -15.8161
Iteration 48550, loss = -15.6470
Iteration 48560, loss = -15.5822
Iteration 48570, loss = -14.8791
Iteration 48580, loss = -15.3707
Iteration 48590, loss = -15.2754
Iteration 48600, loss = -15.4525
Iteration 48610, loss = -14.7963
Iteration 48620, loss = -14.8500
Iteration 48630, loss = -15.6151
Iteration 48640, loss = -15.5394
Iteration 48650, loss = -15.1243
Iteration 48660, loss = -15.3136
Iteration 48670, loss = -15.5971
Iteration 48680, loss = -15.1787
Iteration 48690, loss = -15.9127
Iteration 48700, loss = -15.9447
Iteration 48710, loss = -15.5390
Iteration 48720, loss = -15.1379
Iteration 48730, loss = -15.4829
Iteration 48740, loss = -15.6740
Iteration 48750, loss = -15.0004
Iteration 48760, loss = -15.4660
Iteration 48770, loss = -15.7384
Iteration 48780, loss = -14.3216
Iteration 48790, loss = -14.6564
Iteration 48800, loss = -15.8819
Iteration 48810, loss = -15.7415
Iteration 48820, loss = -14.5899
Iteration 48830, loss = -15.3568
Iteration 48840, loss = -15.1328
Iteration 48850, loss = -14.6582
Iteration 48860, loss = -15.9577
Iteration 48870, loss = -16.0230
Iteration 48880, loss = -15.1164
Iteration 48890, loss = -15.5179
Iteration 48900, loss = -15.8101
Iteration 48910, loss = -15.4686
Iteration 48920, loss = -15.9454
Iteration 48930, loss = -14.1118
Iteration 48940, loss = -14.4374
Iteration 48950, loss = -15.4061
Iteration 48960, loss = -15.6433
Iteration 48970, loss = -15.6950
Iteration 48980, loss = -15.1375
Iteration 48990, loss = -15.5945
Iteration 49000, loss = -14.5343
Om: 5.54%, s8: 4.40% accuracy
chi2: 3.333

Iteration 49010, loss = -13.7625
Iteration 49020, loss = -14.7689
Iteration 49030, loss = -15.2628
Iteration 49040, loss = -15.2158
Iteration 49050, loss = -15.8756
Iteration 49060, loss = -15.1589
Iteration 49070, loss = -16.0886
Iteration 49080, loss = -15.7949
Iteration 49090, loss = -15.5955
Iteration 49100, loss = -15.0763
Iteration 49110, loss = -15.7756
Iteration 49120, loss = -15.2317
Starting epoch 34
Iteration 49130, loss = -15.6051
Iteration 49140, loss = -14.5331
Iteration 49150, loss = -15.8420
Iteration 49160, loss = -14.9990
Iteration 49170, loss = -16.0125
Iteration 49180, loss = -15.1069
Iteration 49190, loss = -15.0487
Iteration 49200, loss = -14.7233
Iteration 49210, loss = -15.2006
Iteration 49220, loss = -15.5985
Iteration 49230, loss = -15.7626
Iteration 49240, loss = -15.7376
Iteration 49250, loss = -15.4256
Iteration 49260, loss = -15.5817
Iteration 49270, loss = -15.6473
Iteration 49280, loss = -16.6155
Iteration 49290, loss = -15.3449
Iteration 49300, loss = -15.4372
Iteration 49310, loss = -15.5395
Iteration 49320, loss = -15.2519
Iteration 49330, loss = -15.3107
Iteration 49340, loss = -15.8193
Iteration 49350, loss = -15.7975
Iteration 49360, loss = -15.5766
slurmstepd: error: *** JOB 42157489 ON sh-19-08 CANCELLED AT 2019-05-12T02:32:26 DUE TO TIME LIMIT ***
