
The following have been reloaded with a version change:
  1) python/3.6.1 => python/2.7.13

-------------------------------------------------------------------------------
There are messages associated with the following module(s):
-------------------------------------------------------------------------------

py-tensorflow/1.9.0_py27:
    Warning: this module requires a GPU, it won't work on CPU nodes.

-------------------------------------------------------------------------------


The following have been reloaded with a version change:
  1) cuda/10.1.168 => cuda/9.0.176


The following have been reloaded with a version change:
  1) openmpi/4.0.1 => openmpi/2.1.1

-------------------------------------------------------------------------------
There are messages associated with the following module(s):
-------------------------------------------------------------------------------

py-scipystack/1.0_py27:
    The SciPy Stack module is deprecated. Please use those individual
    modules instead: py-scipy, py-numpy, py-matplotlib, py-pandas, py-sympy

-------------------------------------------------------------------------------

RuntimeError: module compiled against API version 0xc but this version of numpy is 0xa
RuntimeError: module compiled against API version 0xc but this version of numpy is 0xa
2019-10-31 08:39:49.874852: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-10-31 08:39:50.031102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 0 with properties: 
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.076
pciBusID: 0000:04:00.0
totalMemory: 11.93GiB freeMemory: 11.82GiB
2019-10-31 08:39:50.117636: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 1 with properties: 
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.076
pciBusID: 0000:85:00.0
totalMemory: 11.93GiB freeMemory: 11.82GiB
2019-10-31 08:39:50.117718: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0, 1
2019-10-31 08:39:50.877373: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-31 08:39:50.877424: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 1 
2019-10-31 08:39:50.877434: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N N 
2019-10-31 08:39:50.877439: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 1:   N N 
2019-10-31 08:39:50.877787: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11440 MB memory) -> physical GPU (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:04:00.0, compute capability: 5.2)
2019-10-31 08:39:51.069814: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 11440 MB memory) -> physical GPU (device: 1, name: GeForce GTX TITAN X, pci bus id: 0000:85:00.0, compute capability: 5.2)
False
Starting epoch 0
Iteration 0, loss = 38.4897
Om: 83.29%, s8: 92.50% accuracy
RMSE: 0.2513, 0.7999
Iteration 10, loss = 6.7705
Iteration 20, loss = 2.8654
Iteration 30, loss = 3.2673
Iteration 40, loss = 3.3683
Iteration 50, loss = 2.4382
Iteration 60, loss = 2.3629
Iteration 70, loss = 4.5942
Iteration 80, loss = 2.1604
Iteration 90, loss = 3.7834
Iteration 100, loss = 4.7328
Iteration 110, loss = 3.1722
Iteration 120, loss = 2.6956
Iteration 130, loss = 2.0916
Iteration 140, loss = 3.5774
Iteration 150, loss = 2.5071
Iteration 160, loss = 2.3656
Iteration 170, loss = 2.2119
Iteration 180, loss = 2.7986
Iteration 190, loss = 2.6684
Iteration 200, loss = 2.7210
Iteration 210, loss = 2.2862
Iteration 220, loss = 2.0401
Iteration 230, loss = 3.1279
Iteration 240, loss = 2.2240
Iteration 250, loss = 2.9873
Iteration 260, loss = 2.8663
Iteration 270, loss = 2.4544
Iteration 280, loss = 2.3417
Iteration 290, loss = 3.2521
Iteration 300, loss = 2.5508
Iteration 310, loss = 2.9576
Iteration 320, loss = 2.3908
Iteration 330, loss = 2.1682
Iteration 340, loss = 2.9553
Iteration 350, loss = 2.7793
Iteration 360, loss = 2.4371
Iteration 370, loss = 2.2743
Iteration 380, loss = 2.8052
Iteration 390, loss = 3.1066
Iteration 400, loss = 2.3105
Iteration 410, loss = 2.1948
Iteration 420, loss = 2.8605
Iteration 430, loss = 2.1148
Iteration 440, loss = 2.6455
Iteration 450, loss = 2.2969
Iteration 460, loss = 2.6053
Iteration 470, loss = 2.5092
Iteration 480, loss = 3.7803
Iteration 490, loss = 3.3426
Iteration 500, loss = 3.9692
Iteration 510, loss = 3.8920
Iteration 520, loss = 3.1470
Iteration 530, loss = 3.0164
Iteration 540, loss = 2.6944
Iteration 550, loss = 2.8705
Iteration 560, loss = 2.3611
Iteration 570, loss = 2.4675
Iteration 580, loss = 2.7057
Iteration 590, loss = 4.6244
Iteration 600, loss = 2.7020
Iteration 610, loss = 2.9176
Iteration 620, loss = 2.4781
Iteration 630, loss = 2.6857
Iteration 640, loss = 2.6590
Iteration 650, loss = 2.2843
Iteration 660, loss = 3.4654
Iteration 670, loss = 2.4680
Iteration 680, loss = 3.0432
Iteration 690, loss = 2.7061
Iteration 700, loss = 2.6877
Iteration 710, loss = 3.5329
Iteration 720, loss = 2.8692
Iteration 730, loss = 2.2716
Iteration 740, loss = 2.8170
Iteration 750, loss = 3.7177
Iteration 760, loss = 3.3666
Iteration 770, loss = 2.8441
Iteration 780, loss = 2.8195
Iteration 790, loss = 2.8473
Iteration 800, loss = 2.5704
Iteration 810, loss = 1.9910
Iteration 820, loss = 2.7107
Iteration 830, loss = 2.8891
Iteration 840, loss = 2.1988
Iteration 850, loss = 2.7719
Iteration 860, loss = 3.9291
Iteration 870, loss = 2.7555
Iteration 880, loss = 2.3393
Iteration 890, loss = 2.6362
Iteration 900, loss = 2.4319
Iteration 910, loss = 2.2342
Iteration 920, loss = 2.8591
Iteration 930, loss = 2.1912
Iteration 940, loss = 2.8082
Iteration 950, loss = 2.9114
Iteration 960, loss = 2.5010
Iteration 970, loss = 2.5919
Iteration 980, loss = 2.4095
Iteration 990, loss = 2.6700
Iteration 1000, loss = 2.3583
Om: 11.00%, s8: 6.75% accuracy
RMSE: 0.0402, 0.0664
Iteration 1010, loss = 2.7182
Iteration 1020, loss = 2.5398
Iteration 1030, loss = 2.5837
Iteration 1040, loss = 2.8400
Iteration 1050, loss = 3.0533
Iteration 1060, loss = 2.7203
Iteration 1070, loss = 2.5925
Iteration 1080, loss = 2.6587
Iteration 1090, loss = 2.9118
Iteration 1100, loss = 2.9380
Iteration 1110, loss = 2.4362
Iteration 1120, loss = 3.8366
Iteration 1130, loss = 2.5307
Iteration 1140, loss = 2.8927
Iteration 1150, loss = 2.2323
Iteration 1160, loss = 2.5556
Iteration 1170, loss = 3.0782
Iteration 1180, loss = 2.8359
Iteration 1190, loss = 2.1250
Iteration 1200, loss = 2.6315
Iteration 1210, loss = 2.4697
Iteration 1220, loss = 2.3913
Iteration 1230, loss = 2.5728
Iteration 1240, loss = 2.9062
Iteration 1250, loss = 2.7234
Iteration 1260, loss = 2.6654
Iteration 1270, loss = 2.6678
Iteration 1280, loss = 2.8182
Iteration 1290, loss = 3.0044
Iteration 1300, loss = 3.0862
Iteration 1310, loss = 2.9583
Iteration 1320, loss = 2.7655
Iteration 1330, loss = 2.4682
Iteration 1340, loss = 2.6426
Iteration 1350, loss = 2.3645
Iteration 1360, loss = 2.4529
Iteration 1370, loss = 2.6856
Iteration 1380, loss = 2.5601
Iteration 1390, loss = 2.2749
Iteration 1400, loss = 2.3221
Iteration 1410, loss = 2.1972
Iteration 1420, loss = 2.5635
Iteration 1430, loss = 2.2455
Iteration 1440, loss = 2.4004
Starting epoch 1
Iteration 1450, loss = 3.3636
Iteration 1460, loss = 2.9511
Iteration 1470, loss = 2.5523
Iteration 1480, loss = 3.0831
Iteration 1490, loss = 3.2668
Iteration 1500, loss = 3.0289
Iteration 1510, loss = 2.3248
Iteration 1520, loss = 2.7830
Iteration 1530, loss = 2.8636
Iteration 1540, loss = 2.6323
Iteration 1550, loss = 2.5850
Iteration 1560, loss = 2.6740
Iteration 1570, loss = 2.5042
Iteration 1580, loss = 2.9166
Iteration 1590, loss = 3.0805
Iteration 1600, loss = 2.3611
Iteration 1610, loss = 2.4311
Iteration 1620, loss = 2.7471
Iteration 1630, loss = 2.5039
Iteration 1640, loss = 2.9809
Iteration 1650, loss = 2.3645
Iteration 1660, loss = 3.1922
Iteration 1670, loss = 3.0496
Iteration 1680, loss = 2.5026
Iteration 1690, loss = 2.5094
Iteration 1700, loss = 2.4117
Iteration 1710, loss = 2.2149
Iteration 1720, loss = 2.5898
Iteration 1730, loss = 2.6749
Iteration 1740, loss = 2.7440
Iteration 1750, loss = 2.6881
Iteration 1760, loss = 3.1824
Iteration 1770, loss = 2.7789
Iteration 1780, loss = 2.7663
Iteration 1790, loss = 2.7691
Iteration 1800, loss = 2.4918
Iteration 1810, loss = 2.3683
Iteration 1820, loss = 2.5049
Iteration 1830, loss = 2.8842
Iteration 1840, loss = 3.0862
Iteration 1850, loss = 2.2785
Iteration 1860, loss = 2.7404
Iteration 1870, loss = 2.8390
Iteration 1880, loss = 2.7306
Iteration 1890, loss = 2.9321
Iteration 1900, loss = 2.6797
Iteration 1910, loss = 2.7801
Iteration 1920, loss = 2.2439
Iteration 1930, loss = 2.4891
Iteration 1940, loss = 3.2952
Iteration 1950, loss = 2.9884
Iteration 1960, loss = 1.9319
Iteration 1970, loss = 2.4020
Iteration 1980, loss = 2.9106
Iteration 1990, loss = 2.7040
Iteration 2000, loss = 2.3110
Om: 8.83%, s8: 6.51% accuracy
RMSE: 0.0295, 0.0672
Iteration 2010, loss = 2.8191
Iteration 2020, loss = 2.6529
Iteration 2030, loss = 2.6562
Iteration 2040, loss = 2.8077
Iteration 2050, loss = 2.6228
Iteration 2060, loss = 2.4306
Iteration 2070, loss = 2.5901
Iteration 2080, loss = 2.6912
Iteration 2090, loss = 2.3747
Iteration 2100, loss = 3.1634
Iteration 2110, loss = 2.6758
Iteration 2120, loss = 2.7665
Iteration 2130, loss = 2.5378
Iteration 2140, loss = 2.5264
Iteration 2150, loss = 3.0071
Iteration 2160, loss = 2.6549
Iteration 2170, loss = 2.9414
Iteration 2180, loss = 2.2194
Iteration 2190, loss = 3.0463
Iteration 2200, loss = 2.7198
Iteration 2210, loss = 2.7233
Iteration 2220, loss = 3.0898
Iteration 2230, loss = 2.8405
Iteration 2240, loss = 3.0608
Iteration 2250, loss = 2.4762
Iteration 2260, loss = 3.0037
Iteration 2270, loss = 2.3373
Iteration 2280, loss = 2.7402
Iteration 2290, loss = 2.1149
Iteration 2300, loss = 3.8436
Iteration 2310, loss = 3.8863
Iteration 2320, loss = 1.9617
Iteration 2330, loss = 2.4839
Iteration 2340, loss = 3.0135
Iteration 2350, loss = 4.1677
Iteration 2360, loss = 2.9058
Iteration 2370, loss = 2.5352
Iteration 2380, loss = 2.6985
Iteration 2390, loss = 2.7415
Iteration 2400, loss = 2.5990
Iteration 2410, loss = 2.4400
Iteration 2420, loss = 2.5222
Iteration 2430, loss = 3.4067
Iteration 2440, loss = 2.4777
Iteration 2450, loss = 2.4499
Iteration 2460, loss = 2.8262
Iteration 2470, loss = 2.9514
Iteration 2480, loss = 2.3628
Iteration 2490, loss = 2.2066
Iteration 2500, loss = 2.8912
Iteration 2510, loss = 2.4070
Iteration 2520, loss = 3.0125
Iteration 2530, loss = 2.2558
Iteration 2540, loss = 3.0108
Iteration 2550, loss = 2.7391
Iteration 2560, loss = 2.4444
Iteration 2570, loss = 3.0139
Iteration 2580, loss = 3.0087
Iteration 2590, loss = 2.8374
Iteration 2600, loss = 2.2203
Iteration 2610, loss = 2.2235
Iteration 2620, loss = 2.3590
Iteration 2630, loss = 2.0455
Iteration 2640, loss = 2.8102
Iteration 2650, loss = 2.5737
Iteration 2660, loss = 3.0033
Iteration 2670, loss = 2.3521
Iteration 2680, loss = 2.5262
Iteration 2690, loss = 2.7728
Iteration 2700, loss = 2.8888
Iteration 2710, loss = 2.7052
Iteration 2720, loss = 2.1146
Iteration 2730, loss = 2.4983
Iteration 2740, loss = 2.2329
Iteration 2750, loss = 2.6640
Iteration 2760, loss = 2.9138
Iteration 2770, loss = 2.4887
Iteration 2780, loss = 2.6552
Iteration 2790, loss = 3.1599
Iteration 2800, loss = 2.3426
Iteration 2810, loss = 2.4975
Iteration 2820, loss = 2.0817
Iteration 2830, loss = 2.1859
Iteration 2840, loss = 2.9839
Iteration 2850, loss = 2.5081
Iteration 2860, loss = 2.8031
Iteration 2870, loss = 3.1216
Iteration 2880, loss = 2.5483
Starting epoch 2
Iteration 2890, loss = 2.3837
Iteration 2900, loss = 2.8563
Iteration 2910, loss = 3.3442
Iteration 2920, loss = 2.9932
Iteration 2930, loss = 2.8942
Iteration 2940, loss = 2.3071
Iteration 2950, loss = 2.5715
Iteration 2960, loss = 3.1510
Iteration 2970, loss = 2.0810
Iteration 2980, loss = 2.5628
Iteration 2990, loss = 2.7299
Iteration 3000, loss = 2.8183
Om: 8.92%, s8: 7.78% accuracy
RMSE: 0.0299, 0.0808
Iteration 3010, loss = 2.7348
Iteration 3020, loss = 2.2090
Iteration 3030, loss = 2.8646
Iteration 3040, loss = 2.4555
Iteration 3050, loss = 2.2365
Iteration 3060, loss = 2.5848
Iteration 3070, loss = 2.8011
Iteration 3080, loss = 2.4361
Iteration 3090, loss = 1.8133
Iteration 3100, loss = 2.4024
Iteration 3110, loss = 2.2051
Iteration 3120, loss = 2.2137
Iteration 3130, loss = 3.3238
Iteration 3140, loss = 2.2770
Iteration 3150, loss = 2.5878
Iteration 3160, loss = 2.4406
Iteration 3170, loss = 2.4746
Iteration 3180, loss = 2.8160
Iteration 3190, loss = 2.3740
Iteration 3200, loss = 2.6895
Iteration 3210, loss = 2.3261
Iteration 3220, loss = 2.1414
Iteration 3230, loss = 2.5956
Iteration 3240, loss = 2.6606
Iteration 3250, loss = 2.3407
Iteration 3260, loss = 2.1817
Iteration 3270, loss = 2.7418
Iteration 3280, loss = 2.8830
Iteration 3290, loss = 2.4315
Iteration 3300, loss = 2.2112
Iteration 3310, loss = 2.8701
Iteration 3320, loss = 2.1255
Iteration 3330, loss = 2.7969
Iteration 3340, loss = 2.7610
Iteration 3350, loss = 2.8254
Iteration 3360, loss = 2.4953
Iteration 3370, loss = 2.4979
Iteration 3380, loss = 2.1754
Iteration 3390, loss = 2.9080
Iteration 3400, loss = 2.8866
Iteration 3410, loss = 2.2299
Iteration 3420, loss = 2.2817
Iteration 3430, loss = 2.4461
Iteration 3440, loss = 2.7606
Iteration 3450, loss = 2.3804
Iteration 3460, loss = 2.3883
Iteration 3470, loss = 2.6473
Iteration 3480, loss = 3.5900
Iteration 3490, loss = 2.6153
Iteration 3500, loss = 2.8051
Iteration 3510, loss = 2.4390
Iteration 3520, loss = 2.3479
Iteration 3530, loss = 2.6388
Iteration 3540, loss = 2.1431
Iteration 3550, loss = 3.0974
Iteration 3560, loss = 2.6214
Iteration 3570, loss = 2.7913
Iteration 3580, loss = 2.5672
Iteration 3590, loss = 2.5022
Iteration 3600, loss = 2.8900
Iteration 3610, loss = 2.9079
Iteration 3620, loss = 2.4874
Iteration 3630, loss = 2.8726
Iteration 3640, loss = 3.2798
Iteration 3650, loss = 2.0381
Iteration 3660, loss = 2.5105
Iteration 3670, loss = 2.7945
Iteration 3680, loss = 2.8334
Iteration 3690, loss = 2.6291
Iteration 3700, loss = 2.0090
Iteration 3710, loss = 2.4800
Iteration 3720, loss = 2.8611
Iteration 3730, loss = 2.0133
Iteration 3740, loss = 2.3111
Iteration 3750, loss = 4.4459
Iteration 3760, loss = 2.6211
Iteration 3770, loss = 2.3279
Iteration 3780, loss = 2.3484
Iteration 3790, loss = 2.3783
Iteration 3800, loss = 2.8737
Iteration 3810, loss = 2.9745
Iteration 3820, loss = 2.0712
Iteration 3830, loss = 2.8391
Iteration 3840, loss = 2.3898
Iteration 3850, loss = 2.3094
Iteration 3860, loss = 2.6790
Iteration 3870, loss = 2.3173
Iteration 3880, loss = 2.6748
Iteration 3890, loss = 2.3521
Iteration 3900, loss = 2.6284
Iteration 3910, loss = 2.3835
Iteration 3920, loss = 2.6620
Iteration 3930, loss = 2.8602
Iteration 3940, loss = 2.7267
Iteration 3950, loss = 2.5310
Iteration 3960, loss = 2.6032
Iteration 3970, loss = 2.5840
Iteration 3980, loss = 2.8400
Iteration 3990, loss = 3.0390
Iteration 4000, loss = 2.4247
Om: 9.62%, s8: 7.60% accuracy
RMSE: 0.0333, 0.0791
Iteration 4010, loss = 3.3984
Iteration 4020, loss = 2.3554
Iteration 4030, loss = 2.8230
Iteration 4040, loss = 2.4724
Iteration 4050, loss = 2.6448
Iteration 4060, loss = 2.7936
Iteration 4070, loss = 2.3893
Iteration 4080, loss = 2.0714
Iteration 4090, loss = 2.7614
Iteration 4100, loss = 2.1013
Iteration 4110, loss = 2.3030
Iteration 4120, loss = 2.6281
Iteration 4130, loss = 2.7159
Iteration 4140, loss = 2.8621
Iteration 4150, loss = 3.1149
Iteration 4160, loss = 2.6444
Iteration 4170, loss = 2.8722
Iteration 4180, loss = 2.4016
Iteration 4190, loss = 3.4286
Iteration 4200, loss = 2.4446
Iteration 4210, loss = 2.3819
Iteration 4220, loss = 2.3748
Iteration 4230, loss = 2.7050
Iteration 4240, loss = 2.5052
Iteration 4250, loss = 2.4962
Iteration 4260, loss = 2.5332
Iteration 4270, loss = 2.5992
Iteration 4280, loss = 2.1699
Iteration 4290, loss = 2.3170
Iteration 4300, loss = 1.9119
Iteration 4310, loss = 2.3668
Iteration 4320, loss = 2.2519
Iteration 4330, loss = 2.6907
Starting epoch 3
Iteration 4340, loss = 2.2701
Iteration 4350, loss = 2.5101
Iteration 4360, loss = 2.5491
Iteration 4370, loss = 2.9431
Iteration 4380, loss = 2.8866
Iteration 4390, loss = 2.9565
Iteration 4400, loss = 2.2533
Iteration 4410, loss = 2.8198
Iteration 4420, loss = 2.4337
Iteration 4430, loss = 3.0710
Iteration 4440, loss = 2.7840
Iteration 4450, loss = 2.7623
Iteration 4460, loss = 3.0118
Iteration 4470, loss = 2.9961
Iteration 4480, loss = 3.2689
Iteration 4490, loss = 2.4672
Iteration 4500, loss = 2.0808
Iteration 4510, loss = 2.9785
Iteration 4520, loss = 2.6465
Iteration 4530, loss = 3.2299
Iteration 4540, loss = 2.7311
Iteration 4550, loss = 2.4118
Iteration 4560, loss = 2.6967
Iteration 4570, loss = 2.3627
Iteration 4580, loss = 2.2003
Iteration 4590, loss = 2.5217
Iteration 4600, loss = 2.3266
Iteration 4610, loss = 2.2962
Iteration 4620, loss = 2.6796
Iteration 4630, loss = 2.8672
Iteration 4640, loss = 2.6163
Iteration 4650, loss = 3.1814
Iteration 4660, loss = 2.4942
Iteration 4670, loss = 2.7081
Iteration 4680, loss = 2.4577
Iteration 4690, loss = 2.4704
Iteration 4700, loss = 2.3469
Iteration 4710, loss = 2.4629
Iteration 4720, loss = 3.0321
Iteration 4730, loss = 3.0349
Iteration 4740, loss = 2.2765
Iteration 4750, loss = 2.8088
Iteration 4760, loss = 3.2427
Iteration 4770, loss = 2.7469
Iteration 4780, loss = 2.4830
Iteration 4790, loss = 2.7140
Iteration 4800, loss = 2.8288
Iteration 4810, loss = 2.2929
Iteration 4820, loss = 2.3327
Iteration 4830, loss = 3.0029
Iteration 4840, loss = 2.2249
Iteration 4850, loss = 2.0070
Iteration 4860, loss = 2.4929
Iteration 4870, loss = 2.9419
Iteration 4880, loss = 2.5775
Iteration 4890, loss = 2.2137
Iteration 4900, loss = 2.4840
Iteration 4910, loss = 2.5195
Iteration 4920, loss = 2.7241
Iteration 4930, loss = 2.8148
Iteration 4940, loss = 2.5626
Iteration 4950, loss = 2.3380
Iteration 4960, loss = 2.6533
Iteration 4970, loss = 2.4686
Iteration 4980, loss = 2.6025
Iteration 4990, loss = 3.1082
Iteration 5000, loss = 2.7051
Om: 8.90%, s8: 6.42% accuracy
RMSE: 0.0299, 0.0636
Iteration 5010, loss = 2.7181
Iteration 5020, loss = 2.4643
Iteration 5030, loss = 2.5623
Iteration 5040, loss = 3.0757
Iteration 5050, loss = 2.7475
Iteration 5060, loss = 2.9474
Iteration 5070, loss = 2.3053
Iteration 5080, loss = 3.1559
Iteration 5090, loss = 3.1222
Iteration 5100, loss = 2.6220
Iteration 5110, loss = 2.9642
Iteration 5120, loss = 3.3129
Iteration 5130, loss = 2.7009
Iteration 5140, loss = 2.4253
Iteration 5150, loss = 2.9693
Iteration 5160, loss = 2.1836
Iteration 5170, loss = 2.6404
Iteration 5180, loss = 2.1221
Iteration 5190, loss = 2.5256
Iteration 5200, loss = 2.9897
Iteration 5210, loss = 2.3113
Iteration 5220, loss = 2.4652
Iteration 5230, loss = 2.9126
Iteration 5240, loss = 3.0576
Iteration 5250, loss = 2.4634
Iteration 5260, loss = 2.5016
Iteration 5270, loss = 2.6891
Iteration 5280, loss = 2.6671
Iteration 5290, loss = 2.6195
Iteration 5300, loss = 2.6893
Iteration 5310, loss = 2.3776
Iteration 5320, loss = 2.6121
Iteration 5330, loss = 3.7004
Iteration 5340, loss = 2.9197
Iteration 5350, loss = 2.6692
Iteration 5360, loss = 2.6951
Iteration 5370, loss = 2.3627
Iteration 5380, loss = 2.3590
Iteration 5390, loss = 3.1175
Iteration 5400, loss = 2.2802
Iteration 5410, loss = 3.0143
Iteration 5420, loss = 2.1815
Iteration 5430, loss = 2.7855
Iteration 5440, loss = 2.7339
Iteration 5450, loss = 2.4812
Iteration 5460, loss = 2.7812
Iteration 5470, loss = 2.3950
Iteration 5480, loss = 3.1769
Iteration 5490, loss = 2.3097
Iteration 5500, loss = 2.2150
Iteration 5510, loss = 2.3481
Iteration 5520, loss = 1.9996
Iteration 5530, loss = 2.6810
Iteration 5540, loss = 2.6184
Iteration 5550, loss = 2.8552
Iteration 5560, loss = 2.3108
Iteration 5570, loss = 2.4551
Iteration 5580, loss = 2.5676
Iteration 5590, loss = 2.7426
Iteration 5600, loss = 2.6910
Iteration 5610, loss = 2.1846
Iteration 5620, loss = 2.5425
Iteration 5630, loss = 2.4107
Iteration 5640, loss = 2.4169
Iteration 5650, loss = 2.9071
Iteration 5660, loss = 2.4200
Iteration 5670, loss = 2.6297
Iteration 5680, loss = 3.1770
Iteration 5690, loss = 2.4460
Iteration 5700, loss = 2.4374
Iteration 5710, loss = 1.8532
Iteration 5720, loss = 2.2809
Iteration 5730, loss = 2.9205
Iteration 5740, loss = 2.8664
Iteration 5750, loss = 2.7912
Iteration 5760, loss = 3.0240
Iteration 5770, loss = 2.4668
Starting epoch 4
Iteration 5780, loss = 2.4491
Iteration 5790, loss = 2.6945
Iteration 5800, loss = 2.7813
Iteration 5810, loss = 2.8649
Iteration 5820, loss = 2.9114
Iteration 5830, loss = 2.3127
Iteration 5840, loss = 2.5757
Iteration 5850, loss = 2.7327
Iteration 5860, loss = 2.2498
Iteration 5870, loss = 3.1521
Iteration 5880, loss = 3.2522
Iteration 5890, loss = 3.6351
Iteration 5900, loss = 3.1525
Iteration 5910, loss = 2.1027
Iteration 5920, loss = 2.7492
Iteration 5930, loss = 2.3559
Iteration 5940, loss = 2.2616
Iteration 5950, loss = 2.4165
Iteration 5960, loss = 2.7850
Iteration 5970, loss = 2.4687
Iteration 5980, loss = 1.9563
Iteration 5990, loss = 2.4782
Iteration 6000, loss = 2.0809
Om: 8.84%, s8: 6.46% accuracy
RMSE: 0.0296, 0.0665
Iteration 6010, loss = 2.1680
Iteration 6020, loss = 2.1851
Iteration 6030, loss = 2.4106
Iteration 6040, loss = 2.3487
Iteration 6050, loss = 2.4829
Iteration 6060, loss = 2.3876
Iteration 6070, loss = 2.9857
Iteration 6080, loss = 2.4100
Iteration 6090, loss = 2.8908
Iteration 6100, loss = 2.5039
Iteration 6110, loss = 2.3944
Iteration 6120, loss = 2.5807
Iteration 6130, loss = 2.6917
Iteration 6140, loss = 2.3411
Iteration 6150, loss = 2.1781
Iteration 6160, loss = 2.7299
Iteration 6170, loss = 2.8735
Iteration 6180, loss = 2.1347
Iteration 6190, loss = 2.8406
Iteration 6200, loss = 3.5892
Iteration 6210, loss = 2.1976
Iteration 6220, loss = 2.4683
Iteration 6230, loss = 2.1233
Iteration 6240, loss = 2.4047
Iteration 6250, loss = 2.4909
Iteration 6260, loss = 2.4864
Iteration 6270, loss = 2.3229
Iteration 6280, loss = 2.7645
Iteration 6290, loss = 2.9040
Iteration 6300, loss = 2.3579
Iteration 6310, loss = 2.5128
Iteration 6320, loss = 2.2755
Iteration 6330, loss = 2.4980
Iteration 6340, loss = 2.1608
Iteration 6350, loss = 2.3979
Iteration 6360, loss = 2.6380
Iteration 6370, loss = 3.4636
Iteration 6380, loss = 2.5751
Iteration 6390, loss = 2.7517
Iteration 6400, loss = 2.4029
Iteration 6410, loss = 2.3913
Iteration 6420, loss = 2.6878
Iteration 6430, loss = 2.1516
Iteration 6440, loss = 2.7817
Iteration 6450, loss = 2.5655
Iteration 6460, loss = 2.7226
Iteration 6470, loss = 2.7072
Iteration 6480, loss = 2.5710
Iteration 6490, loss = 2.9245
Iteration 6500, loss = 2.8349
Iteration 6510, loss = 2.5459
Iteration 6520, loss = 2.8330
Iteration 6530, loss = 3.2292
Iteration 6540, loss = 2.0800
Iteration 6550, loss = 2.5112
Iteration 6560, loss = 2.7970
Iteration 6570, loss = 2.8394
Iteration 6580, loss = 2.7376
Iteration 6590, loss = 1.9670
Iteration 6600, loss = 2.7271
Iteration 6610, loss = 2.7028
Iteration 6620, loss = 2.0121
Iteration 6630, loss = 2.2899
Iteration 6640, loss = 3.1808
Iteration 6650, loss = 2.6601
Iteration 6660, loss = 2.6141
Iteration 6670, loss = 2.6906
Iteration 6680, loss = 2.5852
Iteration 6690, loss = 2.2815
Iteration 6700, loss = 2.8608
Iteration 6710, loss = 2.0885
Iteration 6720, loss = 2.8258
Iteration 6730, loss = 2.3161
Iteration 6740, loss = 2.6478
Iteration 6750, loss = 2.6282
Iteration 6760, loss = 2.3963
Iteration 6770, loss = 2.5413
Iteration 6780, loss = 2.3784
Iteration 6790, loss = 3.0194
Iteration 6800, loss = 2.3042
Iteration 6810, loss = 2.6149
Iteration 6820, loss = 3.2085
Iteration 6830, loss = 2.6764
Iteration 6840, loss = 2.3655
Iteration 6850, loss = 2.7469
Iteration 6860, loss = 2.5979
Iteration 6870, loss = 2.7061
Iteration 6880, loss = 2.9210
Iteration 6890, loss = 2.4364
Iteration 6900, loss = 3.0125
Iteration 6910, loss = 2.7183
Iteration 6920, loss = 3.2717
Iteration 6930, loss = 2.3968
Iteration 6940, loss = 2.5823
Iteration 6950, loss = 2.8838
Iteration 6960, loss = 2.2442
Iteration 6970, loss = 2.2670
Iteration 6980, loss = 2.6011
Iteration 6990, loss = 2.0473
Iteration 7000, loss = 2.3231
Om: 9.01%, s8: 6.43% accuracy
RMSE: 0.0304, 0.0633
Iteration 7010, loss = 2.4840
Iteration 7020, loss = 2.6441
Iteration 7030, loss = 2.8276
Iteration 7040, loss = 2.8727
Iteration 7050, loss = 2.6207
Iteration 7060, loss = 2.4290
Iteration 7070, loss = 2.6020
Iteration 7080, loss = 3.3791
Iteration 7090, loss = 2.4550
Iteration 7100, loss = 2.3389
Iteration 7110, loss = 2.3556
Iteration 7120, loss = 2.7480
Iteration 7130, loss = 2.4596
Iteration 7140, loss = 2.4288
Iteration 7150, loss = 2.4086
Iteration 7160, loss = 2.5790
Iteration 7170, loss = 2.1685
Iteration 7180, loss = 2.2993
Iteration 7190, loss = 1.9037
Iteration 7200, loss = 2.3607
Iteration 7210, loss = 2.3096
Iteration 7220, loss = 2.3643
