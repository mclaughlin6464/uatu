
The following have been reloaded with a version change:
  1) openmpi/2.1.1 => openmpi/4.0.1


Lmod is automatically replacing "py-scipystack/1.0_py27" with
"py-numpy/1.14.3_py27".

-------------------------------------------------------------------------------
There are messages associated with the following module(s):
-------------------------------------------------------------------------------

py-tensorflow/1.9.0_py27:
    Warning: this module requires a GPU, it won't work on CPU nodes.

-------------------------------------------------------------------------------


The following have been reloaded with a version change:
  1) cuda/10.1.168 => cuda/9.0.176


The following have been reloaded with a version change:
  1) openmpi/4.0.1 => openmpi/2.1.1


Lmod is automatically replacing "py-numpy/1.14.3_py27" with
"py-scipystack/1.0_py27".

-------------------------------------------------------------------------------
The following dependent module(s) are not currently loaded: py-numpy/1.14.3_py27 (required by: py-tensorflow/1.9.0_py27)
-------------------------------------------------------------------------------
RuntimeError: module compiled against API version 0xc but this version of numpy is 0xa
RuntimeError: module compiled against API version 0xc but this version of numpy is 0xa
2019-10-03 10:44:09.597906: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-10-03 10:44:09.839085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 0 with properties: 
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.076
pciBusID: 0000:04:00.0
totalMemory: 11.93GiB freeMemory: 11.82GiB
2019-10-03 10:44:09.943900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 1 with properties: 
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.076
pciBusID: 0000:05:00.0
totalMemory: 11.93GiB freeMemory: 11.82GiB
2019-10-03 10:44:09.944504: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0, 1
2019-10-03 10:44:10.821439: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-03 10:44:10.821507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 1 
2019-10-03 10:44:10.821517: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N Y 
2019-10-03 10:44:10.821523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 1:   Y N 
2019-10-03 10:44:10.822774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11440 MB memory) -> physical GPU (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:04:00.0, compute capability: 5.2)
2019-10-03 10:44:11.010213: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 11440 MB memory) -> physical GPU (device: 1, name: GeForce GTX TITAN X, pci bus id: 0000:05:00.0, compute capability: 5.2)
Starting epoch 0
Iteration 0, loss = 4.3043
Om: 651.58%, s8: 146.22% accuracy
RMSE: 1.9274, 1.2508

Iteration 10, loss = 1.8204
Iteration 20, loss = 1.0142
Iteration 30, loss = 0.5394
Iteration 40, loss = 0.3714
Iteration 50, loss = 0.6868
Iteration 60, loss = 0.3377
Iteration 70, loss = 0.1632
Iteration 80, loss = 0.4250
Iteration 90, loss = 0.4160
Iteration 100, loss = 0.5784
Iteration 110, loss = 0.6262
Iteration 120, loss = 0.5673
Iteration 130, loss = 0.3349
Iteration 140, loss = 0.6112
Iteration 150, loss = 0.3417
Iteration 160, loss = 0.5049
Iteration 170, loss = 0.5880
Iteration 180, loss = 0.4053
Iteration 190, loss = 0.3973
Iteration 200, loss = 0.3619
Iteration 210, loss = 0.8641
Iteration 220, loss = 0.2486
Iteration 230, loss = 0.2026
Iteration 240, loss = 0.4572
Iteration 250, loss = 0.4322
Iteration 260, loss = 0.9772
Iteration 270, loss = 0.4270
Iteration 280, loss = 0.5107
Iteration 290, loss = 0.4015
Iteration 300, loss = 0.3896
Iteration 310, loss = 0.3436
Iteration 320, loss = 0.4832
Iteration 330, loss = 0.2969
Iteration 340, loss = 0.4234
Iteration 350, loss = 0.3957
Iteration 360, loss = 0.3649
Iteration 370, loss = 0.7992
Iteration 380, loss = 0.9049
Iteration 390, loss = 0.9955
Iteration 400, loss = 0.6048
Iteration 410, loss = 0.3826
Iteration 420, loss = 0.7477
Iteration 430, loss = 0.6657
Iteration 440, loss = 0.3071
Iteration 450, loss = 0.5047
Iteration 460, loss = 1.0291
Iteration 470, loss = 0.3365
Iteration 480, loss = 0.5779
Iteration 490, loss = 0.3751
Iteration 500, loss = 0.3863
Iteration 510, loss = 0.4019
Iteration 520, loss = 0.3683
Iteration 530, loss = 0.3533
Iteration 540, loss = 0.2565
Iteration 550, loss = 0.5213
Iteration 560, loss = 0.1627
Iteration 570, loss = 0.4409
Iteration 580, loss = 0.2395
Iteration 590, loss = 0.3143
Iteration 600, loss = 0.2260
Iteration 610, loss = 0.4336
Iteration 620, loss = 0.5943
Iteration 630, loss = 0.5629
Iteration 640, loss = 0.4016
Iteration 650, loss = 0.2268
Iteration 660, loss = 0.1916
Iteration 670, loss = 0.5307
Iteration 680, loss = 0.4583
Iteration 690, loss = 0.3157
Iteration 700, loss = 0.2843
Iteration 710, loss = 0.4259
Iteration 720, loss = 0.3660
Iteration 730, loss = 0.1609
Iteration 740, loss = 0.2956
Iteration 750, loss = 0.2955
Iteration 760, loss = 0.3570
Iteration 770, loss = 0.7421
Iteration 780, loss = 0.4743
Iteration 790, loss = 0.4438
Iteration 800, loss = 0.6078
Iteration 810, loss = 0.1680
Iteration 820, loss = 0.7235
Iteration 830, loss = 0.5334
Iteration 840, loss = 0.2731
Iteration 850, loss = 0.2004
Iteration 860, loss = 0.6565
Iteration 870, loss = 0.2874
Iteration 880, loss = 0.3606
Iteration 890, loss = 0.5697
Iteration 900, loss = 0.3802
Iteration 910, loss = 0.3527
Iteration 920, loss = 0.3262
Iteration 930, loss = 0.2586
Iteration 940, loss = 0.3203
Iteration 950, loss = 0.1779
Iteration 960, loss = 0.4614
Iteration 970, loss = 0.3716
Iteration 980, loss = 0.5652
Iteration 990, loss = 0.2015
Iteration 1000, loss = 0.4817
Om: 9.75%, s8: 9.59% accuracy
RMSE: 0.0344, 0.1033

Iteration 1010, loss = 0.3253
Iteration 1020, loss = 0.2123
Iteration 1030, loss = 0.2897
Iteration 1040, loss = 0.5423
Iteration 1050, loss = 0.4026
Iteration 1060, loss = 0.3450
Iteration 1070, loss = 0.4001
Iteration 1080, loss = 0.2955
Iteration 1090, loss = 0.1576
Iteration 1100, loss = 0.4345
Iteration 1110, loss = 0.4585
Iteration 1120, loss = 0.2479
Iteration 1130, loss = 0.3813
Iteration 1140, loss = 0.6096
Iteration 1150, loss = 0.4857
Iteration 1160, loss = 0.1869
Iteration 1170, loss = 0.4395
Iteration 1180, loss = 0.3225
Iteration 1190, loss = 0.2938
Iteration 1200, loss = 0.2418
Iteration 1210, loss = 0.2592
Iteration 1220, loss = 0.3799
Iteration 1230, loss = 0.5457
Iteration 1240, loss = 0.6852
Iteration 1250, loss = 0.1786
Iteration 1260, loss = 0.3893
Iteration 1270, loss = 0.3084
Iteration 1280, loss = 0.2988
Iteration 1290, loss = 0.2349
Iteration 1300, loss = 0.3229
Iteration 1310, loss = 0.4078
Iteration 1320, loss = 0.4212
Iteration 1330, loss = 0.4630
Iteration 1340, loss = 0.6693
Iteration 1350, loss = 0.1331
Iteration 1360, loss = 0.4503
Iteration 1370, loss = 0.3864
Iteration 1380, loss = 0.2320
Iteration 1390, loss = 0.2156
Iteration 1400, loss = 0.3149
Iteration 1410, loss = 0.2281
Iteration 1420, loss = 0.3823
Iteration 1430, loss = 0.4024
Iteration 1440, loss = 0.4173
Iteration 1450, loss = 0.2987
Iteration 1460, loss = 0.3010
Iteration 1470, loss = 0.2771
Iteration 1480, loss = 0.2508
Iteration 1490, loss = 0.5846
Iteration 1500, loss = 0.2628
Iteration 1510, loss = 0.1957
Iteration 1520, loss = 0.1796
Iteration 1530, loss = 0.3239
Iteration 1540, loss = 0.2587
Iteration 1550, loss = 0.2719
Iteration 1560, loss = 0.1805
Iteration 1570, loss = 0.1904
Iteration 1580, loss = 0.2396
Iteration 1590, loss = 0.3140
Iteration 1600, loss = 0.3879
Iteration 1610, loss = 0.2227
Iteration 1620, loss = 0.3107
Iteration 1630, loss = 0.3113
Iteration 1640, loss = 0.2208
Iteration 1650, loss = 0.3380
Iteration 1660, loss = 0.3003
Iteration 1670, loss = 0.3978
Iteration 1680, loss = 0.1652
Iteration 1690, loss = 0.3096
Iteration 1700, loss = 0.4160
Iteration 1710, loss = 0.2477
Iteration 1720, loss = 0.2584
Iteration 1730, loss = 0.2213
Iteration 1740, loss = 0.2721
Iteration 1750, loss = 0.2436
Iteration 1760, loss = 0.4299
Iteration 1770, loss = 0.1891
Iteration 1780, loss = 0.3569
Iteration 1790, loss = 0.4641
Iteration 1800, loss = 0.3929
Iteration 1810, loss = 0.2717
Iteration 1820, loss = 0.3736
Iteration 1830, loss = 0.1811
Iteration 1840, loss = 0.3298
Iteration 1850, loss = 0.2145
Iteration 1860, loss = 0.2025
Iteration 1870, loss = 0.2516
Iteration 1880, loss = 0.5466
Iteration 1890, loss = 0.4031
Iteration 1900, loss = 0.3432
Iteration 1910, loss = 0.2560
Iteration 1920, loss = 0.4000
Iteration 1930, loss = 0.2763
Iteration 1940, loss = 0.3503
Iteration 1950, loss = 0.2572
Iteration 1960, loss = 0.2831
Iteration 1970, loss = 0.2497
Iteration 1980, loss = 0.2291
Iteration 1990, loss = 0.2655
Iteration 2000, loss = 0.2582
Om: 10.77%, s8: 7.99% accuracy
RMSE: 0.0383, 0.0823

Iteration 2010, loss = 0.2398
Iteration 2020, loss = 0.2863
Iteration 2030, loss = 0.1749
Iteration 2040, loss = 0.2175
Iteration 2050, loss = 0.2685
Iteration 2060, loss = 0.3623
Iteration 2070, loss = 0.2332
Iteration 2080, loss = 0.3908
Iteration 2090, loss = 0.1938
Iteration 2100, loss = 0.2893
Iteration 2110, loss = 0.3624
Iteration 2120, loss = 0.1812
Iteration 2130, loss = 0.3204
Iteration 2140, loss = 0.1806
Iteration 2150, loss = 0.1974
Iteration 2160, loss = 0.2716
Iteration 2170, loss = 0.4548
Iteration 2180, loss = 0.3826
Iteration 2190, loss = 0.3486
Iteration 2200, loss = 0.4377
Iteration 2210, loss = 0.5139
Iteration 2220, loss = 0.3450
Iteration 2230, loss = 0.3587
Iteration 2240, loss = 0.2328
Iteration 2250, loss = 0.2991
Iteration 2260, loss = 0.2835
Iteration 2270, loss = 0.3137
Iteration 2280, loss = 0.2813
Iteration 2290, loss = 0.2439
Iteration 2300, loss = 0.3753
Iteration 2310, loss = 0.1749
Iteration 2320, loss = 0.2626
Iteration 2330, loss = 0.5865
Iteration 2340, loss = 0.3513
Iteration 2350, loss = 0.2770
Iteration 2360, loss = 0.1748
Iteration 2370, loss = 0.1921
Iteration 2380, loss = 0.1733
Iteration 2390, loss = 0.2136
Iteration 2400, loss = 0.3749
Iteration 2410, loss = 0.3220
Iteration 2420, loss = 0.3362
Iteration 2430, loss = 0.4831
Iteration 2440, loss = 0.3926
Iteration 2450, loss = 0.3004
Iteration 2460, loss = 0.3826
Iteration 2470, loss = 0.2596
Iteration 2480, loss = 0.2469
Iteration 2490, loss = 0.1345
Iteration 2500, loss = 0.3456
Iteration 2510, loss = 0.4700
Iteration 2520, loss = 0.2698
Iteration 2530, loss = 0.2399
Iteration 2540, loss = 0.2822
Iteration 2550, loss = 0.2169
Iteration 2560, loss = 0.2905
Iteration 2570, loss = 0.2120
Iteration 2580, loss = 0.3055
Iteration 2590, loss = 0.3229
Iteration 2600, loss = 0.3017
Iteration 2610, loss = 0.2162
Iteration 2620, loss = 0.2708
Iteration 2630, loss = 0.3397
Iteration 2640, loss = 0.2467
Iteration 2650, loss = 0.2594
Iteration 2660, loss = 0.4355
Iteration 2670, loss = 0.3263
Iteration 2680, loss = 0.4897
Iteration 2690, loss = 0.1787
Iteration 2700, loss = 0.3315
Iteration 2710, loss = 0.3071
Iteration 2720, loss = 0.3799
Iteration 2730, loss = 0.2822
Iteration 2740, loss = 0.2423
Iteration 2750, loss = 0.3106
Iteration 2760, loss = 0.2534
Iteration 2770, loss = 0.2888
Iteration 2780, loss = 0.3330
Iteration 2790, loss = 0.3014
Iteration 2800, loss = 0.2682
Iteration 2810, loss = 0.1557
Iteration 2820, loss = 0.2064
Iteration 2830, loss = 0.3129
Iteration 2840, loss = 0.2093
Iteration 2850, loss = 0.2907
Iteration 2860, loss = 0.3400
Iteration 2870, loss = 0.2162
Iteration 2880, loss = 0.2193
Iteration 2890, loss = 0.1816
Iteration 2900, loss = 0.3133
Iteration 2910, loss = 0.5814
Iteration 2920, loss = 0.1988
Iteration 2930, loss = 0.2251
Iteration 2940, loss = 0.3911
Iteration 2950, loss = 0.4134
Iteration 2960, loss = 0.2053
Iteration 2970, loss = 0.3689
Iteration 2980, loss = 0.3088
Iteration 2990, loss = 0.2977
Iteration 3000, loss = 0.3250
Om: 9.15%, s8: 6.38% accuracy
RMSE: 0.0313, 0.0627

Iteration 3010, loss = 0.4211
Iteration 3020, loss = 0.3597
Iteration 3030, loss = 0.2234
Iteration 3040, loss = 0.1331
Iteration 3050, loss = 0.1478
Iteration 3060, loss = 0.3524
Iteration 3070, loss = 0.3769
Iteration 3080, loss = 0.3570
Iteration 3090, loss = 0.2091
Iteration 3100, loss = 0.2336
Iteration 3110, loss = 0.2855
Iteration 3120, loss = 0.2855
Iteration 3130, loss = 0.2468
Iteration 3140, loss = 0.2825
Iteration 3150, loss = 0.3325
Iteration 3160, loss = 0.3316
Iteration 3170, loss = 0.2560
Iteration 3180, loss = 0.3348
Iteration 3190, loss = 0.2766
Iteration 3200, loss = 0.2051
Iteration 3210, loss = 0.2869
Iteration 3220, loss = 0.2747
Iteration 3230, loss = 0.3289
Iteration 3240, loss = 0.2865
Iteration 3250, loss = 0.3569
Iteration 3260, loss = 0.4222
Iteration 3270, loss = 0.4163
Iteration 3280, loss = 0.3683
Iteration 3290, loss = 0.6840
Iteration 3300, loss = 0.4846
Iteration 3310, loss = 0.2362
Iteration 3320, loss = 0.5220
Iteration 3330, loss = 0.1136
Iteration 3340, loss = 0.1143
Iteration 3350, loss = 0.3536
Iteration 3360, loss = 0.2527
Iteration 3370, loss = 0.2534
Iteration 3380, loss = 0.2126
Iteration 3390, loss = 0.2116
Iteration 3400, loss = 0.1815
Iteration 3410, loss = 0.3459
Iteration 3420, loss = 0.3685
Iteration 3430, loss = 0.4570
Iteration 3440, loss = 0.2734
Iteration 3450, loss = 0.3602
Iteration 3460, loss = 0.3367
Iteration 3470, loss = 0.3347
Iteration 3480, loss = 0.4241
Iteration 3490, loss = 0.3368
Iteration 3500, loss = 0.2892
Iteration 3510, loss = 0.2324
Iteration 3520, loss = 0.2570
Iteration 3530, loss = 0.2825
Iteration 3540, loss = 0.3977
Iteration 3550, loss = 0.3676
Iteration 3560, loss = 0.2647
Iteration 3570, loss = 0.3205
Iteration 3580, loss = 0.1913
Iteration 3590, loss = 0.2197
Iteration 3600, loss = 0.4099
Iteration 3610, loss = 0.1987
Iteration 3620, loss = 0.3869
Iteration 3630, loss = 0.3577
Iteration 3640, loss = 0.3436
Iteration 3650, loss = 0.2486
Iteration 3660, loss = 0.1974
Iteration 3670, loss = 0.3137
Iteration 3680, loss = 0.1994
Iteration 3690, loss = 0.2696
Iteration 3700, loss = 0.5203
Iteration 3710, loss = 0.2826
Iteration 3720, loss = 0.1942
Iteration 3730, loss = 0.2653
Iteration 3740, loss = 0.1567
Iteration 3750, loss = 0.2143
Iteration 3760, loss = 0.3231
Iteration 3770, loss = 0.2321
Iteration 3780, loss = 0.1909
Iteration 3790, loss = 0.1462
Iteration 3800, loss = 0.5153
Iteration 3810, loss = 0.2603
Iteration 3820, loss = 0.3063
Iteration 3830, loss = 0.2956
Iteration 3840, loss = 0.2697
Iteration 3850, loss = 0.3817
Iteration 3860, loss = 0.2357
Iteration 3870, loss = 0.1869
Iteration 3880, loss = 0.1845
Iteration 3890, loss = 0.3714
Iteration 3900, loss = 0.4425
Iteration 3910, loss = 0.3414
Iteration 3920, loss = 0.2710
Iteration 3930, loss = 0.4281
Iteration 3940, loss = 0.2595
Iteration 3950, loss = 0.1740
Iteration 3960, loss = 0.2665
Iteration 3970, loss = 0.2207
Iteration 3980, loss = 0.2723
Iteration 3990, loss = 0.1578
Iteration 4000, loss = 0.3293
Om: 8.86%, s8: 6.53% accuracy
RMSE: 0.0295, 0.0674

Iteration 4010, loss = 0.3328
Iteration 4020, loss = 0.2635
Iteration 4030, loss = 0.1738
Iteration 4040, loss = 0.3213
Iteration 4050, loss = 0.2928
Iteration 4060, loss = 0.2754
Iteration 4070, loss = 0.2010
Iteration 4080, loss = 0.1730
Iteration 4090, loss = 0.2433
Iteration 4100, loss = 0.3159
Iteration 4110, loss = 0.2722
Iteration 4120, loss = 0.3213
Iteration 4130, loss = 0.3852
Iteration 4140, loss = 0.2225
Iteration 4150, loss = 0.1373
Iteration 4160, loss = 0.2431
Iteration 4170, loss = 0.3190
Iteration 4180, loss = 0.2656
Iteration 4190, loss = 0.3934
Iteration 4200, loss = 0.2161
Iteration 4210, loss = 0.2398
Iteration 4220, loss = 0.2980
Iteration 4230, loss = 0.2661
Iteration 4240, loss = 0.3282
Iteration 4250, loss = 0.2618
Iteration 4260, loss = 0.4699
Iteration 4270, loss = 0.3314
Iteration 4280, loss = 0.3536
Iteration 4290, loss = 0.3543
Iteration 4300, loss = 0.1466
Iteration 4310, loss = 0.4063
Iteration 4320, loss = 0.2734
Iteration 4330, loss = 0.3355
Iteration 4340, loss = 0.2792
Iteration 4350, loss = 0.3000
Iteration 4360, loss = 0.2380
Iteration 4370, loss = 0.2868
Iteration 4380, loss = 0.5595
Iteration 4390, loss = 0.3942
Iteration 4400, loss = 0.3086
Iteration 4410, loss = 0.2312
Iteration 4420, loss = 0.3858
Iteration 4430, loss = 0.2323
Iteration 4440, loss = 0.1813
Iteration 4450, loss = 0.2259
Iteration 4460, loss = 0.3878
Iteration 4470, loss = 0.2863
Iteration 4480, loss = 0.2766
Iteration 4490, loss = 0.3786
Iteration 4500, loss = 0.4144
Iteration 4510, loss = 0.1936
Iteration 4520, loss = 0.3337
Iteration 4530, loss = 0.2337
Iteration 4540, loss = 0.3936
Iteration 4550, loss = 0.3925
Iteration 4560, loss = 0.1823
Iteration 4570, loss = 0.2323
Iteration 4580, loss = 0.2449
Iteration 4590, loss = 0.3534
Iteration 4600, loss = 0.3018
Iteration 4610, loss = 0.2507
Iteration 4620, loss = 0.2007
Iteration 4630, loss = 0.3562
Iteration 4640, loss = 0.1725
Iteration 4650, loss = 0.2626
Iteration 4660, loss = 0.2212
Iteration 4670, loss = 0.3283
Iteration 4680, loss = 0.3020
Iteration 4690, loss = 0.1300
Iteration 4700, loss = 0.3850
Iteration 4710, loss = 0.4744
Iteration 4720, loss = 0.4077
Iteration 4730, loss = 0.2324
Iteration 4740, loss = 0.1802
Iteration 4750, loss = 0.4046
Iteration 4760, loss = 0.1634
Iteration 4770, loss = 0.2952
Iteration 4780, loss = 0.2141
Iteration 4790, loss = 0.4024
Iteration 4800, loss = 0.4148
Iteration 4810, loss = 0.2624
Iteration 4820, loss = 0.1931
Iteration 4830, loss = 0.1850
Iteration 4840, loss = 0.2877
Iteration 4850, loss = 0.3101
Iteration 4860, loss = 0.1937
Iteration 4870, loss = 0.2004
Iteration 4880, loss = 0.3469
Iteration 4890, loss = 0.1805
Iteration 4900, loss = 0.3226
Iteration 4910, loss = 0.2108
Iteration 4920, loss = 0.3037
Iteration 4930, loss = 0.2711
Iteration 4940, loss = 0.1719
Iteration 4950, loss = 0.3219
Iteration 4960, loss = 0.2943
Iteration 4970, loss = 0.2828
Iteration 4980, loss = 0.3339
Iteration 4990, loss = 0.2011
Iteration 5000, loss = 0.1786
Om: 8.83%, s8: 6.49% accuracy
RMSE: 0.0296, 0.0627

Iteration 5010, loss = 0.2651
Iteration 5020, loss = 0.2523
Iteration 5030, loss = 0.1334
Iteration 5040, loss = 0.2386
Iteration 5050, loss = 0.3755
Iteration 5060, loss = 0.2828
Iteration 5070, loss = 0.3013
Iteration 5080, loss = 0.2974
Iteration 5090, loss = 0.1960
Iteration 5100, loss = 0.4517
Iteration 5110, loss = 0.3209
Iteration 5120, loss = 0.2354
Iteration 5130, loss = 0.2310
Iteration 5140, loss = 0.2476
Iteration 5150, loss = 0.2392
Iteration 5160, loss = 0.2809
Iteration 5170, loss = 0.2081
Iteration 5180, loss = 0.1978
Iteration 5190, loss = 0.2388
Iteration 5200, loss = 0.2364
Iteration 5210, loss = 0.2705
Iteration 5220, loss = 0.2287
Iteration 5230, loss = 0.1814
Iteration 5240, loss = 0.2269
Iteration 5250, loss = 0.3026
Iteration 5260, loss = 0.2895
Iteration 5270, loss = 0.3108
Iteration 5280, loss = 0.3584
Iteration 5290, loss = 0.2415
Iteration 5300, loss = 0.2794
Iteration 5310, loss = 0.2760
Iteration 5320, loss = 0.2144
Iteration 5330, loss = 0.2163
Iteration 5340, loss = 0.2705
Iteration 5350, loss = 0.2475
Iteration 5360, loss = 0.3446
Iteration 5370, loss = 0.2626
Iteration 5380, loss = 0.2866
Iteration 5390, loss = 0.3216
Iteration 5400, loss = 0.3501
Iteration 5410, loss = 0.2024
Iteration 5420, loss = 0.2268
Iteration 5430, loss = 0.2722
Iteration 5440, loss = 0.1772
Iteration 5450, loss = 0.2098
Iteration 5460, loss = 0.2090
Iteration 5470, loss = 0.2911
Iteration 5480, loss = 0.3477
Iteration 5490, loss = 0.3713
Iteration 5500, loss = 0.3936
Iteration 5510, loss = 0.3387
Iteration 5520, loss = 0.3696
Iteration 5530, loss = 0.3255
Iteration 5540, loss = 0.3921
Iteration 5550, loss = 0.1792
Iteration 5560, loss = 0.1359
Iteration 5570, loss = 0.2326
Iteration 5580, loss = 0.2828
Iteration 5590, loss = 0.4232
Iteration 5600, loss = 0.2192
Iteration 5610, loss = 0.2711
Iteration 5620, loss = 0.2349
Iteration 5630, loss = 0.2662
Iteration 5640, loss = 0.2550
Iteration 5650, loss = 0.3368
Iteration 5660, loss = 0.2267
Iteration 5670, loss = 0.2715
Iteration 5680, loss = 0.3380
Iteration 5690, loss = 0.2733
Iteration 5700, loss = 0.1771
Iteration 5710, loss = 0.1404
Iteration 5720, loss = 0.1649
Iteration 5730, loss = 0.4038
Iteration 5740, loss = 0.5739
Iteration 5750, loss = 0.3343
Iteration 5760, loss = 0.4088
Iteration 5770, loss = 0.1128
Iteration 5780, loss = 0.3372
Iteration 5790, loss = 0.3671
Iteration 5800, loss = 0.3033
Iteration 5810, loss = 0.4438
Iteration 5820, loss = 0.3431
Iteration 5830, loss = 0.2072
Iteration 5840, loss = 0.2920
Iteration 5850, loss = 0.3108
Iteration 5860, loss = 0.1770
Iteration 5870, loss = 0.3526
Iteration 5880, loss = 0.3106
Iteration 5890, loss = 0.3470
Iteration 5900, loss = 0.3328
Iteration 5910, loss = 0.3152
Iteration 5920, loss = 0.2452
Iteration 5930, loss = 0.2849
Iteration 5940, loss = 0.2944
Iteration 5950, loss = 0.2916
Iteration 5960, loss = 0.1652
Iteration 5970, loss = 0.2133
Iteration 5980, loss = 0.3198
Iteration 5990, loss = 0.4023
Iteration 6000, loss = 0.1938
Om: 8.99%, s8: 6.40% accuracy
RMSE: 0.0303, 0.0645

Iteration 6010, loss = 0.2492
Iteration 6020, loss = 0.2554
Iteration 6030, loss = 0.2354
Iteration 6040, loss = 0.2775
Iteration 6050, loss = 0.2118
Iteration 6060, loss = 0.3513
Iteration 6070, loss = 0.3846
Iteration 6080, loss = 0.3003
Iteration 6090, loss = 0.3570
Iteration 6100, loss = 0.2734
Iteration 6110, loss = 0.3176
Iteration 6120, loss = 0.2251
Iteration 6130, loss = 0.4568
Iteration 6140, loss = 0.3951
Iteration 6150, loss = 0.1962
Iteration 6160, loss = 0.2822
Iteration 6170, loss = 0.2179
Iteration 6180, loss = 0.3545
Iteration 6190, loss = 0.2636
Iteration 6200, loss = 0.2619
Iteration 6210, loss = 0.2278
Iteration 6220, loss = 0.3078
Iteration 6230, loss = 0.2767
Iteration 6240, loss = 0.3334
Iteration 6250, loss = 0.2649
Iteration 6260, loss = 0.3438
Iteration 6270, loss = 0.1855
Iteration 6280, loss = 0.2712
Iteration 6290, loss = 0.2684
Iteration 6300, loss = 0.2659
Iteration 6310, loss = 0.1426
Iteration 6320, loss = 0.6600
Iteration 6330, loss = 0.3141
Iteration 6340, loss = 0.1773
Iteration 6350, loss = 0.1851
Iteration 6360, loss = 0.3992
Iteration 6370, loss = 0.1672
Iteration 6380, loss = 0.3099
Iteration 6390, loss = 0.2845
Iteration 6400, loss = 0.3315
Iteration 6410, loss = 0.2355
Iteration 6420, loss = 0.3321
Iteration 6430, loss = 0.2338
Iteration 6440, loss = 0.3685
Iteration 6450, loss = 0.3290
Iteration 6460, loss = 0.1746
Iteration 6470, loss = 0.1684
Iteration 6480, loss = 0.1812
Iteration 6490, loss = 0.2069
Iteration 6500, loss = 0.1754
Iteration 6510, loss = 0.2519
Iteration 6520, loss = 0.4961
Iteration 6530, loss = 0.3919
Iteration 6540, loss = 0.2555
Iteration 6550, loss = 0.3469
Iteration 6560, loss = 0.3138
Iteration 6570, loss = 0.2767
Iteration 6580, loss = 0.3236
Iteration 6590, loss = 0.2412
Iteration 6600, loss = 0.2415
Iteration 6610, loss = 0.2889
Iteration 6620, loss = 0.3763
Iteration 6630, loss = 0.2006
Iteration 6640, loss = 0.2288
Iteration 6650, loss = 0.1943
Iteration 6660, loss = 0.2873
Iteration 6670, loss = 0.2558
Iteration 6680, loss = 0.2292
Iteration 6690, loss = 0.1737
Iteration 6700, loss = 0.3326
Iteration 6710, loss = 0.2505
Iteration 6720, loss = 0.2925
Iteration 6730, loss = 0.2440
Iteration 6740, loss = 0.2611
Iteration 6750, loss = 0.3650
Iteration 6760, loss = 0.2201
Iteration 6770, loss = 0.4086
Iteration 6780, loss = 0.4071
Iteration 6790, loss = 0.3116
Iteration 6800, loss = 0.2160
Iteration 6810, loss = 0.2293
Iteration 6820, loss = 0.2161
Iteration 6830, loss = 0.2452
Iteration 6840, loss = 0.2601
Iteration 6850, loss = 0.3327
Iteration 6860, loss = 0.3725
Iteration 6870, loss = 0.2247
Iteration 6880, loss = 0.3064
Iteration 6890, loss = 0.1330
Iteration 6900, loss = 0.4107
Iteration 6910, loss = 0.4154
Iteration 6920, loss = 0.3379
Iteration 6930, loss = 0.4532
Iteration 6940, loss = 0.2713
Iteration 6950, loss = 0.2514
Iteration 6960, loss = 0.2003
Iteration 6970, loss = 0.2688
Iteration 6980, loss = 0.3976
Iteration 6990, loss = 0.2960
Iteration 7000, loss = 0.2677
Om: 8.86%, s8: 6.44% accuracy
RMSE: 0.0295, 0.0629

Iteration 7010, loss = 0.1725
Iteration 7020, loss = 0.2019
Iteration 7030, loss = 0.3110
Iteration 7040, loss = 0.2908
Iteration 7050, loss = 0.5149
Iteration 7060, loss = 0.3024
Iteration 7070, loss = 0.3524
Iteration 7080, loss = 0.4171
Iteration 7090, loss = 0.2947
Iteration 7100, loss = 0.2466
Iteration 7110, loss = 0.2015
Iteration 7120, loss = 0.2910
Iteration 7130, loss = 0.2712
Iteration 7140, loss = 0.3432
Iteration 7150, loss = 0.2276
Iteration 7160, loss = 0.2901
Iteration 7170, loss = 0.3795
Iteration 7180, loss = 0.1397
Iteration 7190, loss = 0.1984
Iteration 7200, loss = 0.2590
Iteration 7210, loss = 0.3070
Iteration 7220, loss = 0.1921
Iteration 7230, loss = 0.4697
Iteration 7240, loss = 0.3002
Iteration 7250, loss = 0.2962
Iteration 7260, loss = 0.2417
Iteration 7270, loss = 0.2638
Iteration 7280, loss = 0.3244
Iteration 7290, loss = 0.3282
Iteration 7300, loss = 0.2229
Iteration 7310, loss = 0.1963
Iteration 7320, loss = 0.2444
Iteration 7330, loss = 0.1438
Iteration 7340, loss = 0.1692
Iteration 7350, loss = 0.2173
Iteration 7360, loss = 0.2193
Iteration 7370, loss = 0.1867
Iteration 7380, loss = 0.3084
Iteration 7390, loss = 0.2693
Iteration 7400, loss = 0.2192
Iteration 7410, loss = 0.3211
Iteration 7420, loss = 0.2809
Iteration 7430, loss = 0.1693
Iteration 7440, loss = 0.3140
Iteration 7450, loss = 0.3192
Iteration 7460, loss = 0.2575
Iteration 7470, loss = 0.4294
Iteration 7480, loss = 0.3301
Iteration 7490, loss = 0.2840
Iteration 7500, loss = 0.2865
Iteration 7510, loss = 0.3917
Iteration 7520, loss = 0.2909
Iteration 7530, loss = 0.2912
Iteration 7540, loss = 0.3602
Iteration 7550, loss = 0.2664
Iteration 7560, loss = 0.2218
Iteration 7570, loss = 0.2862
Iteration 7580, loss = 0.2928
Iteration 7590, loss = 0.1755
Iteration 7600, loss = 0.1924
Iteration 7610, loss = 0.2143
Iteration 7620, loss = 0.2590
Iteration 7630, loss = 0.2402
Iteration 7640, loss = 0.1537
Iteration 7650, loss = 0.3985
Iteration 7660, loss = 0.2382
Iteration 7670, loss = 0.4794
Iteration 7680, loss = 0.4138
Iteration 7690, loss = 0.1746
Iteration 7700, loss = 0.2531
Iteration 7710, loss = 0.2561
Iteration 7720, loss = 0.5375
Iteration 7730, loss = 0.2639
Iteration 7740, loss = 0.3566
Iteration 7750, loss = 0.2068
Iteration 7760, loss = 0.2865
Iteration 7770, loss = 0.1812
Iteration 7780, loss = 0.2585
Iteration 7790, loss = 0.1847
Iteration 7800, loss = 0.3028
Iteration 7810, loss = 0.3037
Iteration 7820, loss = 0.1817
Iteration 7830, loss = 0.1765
Iteration 7840, loss = 0.2990
Iteration 7850, loss = 0.2162
Iteration 7860, loss = 0.3125
Iteration 7870, loss = 0.2462
Iteration 7880, loss = 0.2313
Iteration 7890, loss = 0.2622
Iteration 7900, loss = 0.3039
Iteration 7910, loss = 0.2282
Iteration 7920, loss = 0.2649
Iteration 7930, loss = 0.2061
Iteration 7940, loss = 0.3561
Iteration 7950, loss = 0.4033
Iteration 7960, loss = 0.3275
Iteration 7970, loss = 0.2956
Iteration 7980, loss = 0.3954
Iteration 7990, loss = 0.2327
Iteration 8000, loss = 0.2486
Om: 9.03%, s8: 7.59% accuracy
RMSE: 0.0305, 0.0791

Iteration 8010, loss = 0.2337
Iteration 8020, loss = 0.2289
Iteration 8030, loss = 0.1637
Iteration 8040, loss = 0.4110
Iteration 8050, loss = 0.3882
Iteration 8060, loss = 0.1927
Iteration 8070, loss = 0.3446
Iteration 8080, loss = 0.2366
Iteration 8090, loss = 0.2618
Iteration 8100, loss = 0.3709
Iteration 8110, loss = 0.5174
Iteration 8120, loss = 0.1991
Iteration 8130, loss = 0.3971
Iteration 8140, loss = 0.2429
Iteration 8150, loss = 0.3105
Iteration 8160, loss = 0.2977
Iteration 8170, loss = 0.2248
Iteration 8180, loss = 0.3626
Iteration 8190, loss = 0.2545
Iteration 8200, loss = 0.3375
Iteration 8210, loss = 0.2416
Iteration 8220, loss = 0.2977
Iteration 8230, loss = 0.1637
Iteration 8240, loss = 0.2003
Iteration 8250, loss = 0.3354
Iteration 8260, loss = 0.2361
Iteration 8270, loss = 0.2783
Iteration 8280, loss = 0.2906
Iteration 8290, loss = 0.2553
Iteration 8300, loss = 0.2243
Iteration 8310, loss = 0.1410
Iteration 8320, loss = 0.1702
Iteration 8330, loss = 0.1882
Iteration 8340, loss = 0.1718
Iteration 8350, loss = 0.1385
Iteration 8360, loss = 0.3058
Iteration 8370, loss = 0.2572
Iteration 8380, loss = 0.2956
Iteration 8390, loss = 0.1608
Iteration 8400, loss = 0.3221
Iteration 8410, loss = 0.3584
Iteration 8420, loss = 0.3432
Iteration 8430, loss = 0.1596
Iteration 8440, loss = 0.3624
Iteration 8450, loss = 0.2355
Iteration 8460, loss = 0.3193
Iteration 8470, loss = 0.2742
Iteration 8480, loss = 0.3741
Iteration 8490, loss = 0.2961
Iteration 8500, loss = 0.1760
Iteration 8510, loss = 0.2072
Iteration 8520, loss = 0.2283
Iteration 8530, loss = 0.2018
Iteration 8540, loss = 0.1976
Iteration 8550, loss = 0.3344
Iteration 8560, loss = 0.1854
Iteration 8570, loss = 0.3583
Iteration 8580, loss = 0.2074
Iteration 8590, loss = 0.2014
Iteration 8600, loss = 0.3652
Iteration 8610, loss = 0.3035
Iteration 8620, loss = 0.2611
Iteration 8630, loss = 0.1686
Iteration 8640, loss = 0.2334
Iteration 8650, loss = 0.1843
Iteration 8660, loss = 0.1690
Iteration 8670, loss = 0.3981
Iteration 8680, loss = 0.2604
Iteration 8690, loss = 0.2949
Iteration 8700, loss = 0.2593
Iteration 8710, loss = 0.2457
Iteration 8720, loss = 0.1476
Iteration 8730, loss = 0.4455
Iteration 8740, loss = 0.3411
Iteration 8750, loss = 0.2601
Iteration 8760, loss = 0.2082
Iteration 8770, loss = 0.3209
Iteration 8780, loss = 0.2505
Iteration 8790, loss = 0.2609
Iteration 8800, loss = 0.3534
Iteration 8810, loss = 0.3004
Iteration 8820, loss = 0.2664
Iteration 8830, loss = 0.1118
Iteration 8840, loss = 0.3303
Iteration 8850, loss = 0.2331
Iteration 8860, loss = 0.3412
Iteration 8870, loss = 0.2650
Iteration 8880, loss = 0.1867
Iteration 8890, loss = 0.2626
Iteration 8900, loss = 0.3167
Iteration 8910, loss = 0.2790
Iteration 8920, loss = 0.2056
Iteration 8930, loss = 0.1793
Iteration 8940, loss = 0.1564
Iteration 8950, loss = 0.2807
Iteration 8960, loss = 0.1792
Iteration 8970, loss = 0.3600
Iteration 8980, loss = 0.1368
Iteration 8990, loss = 0.1778
Iteration 9000, loss = 0.2422
Om: 8.90%, s8: 6.49% accuracy
RMSE: 0.0297, 0.0628

Iteration 9010, loss = 0.2484
Iteration 9020, loss = 0.2450
Iteration 9030, loss = 0.2465
Iteration 9040, loss = 0.1729
Iteration 9050, loss = 0.2032
Iteration 9060, loss = 0.2411
Iteration 9070, loss = 0.3255
Iteration 9080, loss = 0.2441
Iteration 9090, loss = 0.1320
Iteration 9100, loss = 0.2256
Iteration 9110, loss = 0.2461
Iteration 9120, loss = 0.5373
Iteration 9130, loss = 0.3318
Iteration 9140, loss = 0.4002
Iteration 9150, loss = 0.2508
Iteration 9160, loss = 0.2558
Iteration 9170, loss = 0.3166
Iteration 9180, loss = 0.3029
Iteration 9190, loss = 0.2929
Iteration 9200, loss = 0.4043
Iteration 9210, loss = 0.5413
Iteration 9220, loss = 0.2446
Iteration 9230, loss = 0.3017
Iteration 9240, loss = 0.2778
Iteration 9250, loss = 0.1389
Iteration 9260, loss = 0.3200
Iteration 9270, loss = 0.3617
Iteration 9280, loss = 0.2862
Iteration 9290, loss = 0.2066
Iteration 9300, loss = 0.3309
Iteration 9310, loss = 0.2235
Iteration 9320, loss = 0.2751
Iteration 9330, loss = 0.1180
Iteration 9340, loss = 0.4115
Iteration 9350, loss = 0.2657
Iteration 9360, loss = 0.2364
Iteration 9370, loss = 0.2451
Iteration 9380, loss = 0.2004
Iteration 9390, loss = 0.2147
Iteration 9400, loss = 0.2296
Iteration 9410, loss = 0.4582
Iteration 9420, loss = 0.3667
Iteration 9430, loss = 0.3453
Iteration 9440, loss = 0.1731
Iteration 9450, loss = 0.1936
Iteration 9460, loss = 0.2579
Iteration 9470, loss = 0.2065
Iteration 9480, loss = 0.2247
Iteration 9490, loss = 0.1961
Iteration 9500, loss = 0.1310
Iteration 9510, loss = 0.2282
Iteration 9520, loss = 0.3076
Iteration 9530, loss = 0.3981
Iteration 9540, loss = 0.2672
Iteration 9550, loss = 0.2995
Iteration 9560, loss = 0.2037
Iteration 9570, loss = 0.1556
Iteration 9580, loss = 0.2256
Iteration 9590, loss = 0.2745
Iteration 9600, loss = 0.3485
Iteration 9610, loss = 0.3276
Iteration 9620, loss = 0.2676
Iteration 9630, loss = 0.1804
Iteration 9640, loss = 0.3258
Iteration 9650, loss = 0.1268
Iteration 9660, loss = 0.1415
Iteration 9670, loss = 0.1660
Iteration 9680, loss = 0.2390
Iteration 9690, loss = 0.1887
Iteration 9700, loss = 0.3606
Iteration 9710, loss = 0.3072
Iteration 9720, loss = 0.2134
Iteration 9730, loss = 0.2631
Iteration 9740, loss = 0.2385
Iteration 9750, loss = 0.3201
Iteration 9760, loss = 0.4443
Iteration 9770, loss = 0.2814
Iteration 9780, loss = 0.3166
Iteration 9790, loss = 0.2203
Iteration 9800, loss = 0.1443
Iteration 9810, loss = 0.2050
Iteration 9820, loss = 0.2992
Iteration 9830, loss = 0.3104
Iteration 9840, loss = 0.1993
Iteration 9850, loss = 0.1814
Iteration 9860, loss = 0.3041
Iteration 9870, loss = 0.3812
Iteration 9880, loss = 0.1664
Iteration 9890, loss = 0.1975
Iteration 9900, loss = 0.2417
Iteration 9910, loss = 0.3418
Iteration 9920, loss = 0.4929
Iteration 9930, loss = 0.3139
Iteration 9940, loss = 0.2309
Iteration 9950, loss = 0.0897
Iteration 9960, loss = 0.2351
Iteration 9970, loss = 0.2813
Iteration 9980, loss = 0.2480
Iteration 9990, loss = 0.4297
Iteration 10000, loss = 0.3173
Om: 10.02%, s8: 7.84% accuracy
RMSE: 0.0351, 0.0813

Iteration 10010, loss = 0.2621
Iteration 10020, loss = 0.2453
Iteration 10030, loss = 0.3234
Iteration 10040, loss = 0.5013
Iteration 10050, loss = 0.5027
Iteration 10060, loss = 0.3682
Iteration 10070, loss = 0.3025
Iteration 10080, loss = 0.3935
Iteration 10090, loss = 0.2606
Iteration 10100, loss = 0.2724
Iteration 10110, loss = 0.3948
Iteration 10120, loss = 0.1476
Iteration 10130, loss = 0.4851
Iteration 10140, loss = 0.2294
Iteration 10150, loss = 0.3657
Iteration 10160, loss = 0.2466
Iteration 10170, loss = 0.1868
Iteration 10180, loss = 0.2927
Iteration 10190, loss = 0.3019
Iteration 10200, loss = 0.3828
Iteration 10210, loss = 0.1767
Iteration 10220, loss = 0.2678
Iteration 10230, loss = 0.2355
Iteration 10240, loss = 0.4556
Iteration 10250, loss = 0.1962
Iteration 10260, loss = 0.2787
Iteration 10270, loss = 0.3647
Iteration 10280, loss = 0.2006
Iteration 10290, loss = 0.2813
Iteration 10300, loss = 0.3279
Iteration 10310, loss = 0.2197
Iteration 10320, loss = 0.1696
Iteration 10330, loss = 0.1937
Iteration 10340, loss = 0.2802
Iteration 10350, loss = 0.3276
Iteration 10360, loss = 0.1224
Iteration 10370, loss = 0.2312
Iteration 10380, loss = 0.2284
Iteration 10390, loss = 0.1601
Iteration 10400, loss = 0.1928
Iteration 10410, loss = 0.2968
Iteration 10420, loss = 0.2634
Iteration 10430, loss = 0.2707
Iteration 10440, loss = 0.2113
Iteration 10450, loss = 0.2130
Iteration 10460, loss = 0.2887
Iteration 10470, loss = 0.1946
Iteration 10480, loss = 0.1904
Iteration 10490, loss = 0.2598
Iteration 10500, loss = 0.1413
Iteration 10510, loss = 0.4283
Iteration 10520, loss = 0.2000
Iteration 10530, loss = 0.1717
Iteration 10540, loss = 0.2540
Iteration 10550, loss = 0.2229
Iteration 10560, loss = 0.2072
Iteration 10570, loss = 0.2907
Iteration 10580, loss = 0.2566
Iteration 10590, loss = 0.2735
Iteration 10600, loss = 0.3504
Iteration 10610, loss = 0.2534
Iteration 10620, loss = 0.2939
Iteration 10630, loss = 0.2361
Iteration 10640, loss = 0.2811
Iteration 10650, loss = 0.2145
Iteration 10660, loss = 0.2014
Iteration 10670, loss = 0.4378
Iteration 10680, loss = 0.1926
Iteration 10690, loss = 0.2960
Iteration 10700, loss = 0.4334
Iteration 10710, loss = 0.2806
Iteration 10720, loss = 0.2739
Iteration 10730, loss = 0.2695
Iteration 10740, loss = 0.2545
Iteration 10750, loss = 0.2626
Iteration 10760, loss = 0.2604
Iteration 10770, loss = 0.1716
Iteration 10780, loss = 0.2290
Iteration 10790, loss = 0.1517
Iteration 10800, loss = 0.2665
Iteration 10810, loss = 0.2580
Iteration 10820, loss = 0.1473
Iteration 10830, loss = 0.2187
Iteration 10840, loss = 0.1967
Iteration 10850, loss = 0.4087
Iteration 10860, loss = 0.1831
Iteration 10870, loss = 0.3444
Iteration 10880, loss = 0.2615
Iteration 10890, loss = 0.3804
Iteration 10900, loss = 0.3562
Iteration 10910, loss = 0.2744
Iteration 10920, loss = 0.2516
Iteration 10930, loss = 0.2502
Iteration 10940, loss = 0.2436
Iteration 10950, loss = 0.3865
Iteration 10960, loss = 0.2631
Iteration 10970, loss = 0.5297
Iteration 10980, loss = 0.2819
Iteration 10990, loss = 0.2083
Iteration 11000, loss = 0.2949
Om: 8.88%, s8: 6.56% accuracy
RMSE: 0.0298, 0.0632

Iteration 11010, loss = 0.3117
Iteration 11020, loss = 0.3342
Iteration 11030, loss = 0.3365
Iteration 11040, loss = 0.4054
Iteration 11050, loss = 0.1480
Iteration 11060, loss = 0.1504
Iteration 11070, loss = 0.2567
Iteration 11080, loss = 0.3351
Iteration 11090, loss = 0.1817
Iteration 11100, loss = 0.1831
Iteration 11110, loss = 0.2359
Iteration 11120, loss = 0.2982
Iteration 11130, loss = 0.2008
Iteration 11140, loss = 0.2199
Iteration 11150, loss = 0.1950
Iteration 11160, loss = 0.3391
Iteration 11170, loss = 0.3144
Iteration 11180, loss = 0.2216
Iteration 11190, loss = 0.3072
Iteration 11200, loss = 0.0997
Iteration 11210, loss = 0.1799
Iteration 11220, loss = 0.3086
Iteration 11230, loss = 0.1822
Iteration 11240, loss = 0.1883
Iteration 11250, loss = 0.1517
Iteration 11260, loss = 0.3026
Iteration 11270, loss = 0.1969
Iteration 11280, loss = 0.2733
Iteration 11290, loss = 0.2050
Iteration 11300, loss = 0.2798
Iteration 11310, loss = 0.3936
Iteration 11320, loss = 0.2770
Iteration 11330, loss = 0.1560
Iteration 11340, loss = 0.1463
Iteration 11350, loss = 0.3630
Iteration 11360, loss = 0.2752
Iteration 11370, loss = 0.2729
Iteration 11380, loss = 0.3379
Iteration 11390, loss = 0.3076
Iteration 11400, loss = 0.1842
Iteration 11410, loss = 0.3690
Iteration 11420, loss = 0.1937
Iteration 11430, loss = 0.2037
Iteration 11440, loss = 0.2703
Iteration 11450, loss = 0.3472
Iteration 11460, loss = 0.3180
Iteration 11470, loss = 0.4094
Iteration 11480, loss = 0.3151
Iteration 11490, loss = 0.2446
Iteration 11500, loss = 0.1943
Iteration 11510, loss = 0.2010
Iteration 11520, loss = 0.1890
Iteration 11530, loss = 0.2087
Iteration 11540, loss = 0.2294
Iteration 11550, loss = 0.1611
Starting epoch 1
Iteration 11560, loss = 0.2251
Iteration 11570, loss = 0.2850
Iteration 11580, loss = 0.2934
Iteration 11590, loss = 0.2863
Iteration 11600, loss = 0.1251
Iteration 11610, loss = 0.2041
Iteration 11620, loss = 0.5132
Iteration 11630, loss = 0.1519
Iteration 11640, loss = 0.3075
Iteration 11650, loss = 0.2775
Iteration 11660, loss = 0.2922
Iteration 11670, loss = 0.2484
Iteration 11680, loss = 0.2987
Iteration 11690, loss = 0.2323
Iteration 11700, loss = 0.2066
Iteration 11710, loss = 0.1876
Iteration 11720, loss = 0.3341
Iteration 11730, loss = 0.2832
Iteration 11740, loss = 0.1778
Iteration 11750, loss = 0.2577
Iteration 11760, loss = 0.1992
Iteration 11770, loss = 0.1467
Iteration 11780, loss = 0.5735
Iteration 11790, loss = 0.2581
Iteration 11800, loss = 0.2325
Iteration 11810, loss = 0.2043
Iteration 11820, loss = 0.1567
Iteration 11830, loss = 0.3071
Iteration 11840, loss = 0.2970
Iteration 11850, loss = 0.2149
Iteration 11860, loss = 0.3520
Iteration 11870, loss = 0.2442
Iteration 11880, loss = 0.3065
Iteration 11890, loss = 0.2727
Iteration 11900, loss = 0.2247
Iteration 11910, loss = 0.2910
Iteration 11920, loss = 0.2442
Iteration 11930, loss = 0.2990
Iteration 11940, loss = 0.2404
Iteration 11950, loss = 0.2627
Iteration 11960, loss = 0.2581
Iteration 11970, loss = 0.3329
Iteration 11980, loss = 0.1845
Iteration 11990, loss = 0.2467
Iteration 12000, loss = 0.2631
Om: 9.11%, s8: 7.10% accuracy
RMSE: 0.0309, 0.0741

Iteration 12010, loss = 0.2913
Iteration 12020, loss = 0.2359
Iteration 12030, loss = 0.4210
Iteration 12040, loss = 0.3774
Iteration 12050, loss = 0.2720
Iteration 12060, loss = 0.3706
Iteration 12070, loss = 0.3942
Iteration 12080, loss = 0.2660
Iteration 12090, loss = 0.3035
Iteration 12100, loss = 0.4309
Iteration 12110, loss = 0.4503
Iteration 12120, loss = 0.2928
Iteration 12130, loss = 0.4557
Iteration 12140, loss = 0.2319
Iteration 12150, loss = 0.2413
Iteration 12160, loss = 0.1637
Iteration 12170, loss = 0.4604
Iteration 12180, loss = 0.4762
Iteration 12190, loss = 0.4232
Iteration 12200, loss = 0.2869
Iteration 12210, loss = 0.1789
Iteration 12220, loss = 0.2750
Iteration 12230, loss = 0.3065
Iteration 12240, loss = 0.3837
Iteration 12250, loss = 0.2257
Iteration 12260, loss = 0.2783
Iteration 12270, loss = 0.1983
Iteration 12280, loss = 0.3552
Iteration 12290, loss = 0.1703
Iteration 12300, loss = 0.1978
Iteration 12310, loss = 0.2926
Iteration 12320, loss = 0.2084
Iteration 12330, loss = 0.2368
Iteration 12340, loss = 0.2282
Iteration 12350, loss = 0.3145
Iteration 12360, loss = 0.2272
Iteration 12370, loss = 0.1953
Iteration 12380, loss = 0.4118
Iteration 12390, loss = 0.2818
Iteration 12400, loss = 0.2310
Iteration 12410, loss = 0.2900
Iteration 12420, loss = 0.2745
Iteration 12430, loss = 0.2395
Iteration 12440, loss = 0.2073
Iteration 12450, loss = 0.2049
Iteration 12460, loss = 0.2907
Iteration 12470, loss = 0.5062
Iteration 12480, loss = 0.4176
Iteration 12490, loss = 0.2125
Iteration 12500, loss = 0.2846
Iteration 12510, loss = 0.1609
Iteration 12520, loss = 0.2607
Iteration 12530, loss = 0.1861
Iteration 12540, loss = 0.3066
Iteration 12550, loss = 0.1834
Iteration 12560, loss = 0.3480
Iteration 12570, loss = 0.1535
Iteration 12580, loss = 0.1142
Iteration 12590, loss = 0.2357
Iteration 12600, loss = 0.2831
Iteration 12610, loss = 0.1729
Iteration 12620, loss = 0.2473
Iteration 12630, loss = 0.2682
Iteration 12640, loss = 0.2659
Iteration 12650, loss = 0.2108
Iteration 12660, loss = 0.2205
Iteration 12670, loss = 0.3133
Iteration 12680, loss = 0.3392
Iteration 12690, loss = 0.3651
Iteration 12700, loss = 0.2733
Iteration 12710, loss = 0.5512
Iteration 12720, loss = 0.1603
Iteration 12730, loss = 0.4051
Iteration 12740, loss = 0.1553
Iteration 12750, loss = 0.3290
Iteration 12760, loss = 0.3938
Iteration 12770, loss = 0.3557
Iteration 12780, loss = 0.3826
Iteration 12790, loss = 0.3436
Iteration 12800, loss = 0.2587
Iteration 12810, loss = 0.1593
Iteration 12820, loss = 0.3813
Iteration 12830, loss = 0.3250
Iteration 12840, loss = 0.2220
Iteration 12850, loss = 0.1595
Iteration 12860, loss = 0.1812
Iteration 12870, loss = 0.2530
Iteration 12880, loss = 0.2345
Iteration 12890, loss = 0.2136
Iteration 12900, loss = 0.4140
Iteration 12910, loss = 0.1614
Iteration 12920, loss = 0.2333
Iteration 12930, loss = 0.2668
Iteration 12940, loss = 0.2084
Iteration 12950, loss = 0.1958
Iteration 12960, loss = 0.3025
Iteration 12970, loss = 0.2142
Iteration 12980, loss = 0.1941
Iteration 12990, loss = 0.2186
Iteration 13000, loss = 0.2716
Om: 8.84%, s8: 6.64% accuracy
RMSE: 0.0296, 0.0688

Iteration 13010, loss = 0.2616
Iteration 13020, loss = 0.3881
Iteration 13030, loss = 0.1764
Iteration 13040, loss = 0.2788
Iteration 13050, loss = 0.3324
Iteration 13060, loss = 0.3019
Iteration 13070, loss = 0.1991
Iteration 13080, loss = 0.1228
Iteration 13090, loss = 0.2640
Iteration 13100, loss = 0.2698
Iteration 13110, loss = 0.2208
Iteration 13120, loss = 0.1701
Iteration 13130, loss = 0.1760
Iteration 13140, loss = 0.3302
Iteration 13150, loss = 0.1660
Iteration 13160, loss = 0.1781
Iteration 13170, loss = 0.2019
Iteration 13180, loss = 0.1678
Iteration 13190, loss = 0.2995
Iteration 13200, loss = 0.3697
Iteration 13210, loss = 0.4322
Iteration 13220, loss = 0.3422
Iteration 13230, loss = 0.3624
Iteration 13240, loss = 0.2466
Iteration 13250, loss = 0.2365
Iteration 13260, loss = 0.3408
Iteration 13270, loss = 0.2490
Iteration 13280, loss = 0.2552
Iteration 13290, loss = 0.2133
Iteration 13300, loss = 0.2996
Iteration 13310, loss = 0.2018
Iteration 13320, loss = 0.4309
Iteration 13330, loss = 0.2192
Iteration 13340, loss = 0.2598
Iteration 13350, loss = 0.2472
Iteration 13360, loss = 0.3505
Iteration 13370, loss = 0.2527
Iteration 13380, loss = 0.2690
Iteration 13390, loss = 0.1680
Iteration 13400, loss = 0.3345
Iteration 13410, loss = 0.2146
Iteration 13420, loss = 0.1462
Iteration 13430, loss = 0.2095
Iteration 13440, loss = 0.2170
Iteration 13450, loss = 0.3059
Iteration 13460, loss = 0.3263
Iteration 13470, loss = 0.2607
Iteration 13480, loss = 0.4034
Iteration 13490, loss = 0.2494
Iteration 13500, loss = 0.2306
Iteration 13510, loss = 0.2026
Iteration 13520, loss = 0.1980
Iteration 13530, loss = 0.2763
Iteration 13540, loss = 0.2569
Iteration 13550, loss = 0.2917
Iteration 13560, loss = 0.2156
Iteration 13570, loss = 0.1487
Iteration 13580, loss = 0.3646
Iteration 13590, loss = 0.3341
Iteration 13600, loss = 0.2796
Iteration 13610, loss = 0.2254
Iteration 13620, loss = 0.2484
Iteration 13630, loss = 0.2265
Iteration 13640, loss = 0.3612
Iteration 13650, loss = 0.2392
Iteration 13660, loss = 0.2721
Iteration 13670, loss = 0.2785
Iteration 13680, loss = 0.1913
Iteration 13690, loss = 0.3268
Iteration 13700, loss = 0.2354
Iteration 13710, loss = 0.1596
Iteration 13720, loss = 0.2699
Iteration 13730, loss = 0.2921
Iteration 13740, loss = 0.1785
Iteration 13750, loss = 0.2628
Iteration 13760, loss = 0.2057
Iteration 13770, loss = 0.2885
Iteration 13780, loss = 0.1686
Iteration 13790, loss = 0.2481
Iteration 13800, loss = 0.2944
Iteration 13810, loss = 0.2670
Iteration 13820, loss = 0.2719
Iteration 13830, loss = 0.2665
Iteration 13840, loss = 0.1702
Iteration 13850, loss = 0.1037
Iteration 13860, loss = 0.3284
Iteration 13870, loss = 0.2318
Iteration 13880, loss = 0.2729
Iteration 13890, loss = 0.2095
Iteration 13900, loss = 0.3480
Iteration 13910, loss = 0.3195
Iteration 13920, loss = 0.1753
Iteration 13930, loss = 0.1647
Iteration 13940, loss = 0.1973
Iteration 13950, loss = 0.1624
Iteration 13960, loss = 0.3291
Iteration 13970, loss = 0.3148
Iteration 13980, loss = 0.3072
Iteration 13990, loss = 0.3592
Iteration 14000, loss = 0.2314
Om: 9.02%, s8: 6.44% accuracy
RMSE: 0.0305, 0.0631

Iteration 14010, loss = 0.3231
Iteration 14020, loss = 0.2263
Iteration 14030, loss = 0.1756
Iteration 14040, loss = 0.3049
Iteration 14050, loss = 0.1269
Iteration 14060, loss = 0.2526
Iteration 14070, loss = 0.3175
Iteration 14080, loss = 0.2738
Iteration 14090, loss = 0.2786
Iteration 14100, loss = 0.1444
