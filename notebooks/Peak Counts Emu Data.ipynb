{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to compare the NNs vs Peak Counts my making a peak counts emulator. This is where I'll try loading them up and making the training data and seeing what they look like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import h5py\n",
    "from lenstools import ConvergenceMap\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from astropy.units import deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_filename = '/home/users/swmclau2/oak/Uatu/UatuFastPMTraining/UatuFastPMTraining.hdf5'\n",
    "test_filename = '/home/users/swmclau2/oak/Uatu/UatuFastPMTest/UatuFastPMTest.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with h5py.File(training_filename, 'r') as f:\n",
    "    mean, std = f.attrs['mean'], f.attrs['std']\n",
    "    X =  f['Box000']['X'][()].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-663e382b9215>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.imshow(np.log10(X[0]-X[0].min()+1e-6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shape_noise = 0.3/np.sqrt((2.34**2)*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def noise_and_smooth(image, noise_level = shape_noise, smooth=1):\n",
    "    i = image + np.random.randn(*image.shape)*noise_level\n",
    "    return gaussian_filter(i, smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "smoothX = noise_and_smooth(X[0])\n",
    "plt.imshow(smoothX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "smoothX.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.hist(smoothX.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def image_pc(image):\n",
    "    #image = (image-image.mean())/image.std()\n",
    "    cmap = ConvergenceMap(image, angle=10*deg)\n",
    "    thresholds = np.linspace(-0.01, 0.04,  41)\n",
    "    #thresholds = np.linspace(-5, 5, 200)\n",
    "    nu,peaks = cmap.peakCount(thresholds, norm=False)\n",
    "    return nu,peaks#/psd1D[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nu,pc = image_pc(smoothX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(nu, pc)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_all_pc(images):\n",
    "    \n",
    "    all_pcs = np.zeros((images.shape[0], 40))\n",
    "    for i, im in enumerate(images):\n",
    "        nu, all_pcs[i] = image_pc(noise_and_smooth(im))\n",
    "    return nu, all_pcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nu, all_pcs = compute_all_pc(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.errorbar(nu, all_pcs.mean(axis=0), yerr = all_pcs.std(axis=0))\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create the peak counts datasets\n",
    "\n",
    "def create_peak_counts_dset(conv_dset_fname):\n",
    "        \n",
    "    with h5py.File(conv_dset_fname, 'r') as cf:\n",
    "        \n",
    "        mean_pc = np.zeros((len(cf.keys()), 40))\n",
    "        #err_pc =  np.zeros((len(cf.keys()), 40))\n",
    "        cov_pc = np.zeros((len(cf.keys()), 40, 40))\n",
    "        for i,key in enumerate(cf.keys()):\n",
    "            print key\n",
    "            X =  cf[key]['X'][()].squeeze()\n",
    "            Y =  cf[key]['Y'][()].squeeze()\n",
    "            \n",
    "            _, all_pcs = compute_all_pc(X)\n",
    "            \n",
    "            mean_pc[i] = all_pcs.mean(axis=0)\n",
    "            #err_pc[i] = all_pcs.std(axis=0)\n",
    "            cov_pc[i] = all_pcs.cov(axis=0)\n",
    "            \n",
    "        return mean_pc, cov_pc"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "training_pc, training_err = create_peak_counts_dset(training_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pc, test_err = create_peak_counts_dset(test_filename)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "np.save('training_pc.npy', training_pc)\n",
    "np.save('training_err.npy', training_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('test_pc.npy', test_pc)\n",
    "np.save('test_err.npy', test_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_pc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
