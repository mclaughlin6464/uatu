{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm having difficultly replicating the results of my TF trained model in pytorch. I'm just gonna manually copy the weights over. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sean/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/sean/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/sean/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/sean/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/sean/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/sean/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/sean/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/sean/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/sean/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/sean/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/sean/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/sean/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uatu.scattering import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf_model_name =  '../networks/gupta_net_kappa-28900'\n",
    "#tf_model_name = '../networks/gupta_bayes_net_kappa-45000'\n",
    "tf_model_name = '../networks/gupta_net_kappa_adv_abs-9050'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 0\n",
    "max_order = 0\n",
    "\n",
    "J = 0\n",
    "L = 8\n",
    "K = int(1 + L*J +(L**2)*(J*(J-1))/2.0)\n",
    "\n",
    "width = 2\n",
    "smooth = 0\n",
    "shape = (256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = True\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scattering = lambda x: x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del model\n",
    "except:\n",
    "    pass\n",
    "\n",
    "model = GuptaNet(1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.load_state_dict(torch.load(model_path, map_location='cpu'))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "        torch.nn.init.ones_(m.weight)#, gain=4.0)\n",
    "        torch.nn.init.zeros_(m.bias)\n",
    "        #m.bias.data.fill_(0.01)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GuptaNet(\n",
       "  (layer_0): BasicBlock(\n",
       "    (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (downsample): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  )\n",
       "  (layer_1): BasicBlock(\n",
       "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (downsample): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  )\n",
       "  (layer_2): BasicBlock(\n",
       "    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (downsample): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  )\n",
       "  (relu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "  (fc1): Linear(in_features=131072, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_path = path.abspath(tf_model_name)  # Path to our TensorFlow checkpoint\n",
    "tf_vars = tf.train.list_variables(tf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('kappa_filters/conv1/weights', [3, 3, 1, 32])\n",
      "('kappa_filters/conv2/weights', [3, 3, 32, 64])\n",
      "('kappa_filters/conv3/weights', [3, 3, 64, 128])\n",
      "('kappa_filters/conv4/weights', [3, 3, 128, 128])\n",
      "('kappa_filters/conv5/weights', [3, 3, 128, 128])\n",
      "('kappa_filters/conv6/weights', [3, 3, 128, 128])\n",
      "('kappa_filters/dense1/biases', [256])\n",
      "('kappa_filters/dense1/weights', [131072, 256])\n",
      "('kappa_filters/dense2/biases', [256])\n",
      "('kappa_filters/dense2/weights', [256, 256])\n",
      "('kappa_filters/dense3/biases', [2])\n",
      "('kappa_filters/dense3/weights', [256, 2])\n"
     ]
    }
   ],
   "source": [
    "var_dict = {}\n",
    "for var in tf_vars:\n",
    "    if 'Adam' not in var[0] and 'beta' not in var[0]:\n",
    "        print(var)\n",
    "        val =  tf.train.load_variable(tf_path, var[0]).T\n",
    "        if len(val.shape)>2:\n",
    "            val = np.swapaxes(val, 2,3)\n",
    "        #elif len(val.shape)==2:\n",
    "        #    val = val.T\n",
    "        var_dict[var[0]] = torch.nn.Parameter(torch.Tensor(val))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for layer_no in range(3):\n",
    "    pt_layer = getattr(model, 'layer_%d'%layer_no)\n",
    "    conv_key = 'conv2d/kernel' if layer_no == 0 else 'conv2d_%d/kernel'%(layer_no*2)\n",
    "    #print(conv_key)\n",
    "    #print(pt_layer.conv1.weight.shape)\n",
    "    pt_layer.conv1.weight = var_dict[conv_key]\n",
    "    #print(pt_layer.conv1.weight.shape)\n",
    "    #print()\n",
    "    bias_key = 'conv2d/bias' if layer_no == 0 else 'conv2d_%d/bias'%(layer_no*2)\n",
    "    #print(pt_layer.conv1.bias.shape)\n",
    "    pt_layer.conv1.bias = var_dict[bias_key]\n",
    "    #print(pt_layer.conv1.bias.shape)\n",
    "    #print()\n",
    "    \n",
    "    conv_key = 'conv2d_%d/kernel'%(layer_no*2+1)\n",
    "    #print(conv_key)\n",
    "    #print(pt_layer.conv2.weight.shape)\n",
    "    pt_layer.conv2.weight = var_dict[conv_key]\n",
    "    #print(pt_layer.conv2.weight.shape)\n",
    "    #print()\n",
    "    bias_key = 'conv2d_%d/bias'%(layer_no*2+1)\n",
    "    #print(pt_layer.conv2.bias.shape)\n",
    "    pt_layer.conv2.bias = var_dict[bias_key]\n",
    "    #print(pt_layer.conv2.bias.shape)\n",
    "    #print()\n",
    "    #print('*'*30)\n",
    "    \n",
    "for layer_no in range(3):\n",
    "    pt_layer = getattr(model, 'fc%d'%(layer_no+1))\n",
    "    weight_key = 'dense/kernel' if layer_no == 0 else 'dense_%d/kernel'%(layer_no) \n",
    "    #print(pt_layer.weight.shape)\n",
    "    pt_layer.weight = var_dict[weight_key]                   \n",
    "    #print(pt_layer.weight.shape)\n",
    "    bias_key = 'dense/bias' if layer_no == 0 else 'dense_%d/bias'%(layer_no) \n",
    "    #print(pt_layer.bias.shape)\n",
    "    pt_layer.bias = var_dict[bias_key]                   \n",
    "    #print(pt_layer.bias.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kappa_filters/conv1/weights\n",
      "torch.Size([32, 1, 3, 3])\n",
      "torch.Size([32, 1, 3, 3])\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "kappa_filters/conv2/weights\n",
      "torch.Size([64, 32, 3, 3])\n",
      "torch.Size([64, 32, 3, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "kappa_filters/conv3/weights\n",
      "torch.Size([128, 64, 3, 3])\n",
      "torch.Size([128, 64, 3, 3])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "kappa_filters/conv4/weights\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "kappa_filters/conv5/weights\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "kappa_filters/conv6/weights\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "Linear(in_features=131072, out_features=256, bias=True)\n",
      "kappa_filters/dense1/weights\n",
      "torch.Size([256, 131072])\n",
      "torch.Size([256, 131072])\n",
      "kappa_filters/dense1/biases\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "Linear(in_features=256, out_features=256, bias=True)\n",
      "kappa_filters/dense2/weights\n",
      "torch.Size([256, 256])\n",
      "torch.Size([256, 256])\n",
      "kappa_filters/dense2/biases\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "Linear(in_features=256, out_features=2, bias=True)\n",
      "kappa_filters/dense3/weights\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "kappa_filters/dense3/biases\n",
      "torch.Size([2])\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "for layer_no in range(3):\n",
    "    pt_layer = getattr(model, 'layer_%d'%layer_no)\n",
    "    conv_key =  'kappa_filters/conv%d/weights'%(layer_no*2+1)\n",
    "    print(conv_key)\n",
    "    print(pt_layer.conv1.weight.shape)\n",
    "    pt_layer.conv1.weight = var_dict[conv_key]\n",
    "    print(pt_layer.conv1.weight.shape)\n",
    "    #print()\n",
    "    #bias_key = 'kappa_filters/conv2d/bias' if layer_no == 0 else 'kappa_filters/conv2d_%d/bias'%(layer_no*2)\n",
    "    print(pt_layer.conv1.bias.shape)\n",
    "    pt_layer.conv1.bias = torch.nn.Parameter(torch.zeros(pt_layer.conv1.bias.shape[0]))#var_dict[bias_key]\n",
    "    print(pt_layer.conv1.bias.shape)\n",
    "    #print()\n",
    "    \n",
    "    conv_key = 'kappa_filters/conv%d/weights'%(layer_no*2+2)\n",
    "    print(conv_key)\n",
    "    print(pt_layer.conv2.weight.shape)\n",
    "    pt_layer.conv2.weight = var_dict[conv_key]\n",
    "    print(pt_layer.conv2.weight.shape)\n",
    "    #print()\n",
    "    #bias_key = 'kappa_filters/conv2d_%d/bias'%(layer_no*2+1)\n",
    "    print(pt_layer.conv2.bias.shape)\n",
    "    #pt_layer.conv2.bias = var_dict[bias_key]\n",
    "    pt_layer.conv2.bias = torch.nn.Parameter(torch.zeros(pt_layer.conv2.bias.shape[0]))#var_dict[bias_key]\n",
    "    print(pt_layer.conv2.bias.shape)\n",
    "    #print()\n",
    "    #print('*'*30)\n",
    "    \n",
    "for layer_no in range(3):\n",
    "    pt_layer = getattr(model, 'fc%d'%(layer_no+1))\n",
    "    print(pt_layer)\n",
    "    weight_key =  'kappa_filters/dense%d/weights'%(layer_no+1) \n",
    "    print(weight_key)\n",
    "    print(pt_layer.weight.shape)\n",
    "    pt_layer.weight = var_dict[weight_key]                   \n",
    "    print(pt_layer.weight.shape)\n",
    "    bias_key = 'kappa_filters/dense%d/biases'%(layer_no+1) \n",
    "    print(bias_key)\n",
    "    print(pt_layer.bias.shape)\n",
    "    pt_layer.bias = var_dict[bias_key]                   \n",
    "    print(pt_layer.bias.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '../networks/gupta_net_tf_adv_clone.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GuptaNet(\n",
       "  (layer_0): BasicBlock(\n",
       "    (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (downsample): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  )\n",
       "  (layer_1): BasicBlock(\n",
       "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (downsample): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  )\n",
       "  (layer_2): BasicBlock(\n",
       "    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (downsample): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  )\n",
       "  (relu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "  (fc1): Linear(in_features=131072, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, x, y, cost_fn):\n",
    "    x, y = torch.Tensor(x).to(device), torch.Tensor(y).to(device)\n",
    "    output = model(x)\n",
    "    #loss = cost_fn(output, y) \n",
    "    \n",
    "    return output.to('cpu').detach().numpy()#, loss.to('cpu').detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File('../data/UatuLightconeTraining.hdf5', 'r')\n",
    "mean, std =  f.attrs['mean'], f.attrs['std']\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File('../data/UatuLightconeSameSeed.hdf5', 'r')\n",
    "boxno = 0\n",
    "test_X = np.array(f['Box%03d'%boxno][\"X\"][()])\n",
    "test_Y = f['Box%03d'%boxno]['Y'][0].reshape((1,2))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = (test_X-mean)/(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100 \n",
    "batch_size = 1 \n",
    "\n",
    "X = test_X[n, :, :, :].reshape((1, test_X.shape[1],\\\n",
    "                                test_X.shape[2], test_X.shape[3]))\n",
    "X = np.tile(X, (batch_size, 1, 1, 1) )\n",
    "Y = test_Y[0, :].reshape((1, test_Y.shape[1]))\n",
    "Y = np.tile(Y, (batch_size, 1))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Box Cosmos:\n",
    "box_cosmos = np.array([\n",
    "[0.303972, 0.877967],\n",
    "[0.281863, 0.856348],\n",
    "[0.250043, 0.760264],\n",
    "[0.347294, 0.978854],\n",
    "[0.260716, 0.776786]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = test(model, X,Y, cost_fn=lambda x,y: torch.nn.functional.l1_loss(x,y, reduction='sum'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.28403902, 0.85110223]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
